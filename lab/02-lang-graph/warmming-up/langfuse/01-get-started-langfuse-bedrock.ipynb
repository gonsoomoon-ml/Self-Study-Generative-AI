{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langfuse 로 Amazon Bedrock 시작하기\n",
    "\n",
    "이 노트북은 [Langfuse](https://langfuse.com/) 를 사용하여 Amazonb Bedrock 의 LLM 을 사용하는 방법을 \n",
    "가이드하는 노트북 입니다.\n",
    "\n",
    "이 노트북을 사용하기 전에 아래의 참조 자료를 확인 해보세요. \n",
    "\n",
    "#### 참조 자료: \n",
    "\n",
    "* LLM 앱 디버깅 툴, Langfuse를 Amazon ECS에 배포하는 방법, [Youtube Link](https://www.youtube.com/watch?v=rrPQcWq5pe8&t=5s)\n",
    "* Hosting Langfuse V3 on Amazon ECS with Fargate using CDK Python, [Git Repo](https://github.com/aws-samples/deploy-langfuse-on-ecs-with-fargate/tree/main/langfuse-v3)\n",
    "* Amazon ECS와 AWS Fargate를 사용하여 AWS CDK Python으로 Langfuse 호스팅하기, [Blog Link](https://aws.amazon.com/ko/blogs/tech/hosting-langfuse-with-aws-cdk-python-using-amazon-ecs-and-aws-fargate/)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 선수 사항: \n",
    "### 1.1 Langfuse 를 AWS 인프라에 호스팅 \n",
    "- 아래의 설치 가이드에 따라 Langfuse 를 먼저 설치 하세요.\n",
    "    - [설치 가이드: Langfuse 를 AWS 인프라에 호스팅 ](../../setup/LAGNFUSE_README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. 선수 사항: 콘다 가상 환경 생성\n",
    "- [setup](../../setup/README.md) 의 가이드에 따라 실행하여, 가상 환경인 langgraph 생성\n",
    "- 이후 모든 노트북의 커널은 langgraph 를 사용합니다.\n",
    "\n",
    "### 1.3. Key 정보를 저장하는 env 파일 생성\n",
    "-  ../../.env 파일을 생성하고 아래의 내용을 작성\n",
    "    ```\n",
    "    LANGFUSE_SECRET_KEY=<secret key>\n",
    "    LANGFUSE_PUBLIC_KEY=<public key>\n",
    "    LANGFUSE_HOST=<host url>\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. .env 파일을 통하여 key 정보 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv(\"../../.env\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. langfuse_handler 핸들러 작성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.callback import CallbackHandler\n",
    "import os\n",
    "\n",
    "langfuse_handler = CallbackHandler(\n",
    "    public_key=os.environ.get('LANGFUSE_PUBLIC_KEY'),\n",
    "    secret_key=os.environ.get('LANGFUSE_SECRET_KEY'),\n",
    "    host=os.environ.get('LANGFUSE_HOST'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. langfuse endpoint 에 인증 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connection test\n",
    "langfuse_handler.auth_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LangCahin 모델 오브젝트 생성 및 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "llm = ChatBedrock(\n",
    "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    model_kwargs=dict(temperature=0),\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='프로그래밍을 좋아합니다.', additional_kwargs={'usage': {'prompt_tokens': 29, 'completion_tokens': 19, 'total_tokens': 48}, 'stop_reason': 'end_turn', 'thinking': {}, 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 29, 'completion_tokens': 19, 'total_tokens': 48}, 'stop_reason': 'end_turn', 'thinking': {}, 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-1acb4d91-48ce-418b-bef8-a8da9d74e319-0', usage_metadata={'input_tokens': 29, 'output_tokens': 19, 'total_tokens': 48})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to Korean. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages, config={\"callbacks\": [langfuse_handler]})\n",
    "ai_msg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프로그래밍을 좋아합니다.\n"
     ]
    }
   ],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LangChain 모델 Chaining 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='프로그래밍을 좋아합니다.', additional_kwargs={'usage': {'prompt_tokens': 23, 'completion_tokens': 19, 'total_tokens': 42}, 'stop_reason': 'end_turn', 'thinking': {}, 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 23, 'completion_tokens': 19, 'total_tokens': 42}, 'stop_reason': 'end_turn', 'thinking': {}, 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-3ce27afd-04ad-4025-8330-7836df81f24e-0', usage_metadata={'input_tokens': 23, 'output_tokens': 19, 'total_tokens': 42})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"korean\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    },\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.LangFuse 추적 내용 보기\n",
    "로컬에 호스팅된 LangFuse 에 로그인을 하면 아래와 같이 기록이 남습니다.\n",
    "- LLM 호출건수 추적 기록 남음\n",
    "    - ![lang_run_result_01.png](img/lang_run_result_01.png)\n",
    "- 아래는 위에서 chain.invoke() 를 실행시에 chain = prompt | llm 여기서 prompt 가 실행된 것을 추적 합니다.    \n",
    "    - ![lang_chain_template.png](img/lang_chain_template.png)  \n",
    "- 아래는 위에서 chain.invoke() 를 실행시에 chain = prompt | llm 여기서 lim 이 실행된 것을 추적 합니다.        \n",
    "    - ![lang_chain_chatbedrock.png](img/lang_chain_chatbedrock.png)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Bedrock Converse API 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='프로그래밍을 좋아합니다.', additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '4bf5cd70-2046-412a-a2f1-ce2f1155d4fb', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 12 Mar 2025 07:43:25 GMT', 'content-type': 'application/json', 'content-length': '216', 'connection': 'keep-alive', 'x-amzn-requestid': '4bf5cd70-2046-412a-a2f1-ce2f1155d4fb'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [464]}}, id='run-e01757bd-8b2d-456d-ae30-b42a9a2dd481-0', usage_metadata={'input_tokens': 29, 'output_tokens': 19, 'total_tokens': 48})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_aws import ChatBedrockConverse\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "llm.invoke(messages, config={\"callbacks\": [langfuse_handler]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=[] additional_kwargs={} response_metadata={} id='run-7f8b34c8-dd64-4320-963c-4cb40f22477f'\n",
      "content=[{'type': 'text', 'text': '프', 'index': 0}] additional_kwargs={} response_metadata={} id='run-7f8b34c8-dd64-4320-963c-4cb40f22477f'\n",
      "content=[{'type': 'text', 'text': '로', 'index': 0}] additional_kwargs={} response_metadata={} id='run-7f8b34c8-dd64-4320-963c-4cb40f22477f'\n",
      "content=[{'type': 'text', 'text': '그', 'index': 0}] additional_kwargs={} response_metadata={} id='run-7f8b34c8-dd64-4320-963c-4cb40f22477f'\n",
      "content=[{'type': 'text', 'text': '래', 'index': 0}] additional_kwargs={} response_metadata={} id='run-7f8b34c8-dd64-4320-963c-4cb40f22477f'\n",
      "content=[{'type': 'text', 'text': '밍', 'index': 0}] additional_kwargs={} response_metadata={} id='run-7f8b34c8-dd64-4320-963c-4cb40f22477f'\n",
      "content=[{'type': 'text', 'text': '을', 'index': 0}] additional_kwargs={} response_metadata={} id='run-7f8b34c8-dd64-4320-963c-4cb40f22477f'\n",
      "content=[{'type': 'text', 'text': ' ', 'index': 0}] additional_kwargs={} response_metadata={} id='run-7f8b34c8-dd64-4320-963c-4cb40f22477f'\n",
      "content=[{'type': 'text', 'text': '좋', 'index': 0}] additional_kwargs={} response_metadata={} id='run-7f8b34c8-dd64-4320-963c-4cb40f22477f'\n",
      "content=[{'type': 'text', 'text': '아', 'index': 0}] additional_kwargs={} response_metadata={} id='run-7f8b34c8-dd64-4320-963c-4cb40f22477f'\n",
      "content=[{'type': 'text', 'text': '합', 'index': 0}] additional_kwargs={} response_metadata={} id='run-7f8b34c8-dd64-4320-963c-4cb40f22477f'\n",
      "content=[{'type': 'text', 'text': '니', 'index': 0}] additional_kwargs={} response_metadata={} id='run-7f8b34c8-dd64-4320-963c-4cb40f22477f'\n",
      "content=[{'type': 'text', 'text': '다', 'index': 0}] additional_kwargs={} response_metadata={} id='run-7f8b34c8-dd64-4320-963c-4cb40f22477f'\n",
      "content=[{'type': 'text', 'text': '.', 'index': 0}] additional_kwargs={} response_metadata={} id='run-7f8b34c8-dd64-4320-963c-4cb40f22477f'\n",
      "content=[{'index': 0}] additional_kwargs={} response_metadata={} id='run-7f8b34c8-dd64-4320-963c-4cb40f22477f'\n",
      "content=[] additional_kwargs={} response_metadata={'stopReason': 'end_turn'} id='run-7f8b34c8-dd64-4320-963c-4cb40f22477f'\n",
      "content=[] additional_kwargs={} response_metadata={'metrics': {'latencyMs': 463}} id='run-7f8b34c8-dd64-4320-963c-4cb40f22477f' usage_metadata={'input_tokens': 29, 'output_tokens': 18, 'total_tokens': 47}\n"
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(messages, config={\"callbacks\": [langfuse_handler]}):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. LangChain 의 StrOutputParser 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|프|로|그|래|밍|을| |좋|아|합|니|다|.||||"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = llm | StrOutputParser()\n",
    "\n",
    "for chunk in chain.stream(messages, config={\"callbacks\": [langfuse_handler]}):\n",
    "    print(chunk, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
