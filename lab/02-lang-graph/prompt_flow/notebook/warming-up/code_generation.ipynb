{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code generation with RAG and self-correction\n",
    "- https://langchain-ai.github.io/langgraph/tutorials/code_assistant/langgraph_code_assistant/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U langchain_community langchain-openai langchain-anthropic langchain langgraph bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bs4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/Self-Study-Generative-AI/lab/02-lang-graph/prompt_flow/notebook/warming-up/code_generation.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://5rpekozdhu6pwqt.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI/lab/02-lang-graph/prompt_flow/notebook/warming-up/code_generation.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mbs4\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m BeautifulSoup \u001b[39mas\u001b[39;00m Soup\n\u001b[1;32m      <a href='vscode-notebook-cell://5rpekozdhu6pwqt.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI/lab/02-lang-graph/prompt_flow/notebook/warming-up/code_generation.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mlangchain_community\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdocument_loaders\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrecursive_url_loader\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m RecursiveUrlLoader\n\u001b[1;32m      <a href='vscode-notebook-cell://5rpekozdhu6pwqt.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI/lab/02-lang-graph/prompt_flow/notebook/warming-up/code_generation.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# LCEL docs\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bs4'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as Soup\n",
    "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
    "\n",
    "# LCEL docs\n",
    "url = \"https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=20, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# Sort the list based on the URLs and get the text\n",
    "d_sorted = sorted(docs, key=lambda x: x.metadata[\"source\"])\n",
    "d_reversed = list(reversed(d_sorted))\n",
    "concatenated_content = \"\\n\\n\\n --- \\n\\n\\n\".join(\n",
    "    [doc.page_content for doc in d_reversed]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "### Anthropic\n",
    "\n",
    "# Prompt to enforce tool use\n",
    "code_gen_prompt_claude = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\" You are a coding assistant with expertise in LCEL, LangChain expression language. \\n \n",
    "    Here is the LCEL documentation:  \\n ------- \\n  {context} \\n ------- \\n Answer the user  question based on the \\n \n",
    "    above provided documentation. Ensure any code you provide can be executed with all required imports and variables \\n\n",
    "    defined. Structure your answer: 1) a prefix describing the code solution, 2) the imports, 3) the functioning code block. \\n\n",
    "    Invoke the code tool to structure the output correctly.  \\n Here is the user question:\"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Data model\n",
    "class code(BaseModel):\n",
    "    \"\"\"Code output\"\"\"\n",
    "\n",
    "    prefix: str = Field(description=\"Description of the problem and approach\")\n",
    "    imports: str = Field(description=\"Code block import statements\")\n",
    "    code: str = Field(description=\"Code block not including import statements\")\n",
    "    description = \"Schema for code solutions to questions about LCEL.\"\n",
    "\n",
    "\n",
    "# LLM\n",
    "# expt_llm = \"claude-3-haiku-20240307\"\n",
    "expt_llm = \"claude-3-opus-20240229\"\n",
    "llm = ChatAnthropic(\n",
    "    model=expt_llm,\n",
    "    default_headers={\"anthropic-beta\": \"tools-2024-04-04\"},\n",
    ")\n",
    "\n",
    "structured_llm_claude = llm.with_structured_output(code, include_raw=True)\n",
    "\n",
    "\n",
    "# Optional: Check for errors in case tool use is flaky\n",
    "def check_claude_output(tool_output):\n",
    "    \"\"\"Check for parse error or failure to call the tool\"\"\"\n",
    "\n",
    "    # Error with parsing\n",
    "    if tool_output[\"parsing_error\"]:\n",
    "        # Report back output and parsing errors\n",
    "        print(\"Parsing error!\")\n",
    "        raw_output = str(tool_output[\"raw\"].content)\n",
    "        error = tool_output[\"parsing_error\"]\n",
    "        raise ValueError(\n",
    "            f\"Error parsing your output! Be sure to invoke the tool. Output: {raw_output}. \\n Parse error: {error}\"\n",
    "        )\n",
    "\n",
    "    # Tool was not invoked\n",
    "    elif not tool_output[\"parsed\"]:\n",
    "        print(\"Failed to invoke tool!\")\n",
    "        raise ValueError(\n",
    "            \"You did not use the provided tool! Be sure to invoke the tool to structure the output.\"\n",
    "        )\n",
    "    return tool_output\n",
    "\n",
    "\n",
    "# Chain with output check\n",
    "code_chain_claude_raw = (\n",
    "    code_gen_prompt_claude | structured_llm_claude | check_claude_output\n",
    ")\n",
    "\n",
    "\n",
    "def insert_errors(inputs):\n",
    "    \"\"\"Insert errors for tool parsing in the messages\"\"\"\n",
    "\n",
    "    # Get errors\n",
    "    error = inputs[\"error\"]\n",
    "    messages = inputs[\"messages\"]\n",
    "    messages += [\n",
    "        (\n",
    "            \"assistant\",\n",
    "            f\"Retry. You are required to fix the parsing errors: {error} \\n\\n You must invoke the provided tool.\",\n",
    "        )\n",
    "    ]\n",
    "    return {\n",
    "        \"messages\": messages,\n",
    "        \"context\": inputs[\"context\"],\n",
    "    }\n",
    "\n",
    "\n",
    "# This will be run as a fallback chain\n",
    "fallback_chain = insert_errors | code_chain_claude_raw\n",
    "N = 3  # Max re-tries\n",
    "code_gen_chain_re_try = code_chain_claude_raw.with_fallbacks(\n",
    "    fallbacks=[fallback_chain] * N, exception_key=\"error\"\n",
    ")\n",
    "\n",
    "\n",
    "def parse_output(solution):\n",
    "    \"\"\"When we add 'include_raw=True' to structured output,\n",
    "    it will return a dict w 'raw', 'parsed', 'parsing_error'.\"\"\"\n",
    "\n",
    "    return solution[\"parsed\"]\n",
    "\n",
    "\n",
    "# Optional: With re-try to correct for failure to invoke tool\n",
    "code_gen_chain = code_gen_chain_re_try | parse_output\n",
    "\n",
    "# No re-try\n",
    "code_gen_chain = code_gen_prompt_claude | structured_llm_claude | parse_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code(prefix='Here is an example of how to build a RAG (retrieval-augmented generation) chain using LangChain Expression Language (LCEL) in Python:', imports='from langchain_core.chains import Runnerfrom langchain_requests.requests_wrapper import RequestsWrapperimport os', code='os.environ[\"OPENAI_API_KEY\"] = \"<UNKNOWN>\"\\n\\nretrieve_urls = RequestsWrapper()\\n    .asynchronous()\\n    .map(lambda query: [\\n        f\"https://api.example.com/search?q={query}\",  \\n        f\"https://api.othersource.com/search?q={query}\"\\n    ])\\n\\nrag_chain = Runner()\\n    .map(lambda query: [query, query])\\n    >> retrieve_urls \\n    >> generate_answers\\n    >> combine_answers\\n\\nresult = rag_chain.invoke(\"What is the capital of France?\")\\nprint(result)', description='Schema for code solutions to questions about LCEL.')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "question = \"How do I build a RAG chain in LCEL?\"\n",
    "solution = code_gen_chain.invoke(\n",
    "    {\"context\": concatenated_content, \"messages\": [(\"user\", question)]}\n",
    ")\n",
    "solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, TypedDict\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        error : Binary flag for control flow to indicate whether test error was tripped\n",
    "        messages : With user question, error messages, reasoning\n",
    "        generation : Code solution\n",
    "        iterations : Number of tries\n",
    "    \"\"\"\n",
    "\n",
    "    error: str\n",
    "    messages: List\n",
    "    generation: str\n",
    "    iterations: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "### Parameter\n",
    "\n",
    "# Max tries\n",
    "max_iterations = 3\n",
    "# Reflect\n",
    "# flag = 'reflect'\n",
    "flag = \"do not reflect\"\n",
    "\n",
    "### Nodes\n",
    "\n",
    "\n",
    "def generate(state: GraphState):\n",
    "    \"\"\"\n",
    "    Generate a code solution\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---GENERATING CODE SOLUTION---\")\n",
    "\n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "    error = state[\"error\"]\n",
    "\n",
    "    # We have been routed back to generation with an error\n",
    "    if error == \"yes\":\n",
    "        messages += [\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Now, try again. Invoke the code tool to structure the output with a prefix, imports, and code block:\",\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    # Solution\n",
    "    code_solution = code_gen_chain.invoke(\n",
    "        {\"context\": concatenated_content, \"messages\": messages}\n",
    "    )\n",
    "    messages += [\n",
    "        (\n",
    "            \"assistant\",\n",
    "            f\"{code_solution.prefix} \\n Imports: {code_solution.imports} \\n Code: {code_solution.code}\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Increment\n",
    "    iterations = iterations + 1\n",
    "    return {\"generation\": code_solution, \"messages\": messages, \"iterations\": iterations}\n",
    "\n",
    "\n",
    "def code_check(state: GraphState):\n",
    "    \"\"\"\n",
    "    Check code\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, error\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECKING CODE---\")\n",
    "\n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    code_solution = state[\"generation\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "\n",
    "    # Get solution components\n",
    "    imports = code_solution.imports\n",
    "    code = code_solution.code\n",
    "\n",
    "    # Check imports\n",
    "    try:\n",
    "        exec(imports)\n",
    "    except Exception as e:\n",
    "        print(\"---CODE IMPORT CHECK: FAILED---\")\n",
    "        error_message = [(\"user\", f\"Your solution failed the import test: {e}\")]\n",
    "        messages += error_message\n",
    "        return {\n",
    "            \"generation\": code_solution,\n",
    "            \"messages\": messages,\n",
    "            \"iterations\": iterations,\n",
    "            \"error\": \"yes\",\n",
    "        }\n",
    "\n",
    "    # Check execution\n",
    "    try:\n",
    "        exec(imports + \"\\n\" + code)\n",
    "    except Exception as e:\n",
    "        print(\"---CODE BLOCK CHECK: FAILED---\")\n",
    "        error_message = [(\"user\", f\"Your solution failed the code execution test: {e}\")]\n",
    "        messages += error_message\n",
    "        return {\n",
    "            \"generation\": code_solution,\n",
    "            \"messages\": messages,\n",
    "            \"iterations\": iterations,\n",
    "            \"error\": \"yes\",\n",
    "        }\n",
    "\n",
    "    # No errors\n",
    "    print(\"---NO CODE TEST FAILURES---\")\n",
    "    return {\n",
    "        \"generation\": code_solution,\n",
    "        \"messages\": messages,\n",
    "        \"iterations\": iterations,\n",
    "        \"error\": \"no\",\n",
    "    }\n",
    "\n",
    "\n",
    "def reflect(state: GraphState):\n",
    "    \"\"\"\n",
    "    Reflect on errors\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---GENERATING CODE SOLUTION---\")\n",
    "\n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "    code_solution = state[\"generation\"]\n",
    "\n",
    "    # Prompt reflection\n",
    "\n",
    "    # Add reflection\n",
    "    reflections = code_gen_chain.invoke(\n",
    "        {\"context\": concatenated_content, \"messages\": messages}\n",
    "    )\n",
    "    messages += [(\"assistant\", f\"Here are reflections on the error: {reflections}\")]\n",
    "    return {\"generation\": code_solution, \"messages\": messages, \"iterations\": iterations}\n",
    "\n",
    "\n",
    "### Edges\n",
    "\n",
    "\n",
    "def decide_to_finish(state: GraphState):\n",
    "    \"\"\"\n",
    "    Determines whether to finish.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "    error = state[\"error\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "\n",
    "    if error == \"no\" or iterations == max_iterations:\n",
    "        print(\"---DECISION: FINISH---\")\n",
    "        return \"end\"\n",
    "    else:\n",
    "        print(\"---DECISION: RE-TRY SOLUTION---\")\n",
    "        if flag == \"reflect\":\n",
    "            return \"reflect\"\n",
    "        else:\n",
    "            return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"generate\", generate)  # generation solution\n",
    "workflow.add_node(\"check_code\", code_check)  # check code\n",
    "workflow.add_node(\"reflect\", reflect)  # reflect\n",
    "\n",
    "# Build graph\n",
    "workflow.add_edge(START, \"generate\")\n",
    "workflow.add_edge(\"generate\", \"check_code\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_code\",\n",
    "    decide_to_finish,\n",
    "    {\n",
    "        \"end\": END,\n",
    "        \"reflect\": \"reflect\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"reflect\", \"generate\")\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---GENERATING CODE SOLUTION---\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'error'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/Self-Study-Generative-AI-1/lang-graph/warming-up/code_generation.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://emvxzuxmduvgmyg.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI-1/lang-graph/warming-up/code_generation.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m question \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mHow can I directly pass a string to a runnable and use it to construct the input needed for my prompt?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://emvxzuxmduvgmyg.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI-1/lang-graph/warming-up/code_generation.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m app\u001b[39m.\u001b[39;49minvoke({\u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: [(\u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, question)], \u001b[39m\"\u001b[39;49m\u001b[39miterations\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m0\u001b[39;49m})\n",
      "File \u001b[0;32m~/Self-Study-Generative-AI-1/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1617\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1615\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1616\u001b[0m     chunks \u001b[39m=\u001b[39m []\n\u001b[0;32m-> 1617\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream(\n\u001b[1;32m   1618\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[1;32m   1619\u001b[0m     config,\n\u001b[1;32m   1620\u001b[0m     stream_mode\u001b[39m=\u001b[39mstream_mode,\n\u001b[1;32m   1621\u001b[0m     output_keys\u001b[39m=\u001b[39moutput_keys,\n\u001b[1;32m   1622\u001b[0m     interrupt_before\u001b[39m=\u001b[39minterrupt_before,\n\u001b[1;32m   1623\u001b[0m     interrupt_after\u001b[39m=\u001b[39minterrupt_after,\n\u001b[1;32m   1624\u001b[0m     debug\u001b[39m=\u001b[39mdebug,\n\u001b[1;32m   1625\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1626\u001b[0m ):\n\u001b[1;32m   1627\u001b[0m     \u001b[39mif\u001b[39;00m stream_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvalues\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1628\u001b[0m         latest \u001b[39m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/Self-Study-Generative-AI-1/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1303\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1300\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1302\u001b[0m \u001b[39m# panic on failure or timeout\u001b[39;00m\n\u001b[0;32m-> 1303\u001b[0m _panic_or_proceed(all_futures, loop\u001b[39m.\u001b[39;49mstep)\n\u001b[1;32m   1304\u001b[0m \u001b[39m# don't keep futures around in memory longer than needed\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m \u001b[39mdel\u001b[39;00m done, inflight, futures\n",
      "File \u001b[0;32m~/Self-Study-Generative-AI-1/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1733\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[0;34m(futs, step, timeout_exc_cls)\u001b[0m\n\u001b[1;32m   1731\u001b[0m             inflight\u001b[39m.\u001b[39mpop()\u001b[39m.\u001b[39mcancel()\n\u001b[1;32m   1732\u001b[0m         \u001b[39m# raise the exception\u001b[39;00m\n\u001b[0;32m-> 1733\u001b[0m         \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m   1735\u001b[0m \u001b[39mif\u001b[39;00m inflight:\n\u001b[1;32m   1736\u001b[0m     \u001b[39m# if we got here means we timed out\u001b[39;00m\n\u001b[1;32m   1737\u001b[0m     \u001b[39mwhile\u001b[39;00m inflight:\n\u001b[1;32m   1738\u001b[0m         \u001b[39m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[0;32m~/Self-Study-Generative-AI-1/.venv/lib/python3.10/site-packages/langgraph/pregel/executor.py:59\u001b[0m, in \u001b[0;36mBackgroundExecutor.done\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdone\u001b[39m(\u001b[39mself\u001b[39m, task: concurrent\u001b[39m.\u001b[39mfutures\u001b[39m.\u001b[39mFuture) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m         task\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m     60\u001b[0m     \u001b[39mexcept\u001b[39;00m GraphInterrupt:\n\u001b[1;32m     61\u001b[0m         \u001b[39m# This exception is an interruption signal, not an error\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[39m# so we don't want to re-raise it on exit\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtasks\u001b[39m.\u001b[39mpop(task)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/Self-Study-Generative-AI-1/.venv/lib/python3.10/site-packages/langgraph/pregel/retry.py:26\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     24\u001b[0m task\u001b[39m.\u001b[39mwrites\u001b[39m.\u001b[39mclear()\n\u001b[1;32m     25\u001b[0m \u001b[39m# run the task\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m task\u001b[39m.\u001b[39;49mproc\u001b[39m.\u001b[39;49minvoke(task\u001b[39m.\u001b[39;49minput, task\u001b[39m.\u001b[39;49mconfig)\n\u001b[1;32m     27\u001b[0m \u001b[39m# if successful, end\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Self-Study-Generative-AI-1/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2876\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2874\u001b[0m context\u001b[39m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m   2875\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2876\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39;49mrun(step\u001b[39m.\u001b[39;49minvoke, \u001b[39minput\u001b[39;49m, config, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2877\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2878\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39mrun(step\u001b[39m.\u001b[39minvoke, \u001b[39minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Self-Study-Generative-AI-1/.venv/lib/python3.10/site-packages/langgraph/utils.py:102\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[39mif\u001b[39;00m accepts_config(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc):\n\u001b[1;32m    101\u001b[0m         kwargs[\u001b[39m\"\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m config\n\u001b[0;32m--> 102\u001b[0m     ret \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc, \u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    103\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ret, Runnable) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecurse:\n\u001b[1;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39minvoke(\u001b[39minput\u001b[39m, config)\n",
      "\u001b[1;32m/home/sagemaker-user/Self-Study-Generative-AI-1/lang-graph/warming-up/code_generation.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://emvxzuxmduvgmyg.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI-1/lang-graph/warming-up/code_generation.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m messages \u001b[39m=\u001b[39m state[\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://emvxzuxmduvgmyg.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI-1/lang-graph/warming-up/code_generation.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m iterations \u001b[39m=\u001b[39m state[\u001b[39m\"\u001b[39m\u001b[39miterations\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://emvxzuxmduvgmyg.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI-1/lang-graph/warming-up/code_generation.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m error \u001b[39m=\u001b[39m state[\u001b[39m\"\u001b[39;49m\u001b[39merror\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell://emvxzuxmduvgmyg.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI-1/lang-graph/warming-up/code_generation.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# We have been routed back to generation with an error\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://emvxzuxmduvgmyg.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI-1/lang-graph/warming-up/code_generation.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mif\u001b[39;00m error \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39myes\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'error'"
     ]
    }
   ],
   "source": [
    "question = \"How can I directly pass a string to a runnable and use it to construct the input needed for my prompt?\"\n",
    "app.invoke({\"messages\": [(\"user\", question)], \"iterations\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph Tutorial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langsmith\n",
    "\n",
    "client = langsmith.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(name='lcel-teacher-eval', description='Eval set for LCEL teacher', data_type=<DataType.kv: 'kv'>, id=UUID('87adbb31-1350-4adb-831c-3940a4c1dbc9'), created_at=datetime.datetime(2024, 9, 3, 14, 26, 0, 386454, tzinfo=datetime.timezone.utc), modified_at=datetime.datetime(2024, 9, 3, 14, 26, 0, 386454, tzinfo=datetime.timezone.utc), example_count=0, session_count=0, last_session_start_time=None, inputs_schema=None, outputs_schema=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clone the dataset to your tenant to use it\n",
    "public_dataset = (\n",
    "    \"https://smith.langchain.com/public/326674a6-62bd-462d-88ae-eea49d503f9d/d\"\n",
    ")\n",
    "client.clone_public_dataset(public_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.schemas import Example, Run\n",
    "\n",
    "\n",
    "def check_import(run: Run, example: Example) -> dict:\n",
    "    imports = run.outputs.get(\"imports\")\n",
    "    try:\n",
    "        exec(imports)\n",
    "        return {\"key\": \"import_check\", \"score\": 1}\n",
    "    except Exception:\n",
    "        return {\"key\": \"import_check\", \"score\": 0}\n",
    "\n",
    "\n",
    "def check_execution(run: Run, example: Example) -> dict:\n",
    "    imports = run.outputs.get(\"imports\")\n",
    "    code = run.outputs.get(\"code\")\n",
    "    try:\n",
    "        exec(imports + \"\\n\" + code)\n",
    "        return {\"key\": \"code_execution_check\", \"score\": 1}\n",
    "    except Exception:\n",
    "        return {\"key\": \"code_execution_check\", \"score\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_base_case(example: dict):\n",
    "    \"\"\"Context stuffing\"\"\"\n",
    "    solution = code_gen_chain.invoke(\n",
    "        {\"context\": concatenated_content, \"messages\": [(\"user\", example[\"question\"])]}\n",
    "    )\n",
    "    solution_structured = code_gen_chain.invoke([(\"code\", solution)])\n",
    "    return {\"imports\": solution_structured.imports, \"code\": solution_structured.code}\n",
    "\n",
    "\n",
    "def predict_langgraph(example: dict):\n",
    "    \"\"\"LangGraph\"\"\"\n",
    "    graph = app.invoke({\"messages\": [(\"user\", example[\"question\"])], \"iterations\": 0})\n",
    "    solution = graph[\"generation\"]\n",
    "    return {\"imports\": solution.imports, \"code\": solution.code}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# Evaluator\n",
    "code_evalulator = [check_import, check_execution]\n",
    "\n",
    "# Dataset\n",
    "dataset_name = \"test-LCEL-code-gen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "LangSmithNotFoundError",
     "evalue": "Dataset test-LCEL-code-gen not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLangSmithNotFoundError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/Self-Study-Generative-AI-1/lang-graph/warming-up/code_generation.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://emvxzuxmduvgmyg.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI-1/lang-graph/warming-up/code_generation.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Run base case\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://emvxzuxmduvgmyg.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI-1/lang-graph/warming-up/code_generation.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m experiment_results_ \u001b[39m=\u001b[39m evaluate(\n\u001b[1;32m      <a href='vscode-notebook-cell://emvxzuxmduvgmyg.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI-1/lang-graph/warming-up/code_generation.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     predict_base_case,\n\u001b[1;32m      <a href='vscode-notebook-cell://emvxzuxmduvgmyg.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI-1/lang-graph/warming-up/code_generation.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     data\u001b[39m=\u001b[39;49mdataset_name,\n\u001b[1;32m      <a href='vscode-notebook-cell://emvxzuxmduvgmyg.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI-1/lang-graph/warming-up/code_generation.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     evaluators\u001b[39m=\u001b[39;49mcode_evalulator,\n\u001b[1;32m      <a href='vscode-notebook-cell://emvxzuxmduvgmyg.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI-1/lang-graph/warming-up/code_generation.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     experiment_prefix\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtest-without-langgraph-\u001b[39;49m\u001b[39m{\u001b[39;49;00mexpt_llm\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://emvxzuxmduvgmyg.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI-1/lang-graph/warming-up/code_generation.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     max_concurrency\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://emvxzuxmduvgmyg.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI-1/lang-graph/warming-up/code_generation.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     metadata\u001b[39m=\u001b[39;49m{\n\u001b[1;32m      <a href='vscode-notebook-cell://emvxzuxmduvgmyg.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI-1/lang-graph/warming-up/code_generation.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mllm\u001b[39;49m\u001b[39m\"\u001b[39;49m: expt_llm,\n\u001b[1;32m     <a href='vscode-notebook-cell://emvxzuxmduvgmyg.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI-1/lang-graph/warming-up/code_generation.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     },\n\u001b[1;32m     <a href='vscode-notebook-cell://emvxzuxmduvgmyg.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI-1/lang-graph/warming-up/code_generation.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Self-Study-Generative-AI-1/.venv/lib/python3.10/site-packages/langsmith/evaluation/_runner.py:251\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\n\u001b[1;32m     86\u001b[0m     target: TARGET_T,\n\u001b[1;32m     87\u001b[0m     \u001b[39m/\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m     blocking: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     98\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ExperimentResults:\n\u001b[1;32m     99\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Evaluate a target system or function on a given dataset.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39m        View the evaluation results for experiment:...\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mreturn\u001b[39;00m _evaluate(\n\u001b[1;32m    252\u001b[0m         target,\n\u001b[1;32m    253\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    254\u001b[0m         evaluators\u001b[39m=\u001b[39;49mevaluators,\n\u001b[1;32m    255\u001b[0m         summary_evaluators\u001b[39m=\u001b[39;49msummary_evaluators,\n\u001b[1;32m    256\u001b[0m         metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m    257\u001b[0m         experiment_prefix\u001b[39m=\u001b[39;49mexperiment_prefix,\n\u001b[1;32m    258\u001b[0m         description\u001b[39m=\u001b[39;49mdescription,\n\u001b[1;32m    259\u001b[0m         max_concurrency\u001b[39m=\u001b[39;49mmax_concurrency,\n\u001b[1;32m    260\u001b[0m         num_repetitions\u001b[39m=\u001b[39;49mnum_repetitions,\n\u001b[1;32m    261\u001b[0m         client\u001b[39m=\u001b[39;49mclient,\n\u001b[1;32m    262\u001b[0m         blocking\u001b[39m=\u001b[39;49mblocking,\n\u001b[1;32m    263\u001b[0m     )\n",
      "File \u001b[0;32m~/Self-Study-Generative-AI-1/.venv/lib/python3.10/site-packages/langsmith/evaluation/_runner.py:861\u001b[0m, in \u001b[0;36m_evaluate\u001b[0;34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment)\u001b[0m\n\u001b[1;32m    844\u001b[0m runs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m _is_callable(target) \u001b[39melse\u001b[39;00m cast(Iterable[schemas\u001b[39m.\u001b[39mRun], target)\n\u001b[1;32m    845\u001b[0m experiment_, runs \u001b[39m=\u001b[39m _resolve_experiment(\n\u001b[1;32m    846\u001b[0m     experiment,\n\u001b[1;32m    847\u001b[0m     runs,\n\u001b[1;32m    848\u001b[0m     client,\n\u001b[1;32m    849\u001b[0m )\n\u001b[1;32m    851\u001b[0m manager \u001b[39m=\u001b[39m _ExperimentManager(\n\u001b[1;32m    852\u001b[0m     data,\n\u001b[1;32m    853\u001b[0m     client\u001b[39m=\u001b[39;49mclient,\n\u001b[1;32m    854\u001b[0m     metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m    855\u001b[0m     experiment\u001b[39m=\u001b[39;49mexperiment_ \u001b[39mor\u001b[39;49;00m experiment_prefix,\n\u001b[1;32m    856\u001b[0m     description\u001b[39m=\u001b[39;49mdescription,\n\u001b[1;32m    857\u001b[0m     num_repetitions\u001b[39m=\u001b[39;49mnum_repetitions,\n\u001b[1;32m    858\u001b[0m     \u001b[39m# If provided, we don't need to create a new experiment.\u001b[39;49;00m\n\u001b[1;32m    859\u001b[0m     runs\u001b[39m=\u001b[39;49mruns,\n\u001b[1;32m    860\u001b[0m     \u001b[39m# Create or resolve the experiment.\u001b[39;49;00m\n\u001b[0;32m--> 861\u001b[0m )\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m    862\u001b[0m cache_dir \u001b[39m=\u001b[39m ls_utils\u001b[39m.\u001b[39mget_cache_dir(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    863\u001b[0m cache_path \u001b[39m=\u001b[39m (\n\u001b[1;32m    864\u001b[0m     pathlib\u001b[39m.\u001b[39mPath(cache_dir) \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmanager\u001b[39m.\u001b[39mdataset_id\u001b[39m}\u001b[39;00m\u001b[39m.yaml\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m cache_dir \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    865\u001b[0m )\n",
      "File \u001b[0;32m~/Self-Study-Generative-AI-1/.venv/lib/python3.10/site-packages/langsmith/evaluation/_runner.py:1154\u001b[0m, in \u001b[0;36m_ExperimentManager.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstart\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m _ExperimentManager:\n\u001b[0;32m-> 1154\u001b[0m     first_example \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexamples, \u001b[39m1\u001b[39;49m))\n\u001b[1;32m   1155\u001b[0m     project \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_project(first_example)\n\u001b[1;32m   1156\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_print_experiment_start(project, first_example)\n",
      "File \u001b[0;32m~/Self-Study-Generative-AI-1/.venv/lib/python3.10/site-packages/langsmith/client.py:3393\u001b[0m, in \u001b[0;36mClient.list_examples\u001b[0;34m(self, dataset_id, dataset_name, example_ids, as_of, splits, inline_s3_urls, offset, limit, metadata, filter, **kwargs)\u001b[0m\n\u001b[1;32m   3391\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataset_id\n\u001b[1;32m   3392\u001b[0m \u001b[39melif\u001b[39;00m dataset_name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 3393\u001b[0m     dataset_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_dataset(dataset_name\u001b[39m=\u001b[39;49mdataset_name)\u001b[39m.\u001b[39mid\n\u001b[1;32m   3394\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataset_id\n\u001b[1;32m   3395\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Self-Study-Generative-AI-1/.venv/lib/python3.10/site-packages/langsmith/utils.py:131\u001b[0m, in \u001b[0;36mxor_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     invalid_group_names \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(arg_groups[i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m invalid_groups]\n\u001b[1;32m    126\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    127\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExactly one argument in each of the following\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    128\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m groups must be defined:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    129\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(invalid_group_names)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m     )\n\u001b[0;32m--> 131\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Self-Study-Generative-AI-1/.venv/lib/python3.10/site-packages/langsmith/client.py:2620\u001b[0m, in \u001b[0;36mClient.read_dataset\u001b[0;34m(self, dataset_name, dataset_id)\u001b[0m\n\u001b[1;32m   2618\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mlist\u001b[39m):\n\u001b[1;32m   2619\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(result) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2620\u001b[0m         \u001b[39mraise\u001b[39;00m ls_utils\u001b[39m.\u001b[39mLangSmithNotFoundError(\n\u001b[1;32m   2621\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataset \u001b[39m\u001b[39m{\u001b[39;00mdataset_name\u001b[39m}\u001b[39;00m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2622\u001b[0m         )\n\u001b[1;32m   2623\u001b[0m     \u001b[39mreturn\u001b[39;00m ls_schemas\u001b[39m.\u001b[39mDataset(\n\u001b[1;32m   2624\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresult[\u001b[39m0\u001b[39m],\n\u001b[1;32m   2625\u001b[0m         _host_url\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_host_url,\n\u001b[1;32m   2626\u001b[0m         _tenant_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_optional_tenant_id(),\n\u001b[1;32m   2627\u001b[0m     )\n\u001b[1;32m   2628\u001b[0m \u001b[39mreturn\u001b[39;00m ls_schemas\u001b[39m.\u001b[39mDataset(\n\u001b[1;32m   2629\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresult,\n\u001b[1;32m   2630\u001b[0m     _host_url\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_host_url,\n\u001b[1;32m   2631\u001b[0m     _tenant_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_optional_tenant_id(),\n\u001b[1;32m   2632\u001b[0m )\n",
      "\u001b[0;31mLangSmithNotFoundError\u001b[0m: Dataset test-LCEL-code-gen not found"
     ]
    }
   ],
   "source": [
    "# Run base case\n",
    "experiment_results_ = evaluate(\n",
    "    predict_base_case,\n",
    "    data=dataset_name,\n",
    "    evaluators=code_evalulator,\n",
    "    experiment_prefix=f\"test-without-langgraph-{expt_llm}\",\n",
    "    max_concurrency=2,\n",
    "    metadata={\n",
    "        \"llm\": expt_llm,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
