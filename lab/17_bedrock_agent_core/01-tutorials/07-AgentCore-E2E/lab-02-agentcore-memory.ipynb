{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2: Personalize our agent by adding memory\n",
    "\n",
    "### Overview\n",
    "\n",
    "In Lab 1, you built a Customer Support Agent that worked well for a single user in a local session. However, real-world customer support needs to scale beyond a single user running in a local environment.\n",
    "\n",
    "When we run an **Agent in Production**, we'll need:\n",
    "- **Multi-User Support**: Handle thousands of customers simultaneously\n",
    "- **Persistent Storage**: Save conversations beyond session lifecycle\n",
    "- **Long-Term Learning**: Extract customer preferences and behavioral patterns\n",
    "- **Cross-Session Continuity**: Remember customers across different interactions\n",
    "\n",
    "**Workshop Progress:**\n",
    "- **Lab 1 (Done)**: Create Agent Prototype - Build a functional customer support agent\n",
    "- **Lab 2 (Current)**: Enhance with Memory - Add conversation context and personalization\n",
    "- **Lab 3**: Scale with Gateway & Identity - Share tools across agents securely\n",
    "- **Lab 4**: Deploy to Production - Use AgentCore Runtime with observability\n",
    "- **Lab 5**: Build User Interface - Create a customer-facing application\n",
    "\n",
    "\n",
    "In this lab, you'll add the missing persistence and learning layer that transforms your Goldfish-Agent (forgets the conversation in seconds) into an smart personalized Assistant.\n",
    "\n",
    "Memory is a critical component of intelligence. While Large Language Models (LLMs) have impressive capabilities, they lack persistent memory across conversations. [Amazon Bedrock AgentCore Memory](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/memory-getting-started.html) addresses this limitation by providing a managed service that enables AI agents to maintain context over time, remember important facts, and deliver consistent, personalized experiences.\n",
    "\n",
    "AgentCore Memory operates on two levels:\n",
    "- **Short-Term Memory**: Immediate conversation context and session-based information that provides continuity within a single interaction or closely related sessions.\n",
    "- **Long-Term Memory**: Persistent information extracted and stored across multiple conversations, including facts, preferences, and summaries that enable personalized experiences over time.\n",
    "\n",
    "### Architecture for Lab 2\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture_lab2_memory.png\" width=\"75%\"/>\n",
    "</div>\n",
    "\n",
    "*Multi-user agent with persistent short term and long term memory capabilities. *\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "* **AWS Account** with appropriate permissions\n",
    "* **Python 3.10+** installed locally\n",
    "* **AWS CLI configured** with credentials\n",
    "* **Anthropic Claude 3.7** enabled on [Amazon Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html)\n",
    "* **Strands Agents** and other libraries installed in the next cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries\n",
    "\n",
    "Let's import the libraries for AgentCore Memory. For it, we will use the [Amazon Bedrock AgentCore Python SDK](https://github.com/aws/bedrock-agentcore-sdk-python), a lightweight wrapper that helps you working with AgentCore capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Import agentCore Memory\n",
    "from bedrock_agentcore.memory import MemoryClient\n",
    "from bedrock_agentcore.memory.constants import StrategyType\n",
    "\n",
    "from strands.hooks import AfterInvocationEvent, HookProvider, HookRegistry, MessageAddedEvent\n",
    "\n",
    "import boto3\n",
    "from boto3.session import Session\n",
    "\n",
    "boto_session = Session()\n",
    "REGION = boto_session.region_name\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from lab_helpers.utils import get_ssm_parameter, put_ssm_parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create Bedrock AgentCore Memory resources\n",
    "\n",
    "Amazon Bedrock AgentCore Memory provides multiple long-term memory strategies. We create a memory resource combining:\n",
    "\n",
    "- **USER_PREFERENCE**: Extracts customer preferences and behaviors\n",
    "- **SEMANTIC**: Stores factual information using vector embeddings\n",
    "\n",
    "AgentCore Memory uses namespaces to logically group long-term memory messages. Every time a new long-term memory is extracted using this memory strategy, it is saved under the namespace you set. We use the follwing namespaces using the `actorId` to group messaging of the same customer together:\n",
    "\n",
    "- `support/customer/{actorId}/preferences`: for the user preference memory strategy\n",
    "- `support/customer/{actorId}/semantic`: for the semantic memory strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_client = MemoryClient(region_name=REGION)\n",
    "memory_name = \"CustomerSupportMemory\"\n",
    "\n",
    "def create_or_get_memory_resource():\n",
    "    try:\n",
    "        memory_id = get_ssm_parameter(\"/app/customersupport/agentcore/memory_id\")\n",
    "        memory_client.gmcp_client.get_memory(memoryId=memory_id)\n",
    "        return memory_id\n",
    "    except:\n",
    "        try:\n",
    "            strategies = [\n",
    "                {\n",
    "                    StrategyType.USER_PREFERENCE.value: {\n",
    "                        \"name\": \"CustomerPreferences\",\n",
    "                        \"description\": \"Captures customer preferences and behavior\",\n",
    "                        \"namespaces\": [\"support/customer/{actorId}/preferences\"],\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    StrategyType.SEMANTIC.value: {\n",
    "                        \"name\": \"CustomerSupportSemantic\",\n",
    "                        \"description\": \"Stores facts from conversations\",\n",
    "                        \"namespaces\": [\"support/customer/{actorId}/semantic\"],\n",
    "                    }\n",
    "                },\n",
    "            ]\n",
    "            print(\"Creating AgentCore Memory resources. This can a couple of minutes..\")\n",
    "            # *** AGENTCORE MEMORY USAGE *** - Create memory resource with semantic strategy\n",
    "            response = memory_client.create_memory_and_wait(\n",
    "                name=memory_name,\n",
    "                description=\"Customer support agent memory\",\n",
    "                strategies=strategies,\n",
    "                event_expiry_days=90,          # Memories expire after 90 days\n",
    "            )\n",
    "            memory_id = response[\"id\"]\n",
    "            try:\n",
    "                put_ssm_parameter(\"/app/customersupport/agentcore/memory_id\", memory_id)\n",
    "            except:\n",
    "                raise\n",
    "            return memory_id\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentCore Memory created successfully\n"
     ]
    }
   ],
   "source": [
    "memory_id = create_or_get_memory_resource()\n",
    "print(\"AgentCore Memory created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Seed previous customer \n",
    "\n",
    "The `create_event` action stores agent interactions into short-term memory instantly. Each saved interaction can include user messages, assistant responses, and tool actions. The process is synchronous, ensuring no conversation data is lost.\n",
    "\n",
    "Short-term memory messages are then asynchronously processed according to the chosen long-term memory strategy.\n",
    "\n",
    "Let's load some previously customer interactions providing the customer id as `actor_id` and a `session_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Arn: arn:aws:bedrock-agentcore:us-east-1:057716757052:memory/CustomerSupportMemory-EtWANNBq0n\n",
      "Memory ID: CustomerSupportMemory-EtWANNBq0n\n",
      "--------------------------------------------------------------------\n",
      "âœ… Seeded customer history\n"
     ]
    }
   ],
   "source": [
    "# List existing memory resources\n",
    "for memory in memory_client.list_memories():\n",
    "    print(f\"Memory Arn: {memory.get('arn')}\")\n",
    "    print(f\"Memory ID: {memory.get('id')}\")\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "\n",
    "# Seed with previous customer interactions\n",
    "# CUSTOMER_ID = \"customer_001\"\n",
    "CUSTOMER_ID = \"customer_002\"\n",
    "\n",
    "# previous_interactions = [\n",
    "#     (\"I'm having issues with my MacBook Pro overheating during video editing.\",\"USER\"),\n",
    "#     (\"I can help with that thermal issue. For video editing workloads, let's check your Activity Monitor and adjust performance settings. Your MacBook Pro order #MB-78432 is still under warranty.\", \"ASSISTANT\"),\n",
    "#     (\"What's the return policy on gaming headphones? I need low latency for competitive FPS games\", \"USER\"),\n",
    "#     (\"For gaming headphones, you have 30 days to return. Since you're into competitive FPS, I'd recommend checking the audio latency specs - most gaming models have <40ms latency.\", \"ASSISTANT\"),\n",
    "#     (\"I need a laptop under $1200 for programming. Prefer 16GB RAM minimum and good Linux compatibility. I like ThinkPad models.\", \"USER\"),\n",
    "#     (\"Perfect! For development work, I'd suggest looking at our ThinkPad E series or Dell XPS models. Both have excellent Linux support and 16GB RAM options within your budget.\", \"ASSISTANT\"),\n",
    "# ]\n",
    "previous_interactions = [\n",
    "    (\"ë¹„ë””ì˜¤ í¸ì§‘í•  ë•Œ MacBook Proê°€ ê³¼ì—´ë˜ëŠ” ë¬¸ì œê°€ ìˆì–´ìš”.\", \"USER\"),\n",
    "    (\"ê·¸ ì—´ ë¬¸ì œë¥¼ ë„ì™€ë“œë¦´ê²Œìš”. ë¹„ë””ì˜¤ í¸ì§‘ ì‘ì—…ëŸ‰ì— ëŒ€í•´ Activity Monitorë¥¼ í™•ì¸í•˜ê³  ì„±ëŠ¥ ì„¤ì •ì„ ì¡°ì •í•´ë³´ê² ìŠµë‹ˆë‹¤. ê·€í•˜ì˜ MacBook Pro ì£¼ë¬¸ë²ˆí˜¸ #MB-78432ëŠ” ì•„ì§ ë³´ì¦ ê¸°ê°„ ë‚´ì…ë‹ˆë‹¤.\", \"ASSISTANT\"),\n",
    "    (\"ê²Œì´ë° í—¤ë“œí°ì˜ ë°˜í’ˆ ì •ì±…ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”? ê²½ìŸì ì¸ FPS ê²Œì„ì„ ìœ„í•´ ë‚®ì€ ì§€ì—°ì‹œê°„ì´ í•„ìš”í•´ìš”\", \"USER\"),\n",
    "    (\"ê²Œì´ë° í—¤ë“œí°ì€ 30ì¼ ì´ë‚´ì— ë°˜í’ˆ ê°€ëŠ¥í•©ë‹ˆë‹¤. ê²½ìŸì ì¸ FPS ê²Œì„ì„ í•˜ì‹ ë‹¤ë©´ ì˜¤ë””ì˜¤ ì§€ì—°ì‹œê°„ ì‚¬ì–‘ì„ í™•ì¸í•´ë³´ì„¸ìš” - ëŒ€ë¶€ë¶„ì˜ ê²Œì´ë° ëª¨ë¸ì€ <40ms ì§€ì—°ì‹œê°„ì„ ê°€ì§‘ë‹ˆë‹¤.\", \"ASSISTANT\"),\n",
    "    (\"í”„ë¡œê·¸ë˜ë°ìš© ë…¸íŠ¸ë¶ì„ $1200 ì´í•˜ë¡œ êµ¬ë§¤í•˜ê³  ì‹¶ì–´ìš”. ìµœì†Œ 16GB RAMê³¼ ì¢‹ì€ Linux í˜¸í™˜ì„±ì„ ì›í•´ìš”. ThinkPad ëª¨ë¸ì„ ì„ í˜¸í•©ë‹ˆë‹¤.\", \"USER\"),\n",
    "    (\"ì™„ë²½í•´ìš”! ê°œë°œ ì‘ì—…ì„ ìœ„í•´ ThinkPad E ì‹œë¦¬ì¦ˆë‚˜ Dell XPS ëª¨ë¸ì„ ì¶”ì²œí•©ë‹ˆë‹¤. ë‘˜ ë‹¤ í›Œë¥­í•œ Linux ì§€ì›ê³¼ ì˜ˆì‚° ë‚´ì—ì„œ 16GB RAM ì˜µì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.\", \"ASSISTANT\"),\n",
    "]\n",
    "\n",
    "# Save previous interactions\n",
    "try:\n",
    "    memory_client.create_event(\n",
    "        memory_id=memory_id,\n",
    "        actor_id=CUSTOMER_ID,\n",
    "        session_id=\"previous_session\",\n",
    "        messages=previous_interactions\n",
    "    )\n",
    "    print(\"âœ… Seeded customer history\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Error seeding history: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you create an event via `create_event`, messages are sent to short-term memory and further asynchronously sent to [Long Term memory](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/long-term-memory.html).\n",
    "It takes about 30 seconds to propogate the information to Long-Term Memory.\n",
    "\n",
    "### Visualize preferences memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(20) # To give some time for memory propogation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1. {\"context\":\"User explicitly stated requirements for programming laptop purchase\",\"preference\":\"Wants a laptop under $1200 with 16GB RAM, good Linux compatibility, and preferring ThinkPad models\",\"categories\":[\"technology\",\"computers\",\"programming\",\"hardware\"]}\n",
      "  2. {\"context\":\"User mentioned competitive FPS gaming and need for low latency gaming headphones\",\"preference\":\"Requires gaming headphones with low audio latency (<40ms) for competitive FPS gaming\",\"categories\":[\"gaming\",\"audio equipment\",\"technology\"]}\n"
     ]
    }
   ],
   "source": [
    "memories = memory_client.retrieve_memories(\n",
    "    memory_id=memory_id,\n",
    "    namespace=f\"support/customer/{CUSTOMER_ID}/preferences\",\n",
    "    # query=\"can you summarize the support issue\"\n",
    "    query=\"ë„ˆ support ë¬¸ì œ ìš”ì•½í•´ì¤˜\"\n",
    ")\n",
    "\n",
    "for i, memory in enumerate(memories, 1):\n",
    "    if isinstance(memory, dict):\n",
    "        content = memory.get('content', {})\n",
    "        if isinstance(content, dict):\n",
    "            text = content.get('text', '')\n",
    "            print(f\"  {i}. {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at Semantic memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1. The user is experiencing overheating issues with a MacBook Pro when editing videos.\n",
      "  2. The user wants to purchase a programming laptop for under $1200 with at least 16GB RAM and good Linux compatibility, preferring ThinkPad models.\n",
      "  3. The user plays competitive FPS games and requires gaming headphones with low latency.\n"
     ]
    }
   ],
   "source": [
    "memories = memory_client.retrieve_memories(\n",
    "    memory_id=memory_id,\n",
    "    namespace=f\"support/customer/{CUSTOMER_ID}/semantic\",\n",
    "    # query=\"can you summarize the support issue\"\n",
    "    query=\"ë„ˆ support ë¬¸ì œ ìš”ì•½í•´ì¤˜\"\n",
    ")    \n",
    "\n",
    "for i, memory in enumerate(memories, 1):\n",
    "    if isinstance(memory, dict):\n",
    "        content = memory.get('content', {})\n",
    "        if isinstance(content, dict):\n",
    "            text = content.get('text', '')\n",
    "            print(f\"  {i}. {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Implement Strands Hooks to save and retrieve agent interactions\n",
    "\n",
    "Strands Agents provides a powerful hook system that enables components to react to or modify agent behavior through strongly-typed event callbacks. We'll use two key hook events:\n",
    "\n",
    "- **MessageAddedEvent**: Triggered when messages are added to the conversation, allowing us to retrieve and inject customer context\n",
    "- **AfterInvocationEvent**: Fired after agent responses, enabling automatic storage of interactions to memory\n",
    "\n",
    "The hook system ensures memory operations happen automatically without manual intervention, creating a seamless experience where customer context is preserved across conversations.\n",
    "\n",
    "To create the hooks we will extend the `HookProvider` class:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerSupportMemoryHooks(HookProvider):\n",
    "    \"\"\"Memory hooks for customer support agent\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, memory_id: str, client: MemoryClient, actor_id: str, session_id: str\n",
    "    ):\n",
    "        self.memory_id = memory_id\n",
    "        self.client = client\n",
    "        self.actor_id = actor_id\n",
    "        self.session_id = session_id\n",
    "        self.namespaces = {\n",
    "            i[\"type\"]: i[\"namespaces\"][0]\n",
    "            for i in self.client.get_memory_strategies(self.memory_id)\n",
    "        }\n",
    "\n",
    "    def retrieve_customer_context(self, event: MessageAddedEvent):\n",
    "        \"\"\"Retrieve customer context before processing support query\"\"\"\n",
    "        messages = event.agent.messages\n",
    "        if (\n",
    "            messages[-1][\"role\"] == \"user\"\n",
    "            and \"toolResult\" not in messages[-1][\"content\"][0]\n",
    "        ):\n",
    "            user_query = messages[-1][\"content\"][0][\"text\"]\n",
    "\n",
    "            try:\n",
    "                all_context = []\n",
    "\n",
    "                for context_type, namespace in self.namespaces.items():\n",
    "                    # *** AGENTCORE MEMORY USAGE *** - Retrieve customer context from each namespace\n",
    "                    memories = self.client.retrieve_memories(\n",
    "                        memory_id=self.memory_id,\n",
    "                        namespace=namespace.format(actorId=self.actor_id),\n",
    "                        query=user_query,\n",
    "                        top_k=3,\n",
    "                    )\n",
    "                    # Post-processing: Format memories into context strings\n",
    "                    for memory in memories:\n",
    "                        if isinstance(memory, dict):\n",
    "                            content = memory.get(\"content\", {})\n",
    "                            if isinstance(content, dict):\n",
    "                                text = content.get(\"text\", \"\").strip()\n",
    "                                if text:\n",
    "                                    all_context.append(\n",
    "                                        f\"[{context_type.upper()}] {text}\"\n",
    "                                    )\n",
    "\n",
    "                # Inject customer context into the query\n",
    "                if all_context:\n",
    "                    context_text = \"\\n\".join(all_context)\n",
    "                    original_text = messages[-1][\"content\"][0][\"text\"]\n",
    "                    messages[-1][\"content\"][0][\n",
    "                        \"text\"\n",
    "                    ] = f\"Customer Context:\\n{context_text}\\n\\n{original_text}\"\n",
    "                    logger.info(f\"Retrieved {len(all_context)} customer context items\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to retrieve customer context: {e}\")\n",
    "\n",
    "    def save_support_interaction(self, event: AfterInvocationEvent):\n",
    "        \"\"\"Save customer support interaction after agent response\"\"\"\n",
    "        try:\n",
    "            messages = event.agent.messages\n",
    "            if len(messages) >= 2 and messages[-1][\"role\"] == \"assistant\":\n",
    "                # Get last customer query and agent response\n",
    "                customer_query = None\n",
    "                agent_response = None\n",
    "\n",
    "                for msg in reversed(messages):\n",
    "                    if msg[\"role\"] == \"assistant\" and not agent_response:\n",
    "                        agent_response = msg[\"content\"][0][\"text\"]\n",
    "                    elif (\n",
    "                        msg[\"role\"] == \"user\"\n",
    "                        and not customer_query\n",
    "                        and \"toolResult\" not in msg[\"content\"][0]\n",
    "                    ):\n",
    "                        customer_query = msg[\"content\"][0][\"text\"]\n",
    "                        break\n",
    "\n",
    "                if customer_query and agent_response:\n",
    "                    # *** AGENTCORE MEMORY USAGE *** - Save the support interaction\n",
    "                    self.client.create_event(\n",
    "                        memory_id=self.memory_id,\n",
    "                        actor_id=self.actor_id,\n",
    "                        session_id=self.session_id,\n",
    "                        messages=[\n",
    "                            (customer_query, \"USER\"),\n",
    "                            (agent_response, \"ASSISTANT\"),\n",
    "                        ],\n",
    "                    )\n",
    "                    logger.info(\"Saved support interaction to memory\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save support interaction: {e}\")\n",
    "\n",
    "    def register_hooks(self, registry: HookRegistry) -> None:\n",
    "        \"\"\"Register customer support memory hooks\"\"\"\n",
    "        registry.add_callback(MessageAddedEvent, self.retrieve_customer_context)\n",
    "        registry.add_callback(AfterInvocationEvent, self.save_support_interaction)\n",
    "        logger.info(\"Customer support memory hooks registered\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create a Customer Support Agent with memory\n",
    "\n",
    "Next, we will implement the Customer Support Agent just as we did in Lab 1, but this time we instantiate the class `CustomerSupportMemoryHooks` and we pass the memory hook to the agent contructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "from lab_helpers.lab1_strands_agent import (\n",
    "    SYSTEM_PROMPT,\n",
    "    get_return_policy, web_search,\n",
    "    get_product_info, MODEL_ID\n",
    ")\n",
    "\n",
    "SESSION_ID = str(uuid.uuid4())\n",
    "memory_hooks = CustomerSupportMemoryHooks(memory_id, memory_client, CUSTOMER_ID, SESSION_ID)\n",
    "\n",
    "\n",
    "# Initialize the Bedrock model (Anthropic Claude 3.7 Sonnet)\n",
    "model = BedrockModel(\n",
    "    model_id=MODEL_ID,\n",
    "    region_name=REGION\n",
    ")\n",
    "\n",
    "# Create the customer support agent with all 5 tools\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    hooks=[memory_hooks], # Pass Memory Hooks\n",
    "    tools=[\n",
    "        get_product_info,      # Tool 1: Simple product information lookup\n",
    "        get_return_policy,      # Tool 2: Simple return policy lookup\n",
    "        web_search,\n",
    "    ],\n",
    "    system_prompt=SYSTEM_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Test Memory Hooks\n",
    "\n",
    "Now let's test how the sophisticated MemoryHook system works automatically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”! ê²Œì„ìš© í—¤ë“œí°ì— ê´€ì‹¬ì´ ìˆìœ¼ì‹  ê²ƒ ê°™ë„¤ìš”. ê²½ìŸì ì¸ FPS ê²Œì„ì„ ìœ„í•œ ë‚®ì€ ì§€ì—° ì‹œê°„ì„ ê°–ì¶˜ í—¤ë“œí°ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì•„ë“œë¦¬ê² ìŠµë‹ˆë‹¤. í—¤ë“œí°ì— ëŒ€í•œ ìì„¸í•œ ì •ë³´ë¥¼ í™•ì¸í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
      "Tool #1: get_product_info\n",
      "ì €í¬ ë§¤ì¥ì—ì„œ ì·¨ê¸‰í•˜ëŠ” í—¤ë“œí°ì— ëŒ€í•œ ê¸°ë³¸ ì •ë³´ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ê²½ìŸì ì¸ FPS ê²Œì„ì— í•„ìš”í•œ ë‚®ì€ ì§€ì—° ì‹œê°„(<40ms)ì„ ê°€ì§„ ê²Œì„ìš© í—¤ë“œí°ì— ëŒ€í•´ ë” ìì„¸í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
      "Tool #2: web_search\n",
      "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ê²½ìŸì ì¸ FPS ê²Œì„ì„ ìœ„í•œ ë‚®ì€ ì§€ì—° ì‹œê°„ì„ ê°€ì§„ í—¤ë“œí°ì— ëŒ€í•´ ì•ˆë‚´í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "## ê²Œì„ìš© í—¤ë“œí° ì¶”ì²œ\n",
      "\n",
      "ê²½ìŸì ì¸ FPS ê²Œì„ì„ ìœ„í•œ ìµœì ì˜ í—¤ë“œí°ì€ ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì§•ì„ ê°–ì¶”ì–´ì•¼ í•©ë‹ˆë‹¤:\n",
      "\n",
      "### ì¶”ì²œ í—¤ë“œí° ì˜µì…˜:\n",
      "\n",
      "1. **Avantree ê²Œì´ë° í—¤ë“œí°**\n",
      "   - ì´ˆì €ì§€ì—° ê¸°ìˆ  íƒ‘ì¬\n",
      "   - ê³ í’ˆì§ˆ ì‚¬ìš´ë“œì™€ ì¸ì²´ê³µí•™ì  ë””ìì¸\n",
      "   - ê²½ìŸ ë° ì¼ë°˜ ê²Œì´ë¨¸ ëª¨ë‘ì—ê²Œ ì í•©\n",
      "\n",
      "2. **CrossBeats Fury Max ê²Œì´ë° ì´ì–´ë²„ë“œ**\n",
      "   - 30ms ì €ì§€ì—° ì‹œê°„ (ìš”êµ¬ì‚¬í•­ì¸ 40ms ë¯¸ë§Œ)\n",
      "   - 360Â° ê³µê°„ ì˜¤ë””ì˜¤ ë° 3D ì‚¬ìš´ë“œ ìŠ¤í…Œì´ì§€\n",
      "   - ê¸´ ë°°í„°ë¦¬ ìˆ˜ëª… (ì•½ 100ì‹œê°„)\n",
      "\n",
      "3. **Nu Republic Cyberstud X8**\n",
      "   - 40ms ì´ˆì €ì§€ì—° ê¸°ìˆ \n",
      "   - ìµœëŒ€ 56ì‹œê°„ ì¬ìƒ ì‹œê°„\n",
      "   - ë¬´ì„  ì´ì–´ë²„ë“œ íƒ€ì…\n",
      "\n",
      "4. **Audeze Maxwell Wireless**\n",
      "   - RTINGS.comì—ì„œ ìµœê³ ì˜ ë¬´ì„  ê²Œì´ë° í—¤ë“œì…‹ìœ¼ë¡œ ì„ ì •\n",
      "   - ì˜¤ë””ì˜¤íŒŒì¼ ìˆ˜ì¤€ì˜ ì‚¬ìš´ë“œì™€ ê²Œì´ë° ê¸°ëŠ¥ ê²°í•©\n",
      "\n",
      "### ê²Œì„ìš© í—¤ë“œí° ì„ íƒ ì‹œ ê³ ë ¤ì‚¬í•­:\n",
      "\n",
      "1. **ì§€ì—° ì‹œê°„(Latency)**: FPS ê²Œì„ì—ì„œëŠ” 40ms ë¯¸ë§Œì˜ ì§€ì—° ì‹œê°„ì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ìœ ì„  í—¤ë“œí°ì´ ì¼ë°˜ì ìœ¼ë¡œ ì§€ì—° ì‹œê°„ì´ ê°€ì¥ ì ìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ìŒì§ˆ**: ë°œìêµ­ ì†Œë¦¬ì™€ ê°™ì€ ë¯¸ë¬˜í•œ ì†Œë¦¬ë¥¼ ì •í™•íˆ ê°ì§€í•  ìˆ˜ ìˆëŠ” ì¤‘ìŒì—­ê³¼ ê³ ìŒì—­ì´ ë›°ì–´ë‚œ ì œí’ˆì„ ì„ íƒí•˜ì„¸ìš”.\n",
      "\n",
      "3. **í¸ì•ˆí•¨**: ì¥ì‹œê°„ ê²Œì„ì„ ìœ„í•œ í¸ì•ˆí•œ ì°©ìš©ê°ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "4. **ì—°ê²° ë°©ì‹**: ë¸”ë£¨íˆ¬ìŠ¤ 5.0 ì´ìƒ, ì „ìš© ë¬´ì„  ì†¡ì‹ ê¸°, ìœ ì„  ì˜µì…˜ ë“±ì„ ê³ ë ¤í•˜ì„¸ìš”.\n",
      "\n",
      "5. **ë§ˆì´í¬ í’ˆì§ˆ**: íŒ€ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ì„ ìœ„í•œ ê¹¨ë—í•œ ë§ˆì´í¬ ì„±ëŠ¥ë„ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì €í¬ ë§¤ì¥ì—ì„œëŠ” ë‹¤ì–‘í•œ ê²Œì´ë° í—¤ë“œí°ì„ ë³´ìœ í•˜ê³  ìˆìœ¼ë©°, ìœ„ì— ì–¸ê¸‰ëœ ì œí’ˆë“¤ì˜ ëŒ€ë¶€ë¶„ì„ êµ¬ë§¤í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§Œì•½ íŠ¹ì • ë¸Œëœë“œë‚˜ ëª¨ë¸ì— ëŒ€í•´ ë” ìì„¸í•œ ì •ë³´ê°€ í•„ìš”í•˜ì‹œê±°ë‚˜, ë‹¤ë¥¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”. ì§ì ‘ ë§¤ì¥ì— ë°©ë¬¸í•˜ì…”ì„œ ì‹œì—°í•´ ë³´ì‹œëŠ” ê²ƒë„ ì¢‹ì€ ë°©ë²•ì…ë‹ˆë‹¤.\n",
      "\n",
      "í˜¹ì‹œ ë‹¤ë¥¸ ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ì‹ ê°€ìš”?"
     ]
    }
   ],
   "source": [
    "# response1 = agent(\"Which headphones would you recommend?\")\n",
    "response1 = agent(\"ì–´ë–¤ í—¤ë“œí°ì´ ì¢‹ì„ê¹Œìš”? í•œê¸€ë¡œ ë‹µë³€ í•´ì¤˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”! ê·€í•˜ì˜ ë…¸íŠ¸ë¶ ì„ í˜¸ë„ì— ëŒ€í•´ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë˜ë°ìš© ë…¸íŠ¸ë¶ì„ ì°¾ê³  ê³„ì‹œëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ê·€í•˜ì˜ ì„ í˜¸ë„ì— ë§ëŠ” ë…¸íŠ¸ë¶ì— ëŒ€í•´ ì •ë³´ë¥¼ ì°¾ì•„ë³´ê² ìŠµë‹ˆë‹¤.\n",
      "Tool #3: get_product_info\n",
      "ê·€í•˜ì˜ ìš”êµ¬ì‚¬í•­ì„ ë” ìì„¸íˆ íŒŒì•…í•˜ê¸° ìœ„í•´ ThinkPad ëª¨ë¸ê³¼ Linux í˜¸í™˜ì„±ì´ ì¢‹ì€ í”„ë¡œê·¸ë˜ë°ìš© ë…¸íŠ¸ë¶ì— ëŒ€í•´ ê²€ìƒ‰í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
      "Tool #4: web_search\n",
      "ê²€ìƒ‰ ê²°ê³¼ê°€ ì •í™•í•˜ì§€ ì•Šì€ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ê²€ìƒ‰í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
      "Tool #5: web_search\n",
      "ì •í™•í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•´ ê²€ìƒ‰ì–´ë¥¼ ë‹¤ì‹œ ì¡°ì •í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
      "Tool #6: web_search\n",
      "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê·€í•˜ì˜ ì„ í˜¸ë„ì— ë§ëŠ” ë…¸íŠ¸ë¶ ì •ë³´ë¥¼ ì •ë¦¬í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "## ê·€í•˜ê°€ ì„ í˜¸í•˜ëŠ” ë…¸íŠ¸ë¶ ì •ë³´\n",
      "\n",
      "ê·€í•˜ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ìš”êµ¬ì‚¬í•­ì„ ê°€ì§„ í”„ë¡œê·¸ë˜ë°ìš© ë…¸íŠ¸ë¶ì„ ì°¾ê³  ê³„ì‹­ë‹ˆë‹¤:\n",
      "- ê°€ê²©ëŒ€: $1,200 ë¯¸ë§Œ\n",
      "- RAM: ìµœì†Œ 16GB\n",
      "- Linux í˜¸í™˜ì„±: ìš°ìˆ˜í•œ í˜¸í™˜ì„± í•„ìš”\n",
      "- ì„ í˜¸ ë¸Œëœë“œ: ThinkPad ëª¨ë¸\n",
      "\n",
      "### ì¶”ì²œ ThinkPad ëª¨ë¸:\n",
      "\n",
      "1. **ThinkPad T16**\n",
      "   - í”„ë¡œê·¸ë˜ë°ì— ìµœì í™”ëœ ì™„ë²½í•œ íŒ¨í‚¤ì§€\n",
      "   - 16ì¸ì¹˜, 16:10 ë””ìŠ¤í”Œë ˆì´ë¡œ ì‹œê°ì  ì‘ì—… ê³µê°„ì´ ë„“ìŒ\n",
      "   - Intel Core i7 ë˜ëŠ” AMD Ryzen 7 Pro í”„ë¡œì„¸ì„œ ì˜µì…˜\n",
      "   - ìµœëŒ€ 32GB RAM ì§€ì› (16GB ëª¨ë¸ì´ ì˜ˆì‚° ë‚´ì— ìˆìŒ)\n",
      "   - Linux í˜¸í™˜ì„± ìš°ìˆ˜\n",
      "   - ì½”ë”© ì‘ì—…ì— ì í•©í•œ ê³ í’ˆì§ˆ í‚¤ë³´ë“œ\n",
      "\n",
      "2. **ThinkPad E14/E15**\n",
      "   - ì˜ˆì‚° ì¹œí™”ì  ê°€ê²©ëŒ€ì˜ ThinkPad ì‹œë¦¬ì¦ˆ\n",
      "   - ìµœì‹  Intel í”„ë¡œì„¸ì„œì™€ 16GB RAM êµ¬ì„± ê°€ëŠ¥\n",
      "   - $1,200 ë¯¸ë§Œì˜ ê°€ê²©ëŒ€\n",
      "   - í›Œë¥­í•œ Linux í˜¸í™˜ì„±\n",
      "\n",
      "3. **ThinkPad L14/L15**\n",
      "   - ì¤‘ê°„ ê°€ê²©ëŒ€ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ìš© ë…¸íŠ¸ë¶\n",
      "   - 16GB RAMê³¼ SSD ìŠ¤í† ë¦¬ì§€\n",
      "   - ê²¬ê³ í•œ ì„¤ê³„ì™€ ì¢‹ì€ í‚¤ë³´ë“œ\n",
      "   - Linux ë°°í¬íŒê³¼ì˜ í˜¸í™˜ì„± ìš°ìˆ˜\n",
      "\n",
      "### ThinkPadì˜ Linux í”„ë¡œê·¸ë˜ë°ìš© ì¥ì :\n",
      "\n",
      "- **ìš°ìˆ˜í•œ Linux í˜¸í™˜ì„±**: ThinkPad ì‹œë¦¬ì¦ˆëŠ” ì¼ë°˜ì ìœ¼ë¡œ ëŒ€ë¶€ë¶„ì˜ Linux ë°°í¬íŒê³¼ í˜¸í™˜ì„±ì´ ë›°ì–´ë‚©ë‹ˆë‹¤.\n",
      "- **ë‚´êµ¬ì„± ìˆëŠ” ì„¤ê³„**: ë¹„ì¦ˆë‹ˆìŠ¤ìš© ë…¸íŠ¸ë¶ìœ¼ë¡œ ì„¤ê³„ë˜ì–´ ì˜¤ë˜ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "- **ë›°ì–´ë‚œ í‚¤ë³´ë“œ**: í”„ë¡œê·¸ë˜ë¨¸ë¥¼ ìœ„í•œ í¸ì•ˆí•˜ê³  ì •í™•í•œ í‚¤ë³´ë“œ ì œê³µ.\n",
      "- **í™•ì¥ ê°€ëŠ¥í•œ í•˜ë“œì›¨ì–´**: ì¼ë¶€ ëª¨ë¸ì€ RAMì´ë‚˜ ìŠ¤í† ë¦¬ì§€ ì—…ê·¸ë ˆì´ë“œ ê°€ëŠ¥.\n",
      "- **ì—´ ê´€ë¦¬ ì‹œìŠ¤í…œ**: ì¥ì‹œê°„ ì½”ë”© ì„¸ì…˜ ë™ì•ˆ ì•ˆì •ì ì¸ ì„±ëŠ¥ ìœ ì§€.\n",
      "\n",
      "### êµ¬ë§¤ ì‹œ ì¶”ê°€ ê³ ë ¤ì‚¬í•­:\n",
      "\n",
      "- SSD ìš©ëŸ‰: ì½”ë”© í”„ë¡œì íŠ¸ì™€ ê°œë°œ í™˜ê²½ì„ ìœ„í•´ ìµœì†Œ 256GB ì´ìƒ ê¶Œì¥\n",
      "- ë””ìŠ¤í”Œë ˆì´: ì¥ì‹œê°„ ì½”ë”©ì„ ìœ„í•œ ëˆˆ í”¼ë¡œë„ê°€ ì ì€ í™”ë©´\n",
      "- ë°°í„°ë¦¬ ìˆ˜ëª…: ì™¸ë¶€ì—ì„œ ì‘ì—…í•  ê²½ìš° ì¤‘ìš”í•œ ìš”ì†Œ\n",
      "- í¬íŠ¸ ë‹¤ì–‘ì„±: ê°œë°œ í™˜ê²½ì— í•„ìš”í•œ ë‹¤ì–‘í•œ ì£¼ë³€ê¸°ê¸° ì—°ê²° ê°€ëŠ¥ì„±\n",
      "\n",
      "ì €í¬ ë§¤ì¥ì—ì„œëŠ” ì´ëŸ¬í•œ ThinkPad ëª¨ë¸ë“¤ì„ ì·¨ê¸‰í•˜ê³  ìˆìœ¼ë©°, ê·€í•˜ì˜ í”„ë¡œê·¸ë˜ë° í•„ìš”ì— ë§ê²Œ êµ¬ì„± ì˜µì…˜ì„ ì œê³µí•´ ë“œë¦½ë‹ˆë‹¤. íŠ¹ì • ëª¨ë¸ì— ëŒ€í•œ ë” ìì„¸í•œ ì •ë³´ë‚˜ í˜„ì¬ ì¬ê³  ìƒí™©ì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.\n",
      "\n",
      "í˜¹ì‹œ ë‹¤ë¥¸ ì§ˆë¬¸ì´ë‚˜ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•˜ì‹ ê°€ìš”?"
     ]
    }
   ],
   "source": [
    "# response1 = agent(\"What is my preferred Laptop?\")\n",
    "response1 = agent(\"ì œê°€ ì„ í˜¸í•˜ëŠ” ë…¸íŠ¸ë¶ì€ ë¬´ì—‡ì¸ê°€ìš”? í•œê¸€ë¡œ ë‹µë³€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! ğŸ‰\n",
    "\n",
    "You have successfully completed **Lab 2: Add memory to the Customer Support Agent**!\n",
    "\n",
    "### What You Accomplished:\n",
    "\n",
    "- Created a serverless managed memory with Amazon Bedrock AgentCore Memory\n",
    "- Implemented long-term memory to store User-Preferences and Semantic (Factual) information.\n",
    "- Integrated AgentCore Memory with the customer support Agent using the hook mechanism provided by Strands Agents\n",
    "\n",
    "##### Next Up [Lab 3 - Scaling with Gateway and Identity  â†’](lab-03-agentcore-gateway.ipynb)\n",
    "\n",
    "## Resources\n",
    "- [Amazon Bedrock Agent Core Memory](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/memory.html)\n",
    "- [Strands Agents Hooks Documentation](https://strandsagents.com/latest/documentation/docs/user-guide/concepts/agents/hooks/?h=hooks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (Python 3.10.18)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
