#!/usr/bin/env python3
"""
Global Fargate Session Manager for Tools
ë„êµ¬ë“¤ì´ ê³µìœ í•˜ëŠ” ê¸€ë¡œë²Œ ì„¸ì…˜ ë§¤ë‹ˆì €
"""

import logging
import sys
import os
import time
import boto3
import requests
import atexit
import subprocess
import json
from datetime import datetime

from src.tools.fargate_container_controller import SessionBasedFargateManager

# Simple logger setup
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

class GlobalFargateSessionManager:
    _instance = None
    _session_manager = None
    _sessions = {}  # {request_id: session_info} - ìš”ì²­ë³„ ì„¸ì…˜ ê´€ë¦¬
    _http_clients = {}  # {request_id: http_session} - ìš”ì²­ë³„ HTTP í´ë¼ì´ì–¸íŠ¸ (ì¿ í‚¤ ê²©ë¦¬)
    _used_container_ips = {}  # {container_ip: request_id} - IP ê¸°ë°˜ ì»¨í…Œì´ë„ˆ ì†Œìœ ê¶Œ ì¶”ì 
    _current_request_id = None  # í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ì˜ ìš”ì²­ ID
    _retry_count = 0
    _max_retries = 2
    _session_creation_failures = {}  # {request_id: failure_count} - ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨ íšŸìˆ˜ ì¶”ì 
    _max_session_failures = 3  # ìµœëŒ€ ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨ í—ˆìš© íšŸìˆ˜
    _cleaned_up_requests = set()  # ì´ë¯¸ cleanupëœ ìš”ì²­ ID ì¶”ì  (ì¬ìƒì„± ë°©ì§€)

    # subprocess ê¸°ë°˜ cookie acquisition helper script ê²½ë¡œ
    _cookie_script_path = "/tmp/acquire_cookie.py"

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(GlobalFargateSessionManager, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if self._session_manager is None:
            logger.info("ğŸš€ Initializing Global Fargate Session Manager")
            self._session_manager = SessionBasedFargateManager()
            atexit.register(self._auto_cleanup)

    def set_request_context(self, request_id: str):
        """í˜„ì¬ ìš”ì²­ ì»¨í…ìŠ¤íŠ¸ ì„¤ì •"""
        self._current_request_id = request_id
        logger.info(f"ğŸ“‹ Request context set: {request_id}")

    def _get_http_client(self, request_id: str):
        """ìš”ì²­ë³„ HTTP í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜ (ì¿ í‚¤ ê²©ë¦¬)"""
        if request_id not in self._http_clients:
            import requests
            self._http_clients[request_id] = requests.Session()
            logger.info(f"ğŸª Created new HTTP client for request {request_id}")
        return self._http_clients[request_id]

    def _acquire_cookie_for_ip(self, expected_ip: str) -> bool:
        """
        íŠ¹ì • IPì˜ ì»¨í…Œì´ë„ˆì— ëŒ€í•œ Sticky Session ì¿ í‚¤ íšë“ (IP ê¸°ë°˜ ê²€ì¦)

        ë°©ë²•:
        - ê° ì‹œë„ë§ˆë‹¤ ìƒˆë¡œìš´ HTTP Client ìƒì„±
        - Cookie ì—†ëŠ” ê¹¨ë—í•œ ìƒíƒœë¡œ ì‹œì‘
        - ì„±ê³µí•œ HTTP Clientë§Œ ì €ì¥í•˜ì—¬ ì´í›„ executionì—ì„œ ì¬ì‚¬ìš©
        - ALB Round Robinì„ í™œìš©í•˜ì—¬ ì—¬ëŸ¬ ì»¨í…Œì´ë„ˆ ì¤‘ íƒ€ê²Ÿ ì°¾ê¸°
        """
        max_attempts = 30  # ë©€í‹° Job í™˜ê²½ì—ì„œëŠ” ë” ë§ì€ ì‹œë„ í•„ìš”

        logger.info(f"ğŸª Acquiring cookie for container: {expected_ip}")
        other_ips = [ip for ip in self._used_container_ips.keys() if ip != expected_ip]
        if other_ips:
            logger.info(f"   Other active containers: {other_ips}")
        else:
            logger.info(f"   No other active containers")

        for attempt in range(1, max_attempts + 1):
            # âœ… í•µì‹¬: ë§¤ ì‹œë„ë§ˆë‹¤ ìƒˆë¡œìš´ HTTP Client ìƒì„± (TCP Connection ê²©ë¦¬)
            http_client = requests.Session()

            actual_ip = 'unknown'  # finally ë¸”ë¡ì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ì´ˆê¸°í™”

            try:
                response = http_client.get(
                    f"{self._session_manager.alb_dns}/container-info",
                    timeout=5
                )

                if response.status_code == 200:
                    data = response.json()
                    actual_ip = data.get('private_ip', 'unknown')

                    # âœ… í•µì‹¬: ë‚´ ì»¨í…Œì´ë„ˆì¸ì§€ í™•ì¸
                    if actual_ip == expected_ip:
                        if 'AWSALB' in http_client.cookies:
                            logger.info(f"âœ… Cookie acquired! (attempt {attempt})")
                            logger.info(f"   My container IP: {actual_ip}")

                            # âœ… ì„±ê³µ! ì´ HTTP Clientë¥¼ ì €ì¥ (ì´í›„ executionì—ì„œ ì¬ì‚¬ìš©)
                            self._http_clients[self._current_request_id] = http_client
                            return True
                        else:
                            logger.debug(f"   Attempt {attempt}: Response from my container but no cookie yet")
                    else:
                        # ë‹¤ë¥¸ Jobì˜ ì»¨í…Œì´ë„ˆë¡œ ë¼ìš°íŒ…ë¨
                        if actual_ip in self._used_container_ips:
                            owner = self._used_container_ips[actual_ip]
                            logger.debug(f"ğŸ”„ Attempt {attempt}: Got other job's container")
                            logger.debug(f"   Response from: {actual_ip} (owner: {owner})")
                            logger.debug(f"   My container:  {expected_ip}")
                        else:
                            # ì˜¤ë˜ëœ ì»¨í…Œì´ë„ˆ (cleanup ì•ˆ ëœ ê²½ìš°)
                            logger.debug(f"ğŸ”„ Attempt {attempt}: Got unregistered container: {actual_ip}")
                            logger.debug(f"   My container:  {expected_ip}")

                if attempt < max_attempts:
                    time.sleep(1)

            except Exception as e:
                logger.warning(f"âš ï¸ Attempt {attempt} failed: {e}")
                if attempt < max_attempts:
                    time.sleep(1)

            finally:
                # âœ… ì‹¤íŒ¨í•œ ì‹œë„ì˜ HTTP ClientëŠ” ëª…ì‹œì ìœ¼ë¡œ ì¢…ë£Œ (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
                # ì„±ê³µí•œ ê²½ìš°ëŠ” ì´ë¯¸ _http_clientsì— ì €ì¥ë˜ì–´ returnë˜ë¯€ë¡œ ì¢…ë£Œí•˜ì§€ ì•ŠìŒ
                if actual_ip != expected_ip:
                    http_client.close()

        logger.error(f"âŒ Failed to acquire cookie after {max_attempts} attempts")
        logger.error(f"   Expected IP: {expected_ip}")
        logger.error(f"   Registered IPs: {list(self._used_container_ips.keys())}")
        return False

    def ensure_session(self):
        """ì„¸ì…˜ì´ ì—†ê±°ë‚˜ ë¹„í™œì„±í™”ëœ ê²½ìš° ìƒˆ ì„¸ì…˜ ìƒì„± (ìš”ì²­ë³„ ì„¸ì…˜ ê´€ë¦¬)"""
        try:
            if not self._current_request_id:
                raise Exception("Request context not set. Call set_request_context() first.")

            # âœ… ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨ íšŸìˆ˜ ì²´í¬
            failure_count = self._session_creation_failures.get(self._current_request_id, 0)
            if failure_count >= self._max_session_failures:
                error_msg = f"âŒ FATAL: Session creation failed {failure_count} times for request {self._current_request_id}. Terminating workflow to prevent resource waste."
                logger.error(error_msg)
                raise Exception(error_msg)

            # âœ… ì´ë¯¸ cleanupëœ ìš”ì²­ì€ ìƒˆ ì„¸ì…˜ ìƒì„± ê¸ˆì§€ (ì¤‘ë³µ ì»¨í…Œì´ë„ˆ ë°©ì§€)
            if self._current_request_id in self._cleaned_up_requests:
                error_msg = f"âŒ FATAL: Request {self._current_request_id} already cleaned up - cannot create new session. This prevents duplicate container creation after workflow completion."
                logger.error(error_msg)
                raise Exception(error_msg)

            # í˜„ì¬ ìš”ì²­ì˜ ì„¸ì…˜ í™•ì¸
            if self._current_request_id in self._sessions:
                # ê¸°ì¡´ ì„¸ì…˜ ì¬ì‚¬ìš©
                session_info = self._sessions[self._current_request_id]
                logger.info(f"â™»ï¸ Reusing existing session for request {self._current_request_id}: {session_info['session_id']}")

                # SessionBasedFargateManagerì˜ current_session ì—…ë°ì´íŠ¸
                self._session_manager.current_session = session_info['fargate_session']

                # âœ… HTTP Sessionë„ ì¬ì£¼ì… (ì„¸ì…˜ ì¬ì‚¬ìš© ì‹œì—ë„ í•„ìš”)
                http_client = self._get_http_client(self._current_request_id)
                self._session_manager.set_http_session(http_client)

                return True

            # ìƒˆ ì„¸ì…˜ ìƒì„±
            logger.info(f"ğŸ“¦ Creating new Fargate session for request {self._current_request_id}...")
            timestamp_id = datetime.now().strftime("%Y-%m-%d-%H-%M-%S")

            try:
                fargate_session_info = self._session_manager.create_session(
                    session_id=timestamp_id,
                    max_executions=300
                )

                # âœ… HTTP Session ì£¼ì… (ìš”ì²­ë³„ ì¿ í‚¤ ê²©ë¦¬)
                http_client = self._get_http_client(self._current_request_id)
                self._session_manager.set_http_session(http_client)
                logger.info(f"ğŸ”— HTTP session injected for request {self._current_request_id}")

                # âœ… ì»¨í…Œì´ë„ˆ IP ë“±ë¡ (AWS VPCê°€ ìœ ë‹ˆí¬í•œ IP ë³´ì¥)
                expected_private_ip = self._session_manager.current_session['private_ip']
                self._used_container_ips[expected_private_ip] = self._current_request_id
                logger.info(f"ğŸ“ Registered container IP: {expected_private_ip}")
                logger.info(f"   Request ID: {self._current_request_id}")
                logger.info(f"   All registered IPs: {list(self._used_container_ips.keys())}")

                # âœ… ì„¸ì…˜ì„ ë”•ì…”ë„ˆë¦¬ì— ì €ì¥ (IP ì •ë³´ í¬í•¨)
                self._sessions[self._current_request_id] = {
                    'session_id': fargate_session_info['session_id'],
                    'request_id': self._current_request_id,
                    'container_ip': expected_private_ip,
                    'fargate_session': self._session_manager.current_session,
                    'created_at': datetime.now()
                }
                logger.info(f"âœ… Session created and saved for request {self._current_request_id}: {fargate_session_info['session_id']}")

                # â° ALB íŠ¸ë˜í”½ ë¼ìš°íŒ… ì•ˆì •í™” ëŒ€ê¸° (health check í†µê³¼ í›„ ì¶”ê°€ ì‹œê°„ í•„ìš”)
                logger.info(f"â° Waiting for ALB to stabilize traffic routing (10 seconds)...")
                time.sleep(10)

                # ğŸª IP ê¸°ë°˜ ì¿ í‚¤ íšë“
                cookie_acquired = self._acquire_cookie_for_ip(expected_private_ip)

                if not cookie_acquired:
                    # ì¿ í‚¤ íšë“ ì‹¤íŒ¨ â†’ IP ë“±ë¡ í•´ì œ
                    logger.warning(f"âš ï¸ Failed to acquire Sticky Session cookie")
                    logger.warning(f"   Releasing IP registration: {expected_private_ip}")
                    if expected_private_ip in self._used_container_ips:
                        del self._used_container_ips[expected_private_ip]
                    logger.warning(f"   Session is saved and will retry on next execution")
                    return True

                logger.info(f"   Total active sessions: {len(self._sessions)}")

                # âœ… ì„¸ì…˜ ìƒì„± ì„±ê³µ - ì‹¤íŒ¨ ì¹´ìš´í„° ë¦¬ì…‹
                if self._current_request_id in self._session_creation_failures:
                    del self._session_creation_failures[self._current_request_id]

                self._retry_count = 0
                return True

            except Exception as create_error:
                logger.error(f"âŒ Session creation failed: {create_error}")

                # âœ… ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨ - ì¹´ìš´í„° ì¦ê°€
                failure_count = self._session_creation_failures.get(self._current_request_id, 0)
                self._session_creation_failures[self._current_request_id] = failure_count + 1
                logger.warning(f"âš ï¸ Session creation failure count for request {self._current_request_id}: {failure_count + 1}/{self._max_session_failures}")

                # ì„¸ì…˜ ìƒì„± ìì²´ê°€ ì‹¤íŒ¨í•œ ê²½ìš°ë§Œ cleanup
                if self._current_request_id in self._sessions:
                    del self._sessions[self._current_request_id]
                self._cleanup_orphaned_containers()
                raise

        except Exception as e:
            logger.error(f"âŒ Failed to ensure session: {e}")

            # âœ… ì¹˜ëª…ì  ì—ëŸ¬ëŠ” ì¬ë°œìƒ (ì›Œí¬í”Œë¡œìš° ì¤‘ë‹¨)
            if "FATAL" in str(e):
                raise

            return False

    def execute_code(self, code: str, description: str = ""):
        """ì½”ë“œ ì‹¤í–‰ with ìë™ ì„¸ì…˜ ê´€ë¦¬ ë° ì—°ê²° ì¬ì‹œë„"""
        max_retries = 3
        retry_delay = 2  # seconds

        for attempt in range(1, max_retries + 1):
            try:
                # ì„¸ì…˜ í™•ì¸ ë° ìƒì„±
                if not self.ensure_session():
                    return {"error": "Failed to create or maintain session"}

                # ì½”ë“œ ì‹¤í–‰
                result = self._session_manager.execute_code(code, description)

                # ì„±ê³µí•˜ë©´ ë°”ë¡œ ë°˜í™˜
                return result

            except Exception as e:
                error_msg = str(e)

                # ì—°ê²° ê´€ë ¨ ì—ëŸ¬ì¸ì§€ í™•ì¸
                is_connection_error = any(keyword in error_msg.upper() for keyword in [
                    "CONNECTION FAILED",
                    "NOT RESPONDING",
                    "TIMEOUT",
                    "CONNECTIONERROR",
                    "HTTPERROR"
                ])

                if is_connection_error:
                    # ì—°ê²° ì—ëŸ¬ - ì¬ì‹œë„
                    logger.warning(f"âš ï¸ Connection error (attempt {attempt}/{max_retries}): {error_msg}")

                    if attempt < max_retries:
                        logger.info(f"ğŸ”„ Retrying in {retry_delay} seconds...")
                        time.sleep(retry_delay)
                    else:
                        logger.error(f"âŒ Connection failed after {max_retries} attempts. Giving up.")
                        return {
                            "error": f"Connection failed after {max_retries} attempts: {error_msg}"
                        }
                else:
                    # ì½”ë“œ ì‹¤í–‰ ì—ëŸ¬ ë“± - ì¬ì‹œë„ ì•ˆ í•¨
                    logger.error(f"âŒ Code execution failed: {e}")
                    # âš ï¸ ì„¸ì…˜ì„ Noneìœ¼ë¡œ ë¦¬ì…‹í•˜ì§€ ì•ŠìŒ!
                    # ì»¨í…Œì´ë„ˆ í†µì‹  ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ë‹¤ìŒ Agentê°€ ì¬ì‹œë„í•  ìˆ˜ ìˆë„ë¡ ì„¸ì…˜ ìœ ì§€
                    # ì—¬ëŸ¬ Agentê°€ ê°™ì€ ì»¨í…Œì´ë„ˆë¥¼ ê³µìœ í•´ì•¼ í•˜ë¯€ë¡œ ì„¸ì…˜ ì´ˆê¸°í™” ê¸ˆì§€
                    return {"error": str(e)}

    def get_session_info(self):
        """í˜„ì¬ ìš”ì²­ì˜ ì„¸ì…˜ ì •ë³´ ë°˜í™˜"""
        if not self._current_request_id:
            return {"status": "no_context"}

        if self._current_request_id in self._sessions:
            session_info = self._sessions[self._current_request_id]
            return {
                "request_id": self._current_request_id,
                "session_id": session_info['session_id'],
                "status": "active",
                "private_ip": session_info['fargate_session']['private_ip']
            }
        else:
            return {"status": "no_session", "request_id": self._current_request_id}

    def ensure_session_with_data(self, csv_file_path: str):
        """CSV íŒŒì¼ê³¼ í•¨ê»˜ ì„¸ì…˜ ìƒì„± (ì„¸ì…˜ í™•ì¸ â†’ S3 ì—…ë¡œë“œ â†’ ì»¨í…Œì´ë„ˆ ë™ê¸°í™”)"""
        try:
            logger.info(f"ğŸš€ Creating session with data: {csv_file_path}")

            # âœ… 1. ë¨¼ì € ì„¸ì…˜ ìƒì„± (Timestamp ìƒì„±)
            if not self.ensure_session():
                raise Exception("Failed to create Fargate session")

            # âœ… 2. ìƒì„±ëœ ì„¸ì…˜ IDë¥¼ ì‚¬ìš©í•˜ì—¬ S3 ì—…ë¡œë“œ
            session_id = self._sessions[self._current_request_id]['session_id']
            s3_key = self._upload_csv_to_s3_with_session_id(csv_file_path, session_id)
            logger.info(f"ğŸ“¤ CSV uploaded to S3: {s3_key}")

            # 3. ì»¨í…Œì´ë„ˆì— S3 â†’ ë¡œì»¬ ë™ê¸°í™”
            self._sync_csv_from_s3_to_container(s3_key)
            logger.info("âœ… CSV file synced to container")

            return True

        except Exception as e:
            logger.error(f"âŒ Failed to create session with data: {e}")
            return False

    def _upload_csv_to_s3_with_session_id(self, csv_file_path: str, session_id: str) -> str:
        """ì„¸ì…˜ IDë¥¼ ë°›ì•„ì„œ S3ì— ì—…ë¡œë“œ (Timestamp ë¶ˆì¼ì¹˜ ë°©ì§€)"""
        try:
            # âœ… ì„¸ì…˜ IDë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ìƒˆ timestamp ìƒì„± ì•ˆí•¨)
            import os
            original_filename = os.path.basename(csv_file_path)
            s3_key = f"manus/fargate_sessions/{session_id}/input/{original_filename}"

            # S3 ì—…ë¡œë“œ
            s3_client = boto3.client('s3', region_name='us-east-1')
            s3_client.upload_file(
                csv_file_path,
                'bedrock-logs-gonsoomoon',
                s3_key,
                ExtraArgs={'ContentType': 'text/csv'}
            )

            logger.info(f"ğŸ“¤ Uploaded {csv_file_path} â†’ s3://bedrock-logs-gonsoomoon/{s3_key}")
            return s3_key

        except Exception as e:
            logger.error(f"âŒ S3 upload failed: {e}")
            raise

    def _upload_csv_to_s3(self, csv_file_path: str) -> str:
        """CSV íŒŒì¼ì„ S3ì— ì—…ë¡œë“œ (ë ˆê±°ì‹œ - ìƒˆ timestamp ìƒì„±)"""
        try:
            # í˜„ì¬ ì„¸ì…˜ ID ê¸°ë°˜ S3 í‚¤ ìƒì„±
            timestamp_id = datetime.now().strftime("%Y-%m-%d-%H-%M-%S")

            # ì›ë³¸ íŒŒì¼ëª… ì¶”ì¶œ
            import os
            original_filename = os.path.basename(csv_file_path)
            s3_key = f"manus/fargate_sessions/{timestamp_id}/input/{original_filename}"

            # S3 ì—…ë¡œë“œ
            s3_client = boto3.client('s3', region_name='us-east-1')
            s3_client.upload_file(
                csv_file_path,
                'bedrock-logs-gonsoomoon',
                s3_key,
                ExtraArgs={'ContentType': 'text/csv'}
            )

            logger.info(f"ğŸ“¤ Uploaded {csv_file_path} â†’ s3://bedrock-logs-gonsoomoon/{s3_key}")
            return s3_key

        except Exception as e:
            logger.error(f"âŒ S3 upload failed: {e}")
            raise

    def _sync_csv_from_s3_to_container(self, s3_key: str):
        """S3ì—ì„œ ì»¨í…Œì´ë„ˆë¡œ CSV íŒŒì¼ ë™ê¸°í™” (Enhanced Logging)"""
        try:
            # ALB DNS (ì„¸ì…˜ ë§¤ë‹ˆì €ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
            alb_dns = self._session_manager.alb_dns
            filename = s3_key.split('/')[-1]

            # âœ… 1. ì‹œì‘ ë¡œê·¸
            logger.info(f"ğŸ”„ Starting file sync...")
            logger.info(f"   S3 Key: {s3_key}")
            logger.info(f"   Filename: {filename}")
            logger.info(f"   Target: /app/data/{filename}")

            # íŒŒì¼ ë™ê¸°í™” ìš”ì²­
            # s3_key í˜•íƒœ: "manus/fargate_sessions/{session_id}/input/file.csv"
            sync_request = {
                "action": "sync_data_from_s3",
                "bucket_name": "bedrock-logs-gonsoomoon",
                "s3_key_prefix": f"manus/fargate_sessions/{s3_key.split('/')[2]}/input/",
                "local_path": "/app/data/"
            }

            # âœ… 2. ìš”ì²­ ë¡œê·¸
            logger.info(f"ğŸ“¤ Sending file sync request:")
            logger.info(f"   URL: {alb_dns}/file-sync")
            logger.info(f"   Request: {sync_request}")

            # âœ… ìš”ì²­ë³„ HTTP í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© (ì¿ í‚¤ ê²©ë¦¬)
            http_client = self._get_http_client(self._current_request_id)
            response = http_client.post(
                f"{alb_dns}/file-sync",
                json=sync_request,
                timeout=30
            )

            # âœ… 3. ì‘ë‹µ ë¡œê·¸
            logger.info(f"ğŸ“¥ File sync response:")
            logger.info(f"   Status: {response.status_code}")
            logger.info(f"   Body: {response.text[:500]}")  # ì²˜ìŒ 500ìë§Œ

            if response.status_code != 200:
                logger.error(f"âŒ File sync failed with status {response.status_code}")
                raise Exception(f"File sync failed: {response.text}")

            result = response.json()
            files_count = result.get('files_count', 0)
            downloaded_files = result.get('downloaded_files', [])

            # âœ… 4. ê²°ê³¼ ë¡œê·¸
            logger.info(f"âœ… File sync completed:")
            logger.info(f"   Files synced: {files_count}")
            logger.info(f"   Downloaded: {downloaded_files}")

            # âœ… 5. ëŒ€ê¸° ì‹œì‘ ë¡œê·¸
            import time
            logger.info("â³ Waiting 10 seconds for file sync to complete...")
            time.sleep(10)  # 10ì´ˆ ëŒ€ê¸° (íŒŒì¼ ë™ê¸°í™” ì™„ë£Œ ì‹œê°„)

            # âœ… 6. ëŒ€ê¸° ì™„ë£Œ ë¡œê·¸
            logger.info("âœ… File sync wait complete")

        except Exception as e:
            logger.error(f"âŒ File sync failed: {e}")
            logger.error(f"   Exception type: {type(e).__name__}")
            logger.error(f"   Exception details: {str(e)[:1000]}")
            raise

    def _cleanup_orphaned_containers(self):
        """ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨ ì‹œ í˜„ì¬ ìš”ì²­ì˜ ì»¨í…Œì´ë„ˆë§Œ ì •ë¦¬ (ë‹¤ë¥¸ ìš”ì²­ì˜ ì»¨í…Œì´ë„ˆëŠ” ë³´í˜¸)"""
        try:
            import boto3
            ecs_client = boto3.client('ecs', region_name='us-east-1')

            # í˜„ì¬ ìš”ì²­ì˜ Task ARN í™•ì¸
            current_task_arn = None
            if self._current_request_id and self._current_request_id in self._sessions:
                session_info = self._sessions[self._current_request_id]
                fargate_session = session_info.get('fargate_session', {})
                current_task_arn = fargate_session.get('task_arn')

            if not current_task_arn:
                logger.warning(f"âš ï¸ No task ARN found for current request {self._current_request_id} - skipping cleanup")
                return

            # âœ… í˜„ì¬ ìš”ì²­ì˜ ì»¨í…Œì´ë„ˆë§Œ ì¢…ë£Œ (ë‹¤ë¥¸ ìš”ì²­ì˜ ì»¨í…Œì´ë„ˆëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ)
            try:
                logger.info(f"ğŸ§¹ Cleaning up orphaned container for request {self._current_request_id}: {current_task_arn.split('/')[-1][:12]}...")
                ecs_client.stop_task(
                    cluster='my-fargate-cluster',
                    task=current_task_arn,
                    reason=f'Session creation failed - cleanup (request: {self._current_request_id})'
                )
                logger.info(f"   âœ… Stopped container: {current_task_arn.split('/')[-1][:12]}")
            except Exception as stop_error:
                logger.warning(f"   âš ï¸ Failed to stop container {current_task_arn.split('/')[-1][:12]}: {stop_error}")

        except Exception as e:
            logger.warning(f"âš ï¸ Orphaned container cleanup failed: {e}")

    def cleanup_session(self, request_id: str = None):
        """íŠ¹ì • ìš”ì²­ì˜ ì„¸ì…˜ ì •ë¦¬"""
        try:
            # request_idê°€ ì—†ìœ¼ë©´ í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©
            cleanup_request_id = request_id or self._current_request_id

            if not cleanup_request_id:
                logger.warning("âš ï¸ No request ID for cleanup")
                return

            if cleanup_request_id in self._sessions:
                session_info = self._sessions[cleanup_request_id]
                logger.info(f"ğŸ§¹ Cleaning up session for request {cleanup_request_id}: {session_info['session_id']}")

                # âœ… ì»¨í…Œì´ë„ˆ IP í•´ì œ
                container_ip = session_info.get('container_ip')
                if container_ip and container_ip in self._used_container_ips:
                    del self._used_container_ips[container_ip]
                    logger.info(f"ğŸ§¹ Released container IP: {container_ip}")
                    logger.info(f"   Remaining IPs: {list(self._used_container_ips.keys())}")

                # SessionBasedFargateManagerì˜ current_session ì„¤ì •
                self._session_manager.current_session = session_info['fargate_session']
                self._session_manager.complete_session()

                # ì„¸ì…˜ ë”•ì…”ë„ˆë¦¬ì—ì„œ ì œê±°
                del self._sessions[cleanup_request_id]
                logger.info(f"âœ… Session cleanup completed. Remaining sessions: {len(self._sessions)}")
            else:
                logger.warning(f"âš ï¸ No session found for request {cleanup_request_id}")

            # âœ… HTTP í´ë¼ì´ì–¸íŠ¸ë„ ì •ë¦¬ (ì¿ í‚¤ ì œê±°)
            if cleanup_request_id in self._http_clients:
                del self._http_clients[cleanup_request_id]
                logger.info(f"ğŸª Removed HTTP client for request {cleanup_request_id}")

            # âœ… ì‹¤íŒ¨ ì¹´ìš´í„°ë„ ì •ë¦¬
            if cleanup_request_id in self._session_creation_failures:
                del self._session_creation_failures[cleanup_request_id]
                logger.info(f"ğŸ§¹ Cleared failure counter for request {cleanup_request_id}")

            # âœ… cleanupëœ ìš”ì²­ IDë¥¼ ì¶”ì  (ì¬ìƒì„± ë°©ì§€)
            self._cleaned_up_requests.add(cleanup_request_id)
            logger.info(f"ğŸ”’ Request {cleanup_request_id} marked as cleaned up - new session creation blocked")

        except Exception as e:
            logger.error(f"âŒ Session cleanup failed: {e}")

    def _auto_cleanup(self):
        """í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ ìë™ìœ¼ë¡œ ëª¨ë“  ì„¸ì…˜ ì •ë¦¬"""
        try:
            if self._sessions:
                logger.info(f"ğŸ§¹ Auto-cleanup: Closing {len(self._sessions)} Fargate sessions on exit...")
                # ëª¨ë“  ì„¸ì…˜ ì •ë¦¬
                for request_id in list(self._sessions.keys()):
                    self.cleanup_session(request_id)

            # âœ… ëª¨ë“  HTTP í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬
            if self._http_clients:
                logger.info(f"ğŸ§¹ Auto-cleanup: Clearing {len(self._http_clients)} HTTP clients...")
                self._http_clients.clear()

            # âœ… ëª¨ë“  ì‹¤íŒ¨ ì¹´ìš´í„° ì •ë¦¬
            if self._session_creation_failures:
                logger.info(f"ğŸ§¹ Auto-cleanup: Clearing {len(self._session_creation_failures)} failure counters...")
                self._session_creation_failures.clear()

            # âœ… ëª¨ë“  cleanup ì¶”ì  ì •ë¦¬
            if self._cleaned_up_requests:
                logger.info(f"ğŸ§¹ Auto-cleanup: Clearing {len(self._cleaned_up_requests)} cleaned-up request trackers...")
                self._cleaned_up_requests.clear()
        except Exception as e:
            logger.warning(f"âš ï¸ Auto-cleanup failed: {e}")

# ê¸€ë¡œë²Œ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤)
global_fargate_session = GlobalFargateSessionManager()

def get_global_session():
    """ê¸€ë¡œë²Œ ì„¸ì…˜ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return global_fargate_session