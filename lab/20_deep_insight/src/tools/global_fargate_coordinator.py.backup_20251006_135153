#!/usr/bin/env python3
"""
Global Fargate Session Manager for Tools
도구들이 공유하는 글로벌 세션 매니저
"""

import logging
import sys
import os
import time
import boto3
import requests
import atexit
import subprocess
import json
from datetime import datetime

from src.tools.fargate_container_controller import SessionBasedFargateManager

# Simple logger setup
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

class GlobalFargateSessionManager:
    _instance = None
    _session_manager = None
    _sessions = {}  # {request_id: session_info} - 요청별 세션 관리
    _http_clients = {}  # {request_id: http_session} - 요청별 HTTP 클라이언트 (쿠키 격리)
    _used_container_ips = {}  # {container_ip: request_id} - IP 기반 컨테이너 소유권 추적
    _current_request_id = None  # 현재 컨텍스트의 요청 ID
    _retry_count = 0
    _max_retries = 2
    _session_creation_failures = {}  # {request_id: failure_count} - 세션 생성 실패 횟수 추적
    _max_session_failures = 3  # 최대 세션 생성 실패 허용 횟수
    _cleaned_up_requests = set()  # 이미 cleanup된 요청 ID 추적 (재생성 방지)

    # subprocess 기반 cookie acquisition helper script 경로
    _cookie_script_path = "/tmp/acquire_cookie.py"

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(GlobalFargateSessionManager, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if self._session_manager is None:
            logger.info("🚀 Initializing Global Fargate Session Manager")
            self._session_manager = SessionBasedFargateManager()
            atexit.register(self._auto_cleanup)

    def set_request_context(self, request_id: str):
        """현재 요청 컨텍스트 설정"""
        self._current_request_id = request_id
        logger.info(f"📋 Request context set: {request_id}")

    def _get_http_client(self, request_id: str):
        """요청별 HTTP 클라이언트 반환 (쿠키 격리)"""
        if request_id not in self._http_clients:
            import requests
            self._http_clients[request_id] = requests.Session()
            logger.info(f"🍪 Created new HTTP client for request {request_id}")
        return self._http_clients[request_id]

    def _acquire_cookie_for_ip(self, expected_ip: str) -> bool:
        """
        특정 IP의 컨테이너에 대한 Sticky Session 쿠키 획득 (IP 기반 검증)

        방법:
        - 각 시도마다 새로운 HTTP Client 생성
        - Cookie 없는 깨끗한 상태로 시작
        - 성공한 HTTP Client만 저장하여 이후 execution에서 재사용
        - ALB Round Robin을 활용하여 여러 컨테이너 중 타겟 찾기
        """
        max_attempts = 30  # 멀티 Job 환경에서는 더 많은 시도 필요

        logger.info(f"🍪 Acquiring cookie for container: {expected_ip}")
        other_ips = [ip for ip in self._used_container_ips.keys() if ip != expected_ip]
        if other_ips:
            logger.info(f"   Other active containers: {other_ips}")
        else:
            logger.info(f"   No other active containers")

        for attempt in range(1, max_attempts + 1):
            # ✅ 핵심: 매 시도마다 새로운 HTTP Client 생성 (TCP Connection 격리)
            http_client = requests.Session()

            actual_ip = 'unknown'  # finally 블록에서 사용하기 위한 초기화

            try:
                response = http_client.get(
                    f"{self._session_manager.alb_dns}/container-info",
                    timeout=5
                )

                if response.status_code == 200:
                    data = response.json()
                    actual_ip = data.get('private_ip', 'unknown')

                    # ✅ 핵심: 내 컨테이너인지 확인
                    if actual_ip == expected_ip:
                        if 'AWSALB' in http_client.cookies:
                            logger.info(f"✅ Cookie acquired! (attempt {attempt})")
                            logger.info(f"   My container IP: {actual_ip}")

                            # ✅ 성공! 이 HTTP Client를 저장 (이후 execution에서 재사용)
                            self._http_clients[self._current_request_id] = http_client
                            return True
                        else:
                            logger.debug(f"   Attempt {attempt}: Response from my container but no cookie yet")
                    else:
                        # 다른 Job의 컨테이너로 라우팅됨
                        if actual_ip in self._used_container_ips:
                            owner = self._used_container_ips[actual_ip]
                            logger.debug(f"🔄 Attempt {attempt}: Got other job's container")
                            logger.debug(f"   Response from: {actual_ip} (owner: {owner})")
                            logger.debug(f"   My container:  {expected_ip}")
                        else:
                            # 오래된 컨테이너 (cleanup 안 된 경우)
                            logger.debug(f"🔄 Attempt {attempt}: Got unregistered container: {actual_ip}")
                            logger.debug(f"   My container:  {expected_ip}")

                if attempt < max_attempts:
                    time.sleep(1)

            except Exception as e:
                logger.warning(f"⚠️ Attempt {attempt} failed: {e}")
                if attempt < max_attempts:
                    time.sleep(1)

            finally:
                # ✅ 실패한 시도의 HTTP Client는 명시적으로 종료 (메모리 누수 방지)
                # 성공한 경우는 이미 _http_clients에 저장되어 return되므로 종료하지 않음
                if actual_ip != expected_ip:
                    http_client.close()

        logger.error(f"❌ Failed to acquire cookie after {max_attempts} attempts")
        logger.error(f"   Expected IP: {expected_ip}")
        logger.error(f"   Registered IPs: {list(self._used_container_ips.keys())}")
        return False

    def ensure_session(self):
        """세션이 없거나 비활성화된 경우 새 세션 생성 (요청별 세션 관리)"""
        try:
            if not self._current_request_id:
                raise Exception("Request context not set. Call set_request_context() first.")

            # ✅ 세션 생성 실패 횟수 체크
            failure_count = self._session_creation_failures.get(self._current_request_id, 0)
            if failure_count >= self._max_session_failures:
                error_msg = f"❌ FATAL: Session creation failed {failure_count} times for request {self._current_request_id}. Terminating workflow to prevent resource waste."
                logger.error(error_msg)
                raise Exception(error_msg)

            # ✅ 이미 cleanup된 요청은 새 세션 생성 금지 (중복 컨테이너 방지)
            if self._current_request_id in self._cleaned_up_requests:
                error_msg = f"❌ FATAL: Request {self._current_request_id} already cleaned up - cannot create new session. This prevents duplicate container creation after workflow completion."
                logger.error(error_msg)
                raise Exception(error_msg)

            # 현재 요청의 세션 확인
            if self._current_request_id in self._sessions:
                # 기존 세션 재사용
                session_info = self._sessions[self._current_request_id]
                logger.info(f"♻️ Reusing existing session for request {self._current_request_id}: {session_info['session_id']}")

                # SessionBasedFargateManager의 current_session 업데이트
                self._session_manager.current_session = session_info['fargate_session']

                # ✅ HTTP Session도 재주입 (세션 재사용 시에도 필요)
                http_client = self._get_http_client(self._current_request_id)
                self._session_manager.set_http_session(http_client)

                return True

            # 새 세션 생성
            logger.info(f"📦 Creating new Fargate session for request {self._current_request_id}...")
            timestamp_id = datetime.now().strftime("%Y-%m-%d-%H-%M-%S")

            try:
                fargate_session_info = self._session_manager.create_session(
                    session_id=timestamp_id,
                    max_executions=300
                )

                # ✅ HTTP Session 주입 (요청별 쿠키 격리)
                http_client = self._get_http_client(self._current_request_id)
                self._session_manager.set_http_session(http_client)
                logger.info(f"🔗 HTTP session injected for request {self._current_request_id}")

                # ✅ 컨테이너 IP 등록 (AWS VPC가 유니크한 IP 보장)
                expected_private_ip = self._session_manager.current_session['private_ip']
                self._used_container_ips[expected_private_ip] = self._current_request_id
                logger.info(f"📝 Registered container IP: {expected_private_ip}")
                logger.info(f"   Request ID: {self._current_request_id}")
                logger.info(f"   All registered IPs: {list(self._used_container_ips.keys())}")

                # ✅ 세션을 딕셔너리에 저장 (IP 정보 포함)
                self._sessions[self._current_request_id] = {
                    'session_id': fargate_session_info['session_id'],
                    'request_id': self._current_request_id,
                    'container_ip': expected_private_ip,
                    'fargate_session': self._session_manager.current_session,
                    'created_at': datetime.now()
                }
                logger.info(f"✅ Session created and saved for request {self._current_request_id}: {fargate_session_info['session_id']}")

                # ⏰ ALB 트래픽 라우팅 안정화 대기 (health check 통과 후 추가 시간 필요)
                logger.info(f"⏰ Waiting for ALB to stabilize traffic routing (10 seconds)...")
                time.sleep(10)

                # 🍪 IP 기반 쿠키 획득
                cookie_acquired = self._acquire_cookie_for_ip(expected_private_ip)

                if not cookie_acquired:
                    # 쿠키 획득 실패 → IP 등록 해제
                    logger.warning(f"⚠️ Failed to acquire Sticky Session cookie")
                    logger.warning(f"   Releasing IP registration: {expected_private_ip}")
                    if expected_private_ip in self._used_container_ips:
                        del self._used_container_ips[expected_private_ip]
                    logger.warning(f"   Session is saved and will retry on next execution")
                    return True

                logger.info(f"   Total active sessions: {len(self._sessions)}")

                # ✅ 세션 생성 성공 - 실패 카운터 리셋
                if self._current_request_id in self._session_creation_failures:
                    del self._session_creation_failures[self._current_request_id]

                self._retry_count = 0
                return True

            except Exception as create_error:
                logger.error(f"❌ Session creation failed: {create_error}")

                # ✅ 세션 생성 실패 - 카운터 증가
                failure_count = self._session_creation_failures.get(self._current_request_id, 0)
                self._session_creation_failures[self._current_request_id] = failure_count + 1
                logger.warning(f"⚠️ Session creation failure count for request {self._current_request_id}: {failure_count + 1}/{self._max_session_failures}")

                # 세션 생성 자체가 실패한 경우만 cleanup
                if self._current_request_id in self._sessions:
                    del self._sessions[self._current_request_id]
                self._cleanup_orphaned_containers()
                raise

        except Exception as e:
            logger.error(f"❌ Failed to ensure session: {e}")

            # ✅ 치명적 에러는 재발생 (워크플로우 중단)
            if "FATAL" in str(e):
                raise

            return False

    def execute_code(self, code: str, description: str = ""):
        """코드 실행 with 자동 세션 관리 및 연결 재시도"""
        max_retries = 3
        retry_delay = 2  # seconds

        for attempt in range(1, max_retries + 1):
            try:
                # 세션 확인 및 생성
                if not self.ensure_session():
                    return {"error": "Failed to create or maintain session"}

                # 코드 실행
                result = self._session_manager.execute_code(code, description)

                # 성공하면 바로 반환
                return result

            except Exception as e:
                error_msg = str(e)

                # 연결 관련 에러인지 확인
                is_connection_error = any(keyword in error_msg.upper() for keyword in [
                    "CONNECTION FAILED",
                    "NOT RESPONDING",
                    "TIMEOUT",
                    "CONNECTIONERROR",
                    "HTTPERROR"
                ])

                if is_connection_error:
                    # 연결 에러 - 재시도
                    logger.warning(f"⚠️ Connection error (attempt {attempt}/{max_retries}): {error_msg}")

                    if attempt < max_retries:
                        logger.info(f"🔄 Retrying in {retry_delay} seconds...")
                        time.sleep(retry_delay)
                    else:
                        logger.error(f"❌ Connection failed after {max_retries} attempts. Giving up.")
                        return {
                            "error": f"Connection failed after {max_retries} attempts: {error_msg}"
                        }
                else:
                    # 코드 실행 에러 등 - 재시도 안 함
                    logger.error(f"❌ Code execution failed: {e}")
                    # ⚠️ 세션을 None으로 리셋하지 않음!
                    # 컨테이너 통신 에러가 발생해도 다음 Agent가 재시도할 수 있도록 세션 유지
                    # 여러 Agent가 같은 컨테이너를 공유해야 하므로 세션 초기화 금지
                    return {"error": str(e)}

    def get_session_info(self):
        """현재 요청의 세션 정보 반환"""
        if not self._current_request_id:
            return {"status": "no_context"}

        if self._current_request_id in self._sessions:
            session_info = self._sessions[self._current_request_id]
            return {
                "request_id": self._current_request_id,
                "session_id": session_info['session_id'],
                "status": "active",
                "private_ip": session_info['fargate_session']['private_ip']
            }
        else:
            return {"status": "no_session", "request_id": self._current_request_id}

    def ensure_session_with_data(self, csv_file_path: str):
        """CSV 파일과 함께 세션 생성 (세션 확인 → S3 업로드 → 컨테이너 동기화)"""
        try:
            logger.info(f"🚀 Creating session with data: {csv_file_path}")

            # ✅ 1. 먼저 세션 생성 (Timestamp 생성)
            if not self.ensure_session():
                raise Exception("Failed to create Fargate session")

            # ✅ 2. 생성된 세션 ID를 사용하여 S3 업로드
            session_id = self._sessions[self._current_request_id]['session_id']
            s3_key = self._upload_csv_to_s3_with_session_id(csv_file_path, session_id)
            logger.info(f"📤 CSV uploaded to S3: {s3_key}")

            # 3. 컨테이너에 S3 → 로컬 동기화
            self._sync_csv_from_s3_to_container(s3_key)
            logger.info("✅ CSV file synced to container")

            return True

        except Exception as e:
            logger.error(f"❌ Failed to create session with data: {e}")
            return False

    def _upload_csv_to_s3_with_session_id(self, csv_file_path: str, session_id: str) -> str:
        """세션 ID를 받아서 S3에 업로드 (Timestamp 불일치 방지)"""
        try:
            # ✅ 세션 ID를 그대로 사용 (새 timestamp 생성 안함)
            import os
            original_filename = os.path.basename(csv_file_path)
            s3_key = f"manus/fargate_sessions/{session_id}/input/{original_filename}"

            # S3 업로드
            s3_client = boto3.client('s3', region_name='us-east-1')
            s3_client.upload_file(
                csv_file_path,
                'bedrock-logs-gonsoomoon',
                s3_key,
                ExtraArgs={'ContentType': 'text/csv'}
            )

            logger.info(f"📤 Uploaded {csv_file_path} → s3://bedrock-logs-gonsoomoon/{s3_key}")
            return s3_key

        except Exception as e:
            logger.error(f"❌ S3 upload failed: {e}")
            raise

    def _upload_csv_to_s3(self, csv_file_path: str) -> str:
        """CSV 파일을 S3에 업로드 (레거시 - 새 timestamp 생성)"""
        try:
            # 현재 세션 ID 기반 S3 키 생성
            timestamp_id = datetime.now().strftime("%Y-%m-%d-%H-%M-%S")

            # 원본 파일명 추출
            import os
            original_filename = os.path.basename(csv_file_path)
            s3_key = f"manus/fargate_sessions/{timestamp_id}/input/{original_filename}"

            # S3 업로드
            s3_client = boto3.client('s3', region_name='us-east-1')
            s3_client.upload_file(
                csv_file_path,
                'bedrock-logs-gonsoomoon',
                s3_key,
                ExtraArgs={'ContentType': 'text/csv'}
            )

            logger.info(f"📤 Uploaded {csv_file_path} → s3://bedrock-logs-gonsoomoon/{s3_key}")
            return s3_key

        except Exception as e:
            logger.error(f"❌ S3 upload failed: {e}")
            raise

    def _sync_csv_from_s3_to_container(self, s3_key: str):
        """S3에서 컨테이너로 CSV 파일 동기화 (Enhanced Logging)"""
        try:
            # ALB DNS (세션 매니저에서 가져오기)
            alb_dns = self._session_manager.alb_dns
            filename = s3_key.split('/')[-1]

            # ✅ 1. 시작 로그
            logger.info(f"🔄 Starting file sync...")
            logger.info(f"   S3 Key: {s3_key}")
            logger.info(f"   Filename: {filename}")
            logger.info(f"   Target: /app/data/{filename}")

            # 파일 동기화 요청
            # s3_key 형태: "manus/fargate_sessions/{session_id}/input/file.csv"
            sync_request = {
                "action": "sync_data_from_s3",
                "bucket_name": "bedrock-logs-gonsoomoon",
                "s3_key_prefix": f"manus/fargate_sessions/{s3_key.split('/')[2]}/input/",
                "local_path": "/app/data/"
            }

            # ✅ 2. 요청 로그
            logger.info(f"📤 Sending file sync request:")
            logger.info(f"   URL: {alb_dns}/file-sync")
            logger.info(f"   Request: {sync_request}")

            # ✅ 요청별 HTTP 클라이언트 사용 (쿠키 격리)
            http_client = self._get_http_client(self._current_request_id)
            response = http_client.post(
                f"{alb_dns}/file-sync",
                json=sync_request,
                timeout=30
            )

            # ✅ 3. 응답 로그
            logger.info(f"📥 File sync response:")
            logger.info(f"   Status: {response.status_code}")
            logger.info(f"   Body: {response.text[:500]}")  # 처음 500자만

            if response.status_code != 200:
                logger.error(f"❌ File sync failed with status {response.status_code}")
                raise Exception(f"File sync failed: {response.text}")

            result = response.json()
            files_count = result.get('files_count', 0)
            downloaded_files = result.get('downloaded_files', [])

            # ✅ 4. 결과 로그
            logger.info(f"✅ File sync completed:")
            logger.info(f"   Files synced: {files_count}")
            logger.info(f"   Downloaded: {downloaded_files}")

            # ✅ 5. 대기 시작 로그
            import time
            logger.info("⏳ Waiting 10 seconds for file sync to complete...")
            time.sleep(10)  # 10초 대기 (파일 동기화 완료 시간)

            # ✅ 6. 대기 완료 로그
            logger.info("✅ File sync wait complete")

        except Exception as e:
            logger.error(f"❌ File sync failed: {e}")
            logger.error(f"   Exception type: {type(e).__name__}")
            logger.error(f"   Exception details: {str(e)[:1000]}")
            raise

    def _cleanup_orphaned_containers(self):
        """세션 생성 실패 시 현재 요청의 컨테이너만 정리 (다른 요청의 컨테이너는 보호)"""
        try:
            import boto3
            ecs_client = boto3.client('ecs', region_name='us-east-1')

            # 현재 요청의 Task ARN 확인
            current_task_arn = None
            if self._current_request_id and self._current_request_id in self._sessions:
                session_info = self._sessions[self._current_request_id]
                fargate_session = session_info.get('fargate_session', {})
                current_task_arn = fargate_session.get('task_arn')

            if not current_task_arn:
                logger.warning(f"⚠️ No task ARN found for current request {self._current_request_id} - skipping cleanup")
                return

            # ✅ 현재 요청의 컨테이너만 종료 (다른 요청의 컨테이너는 건드리지 않음)
            try:
                logger.info(f"🧹 Cleaning up orphaned container for request {self._current_request_id}: {current_task_arn.split('/')[-1][:12]}...")
                ecs_client.stop_task(
                    cluster='my-fargate-cluster',
                    task=current_task_arn,
                    reason=f'Session creation failed - cleanup (request: {self._current_request_id})'
                )
                logger.info(f"   ✅ Stopped container: {current_task_arn.split('/')[-1][:12]}")
            except Exception as stop_error:
                logger.warning(f"   ⚠️ Failed to stop container {current_task_arn.split('/')[-1][:12]}: {stop_error}")

        except Exception as e:
            logger.warning(f"⚠️ Orphaned container cleanup failed: {e}")

    def cleanup_session(self, request_id: str = None):
        """특정 요청의 세션 정리"""
        try:
            # request_id가 없으면 현재 컨텍스트 사용
            cleanup_request_id = request_id or self._current_request_id

            if not cleanup_request_id:
                logger.warning("⚠️ No request ID for cleanup")
                return

            if cleanup_request_id in self._sessions:
                session_info = self._sessions[cleanup_request_id]
                logger.info(f"🧹 Cleaning up session for request {cleanup_request_id}: {session_info['session_id']}")

                # ✅ 컨테이너 IP 해제
                container_ip = session_info.get('container_ip')
                if container_ip and container_ip in self._used_container_ips:
                    del self._used_container_ips[container_ip]
                    logger.info(f"🧹 Released container IP: {container_ip}")
                    logger.info(f"   Remaining IPs: {list(self._used_container_ips.keys())}")

                # SessionBasedFargateManager의 current_session 설정
                self._session_manager.current_session = session_info['fargate_session']
                self._session_manager.complete_session()

                # 세션 딕셔너리에서 제거
                del self._sessions[cleanup_request_id]
                logger.info(f"✅ Session cleanup completed. Remaining sessions: {len(self._sessions)}")
            else:
                logger.warning(f"⚠️ No session found for request {cleanup_request_id}")

            # ✅ HTTP 클라이언트도 정리 (쿠키 제거)
            if cleanup_request_id in self._http_clients:
                del self._http_clients[cleanup_request_id]
                logger.info(f"🍪 Removed HTTP client for request {cleanup_request_id}")

            # ✅ 실패 카운터도 정리
            if cleanup_request_id in self._session_creation_failures:
                del self._session_creation_failures[cleanup_request_id]
                logger.info(f"🧹 Cleared failure counter for request {cleanup_request_id}")

            # ✅ cleanup된 요청 ID를 추적 (재생성 방지)
            self._cleaned_up_requests.add(cleanup_request_id)
            logger.info(f"🔒 Request {cleanup_request_id} marked as cleaned up - new session creation blocked")

        except Exception as e:
            logger.error(f"❌ Session cleanup failed: {e}")

    def _auto_cleanup(self):
        """프로그램 종료 시 자동으로 모든 세션 정리"""
        try:
            if self._sessions:
                logger.info(f"🧹 Auto-cleanup: Closing {len(self._sessions)} Fargate sessions on exit...")
                # 모든 세션 정리
                for request_id in list(self._sessions.keys()):
                    self.cleanup_session(request_id)

            # ✅ 모든 HTTP 클라이언트 정리
            if self._http_clients:
                logger.info(f"🧹 Auto-cleanup: Clearing {len(self._http_clients)} HTTP clients...")
                self._http_clients.clear()

            # ✅ 모든 실패 카운터 정리
            if self._session_creation_failures:
                logger.info(f"🧹 Auto-cleanup: Clearing {len(self._session_creation_failures)} failure counters...")
                self._session_creation_failures.clear()

            # ✅ 모든 cleanup 추적 정리
            if self._cleaned_up_requests:
                logger.info(f"🧹 Auto-cleanup: Clearing {len(self._cleaned_up_requests)} cleaned-up request trackers...")
                self._cleaned_up_requests.clear()
        except Exception as e:
            logger.warning(f"⚠️ Auto-cleanup failed: {e}")

# 글로벌 인스턴스 (싱글톤)
global_fargate_session = GlobalFargateSessionManager()

def get_global_session():
    """글로벌 세션 매니저 인스턴스 반환"""
    return global_fargate_session