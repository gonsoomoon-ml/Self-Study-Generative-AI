"""
AgentCore Runtime - Enhanced entry point for the Strands Agent Demo with AgentCore integration.
Based on main.py with AgentCore-specific enhancements.
"""
import os
import sys
import shutil
import asyncio
import atexit
import signal
import time
import subprocess
from dotenv import load_dotenv
from bedrock_agentcore.runtime import BedrockAgentCoreApp
from src.utils.strands_sdk_utils import strands_utils
from src.graph.builder import build_graph

# Load environment variables
load_dotenv()

# Observability
from opentelemetry import trace
from opentelemetry import context as otel_context
from src.utils.agentcore_observability import set_session_context, add_span_event

# Import event queue for unified event processing
from src.utils.event_queue import clear_queue

# Import Fargate session manager for cleanup
from src.tools.global_fargate_coordinator import get_global_session

# Initialize AgentCore app
app = BedrockAgentCoreApp()

def remove_artifact_folder(folder_path="./artifacts/"):
    """
    ./artifact/ í´ë”ê°€ ì¡´ì¬í•˜ë©´ ì‚­ì œí•˜ëŠ” í•¨ìˆ˜

    Args:
        folder_path (str): ì‚­ì œí•  í´ë” ê²½ë¡œ
    """
    if os.path.exists(folder_path):
        print(f"'{folder_path}' í´ë”ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤...")
        try:
            shutil.rmtree(folder_path)
            print(f"'{folder_path}' í´ë”ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
    else:
        print(f"'{folder_path}' í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

def cleanup_fargate_session():
    """Enhanced Fargate session cleanup with guaranteed task termination"""
    try:
        # 1. ì •ìƒì ì¸ ì„¸ì…˜ ì •ë¦¬ ì‹œë„
        fargate_manager = get_global_session()
        if fargate_manager and fargate_manager._session_manager and fargate_manager._session_manager.current_session:
            print("\nğŸ§¹ Starting final Fargate session cleanup...", flush=True)

            # ì„¸ì…˜ ì™„ë£Œ ì‹ í˜¸ ì „ì†¡ + S3 ì—…ë¡œë“œ ì™„ë£Œ ëŒ€ê¸°
            print("ğŸ“¤ Initiating final S3 upload and waiting for completion...", flush=True)
            completion_result = fargate_manager._session_manager.complete_session(wait_for_s3=True)

            if completion_result and completion_result.get("status") == "success":
                print("âœ… S3 upload confirmed - all Fargate artifacts uploaded", flush=True)
            else:
                print("âš ï¸ S3 upload status unclear, but proceeding with cleanup", flush=True)

        # 2. ê°•ì œë¡œ ëª¨ë“  Fargate íƒœìŠ¤í¬ ì •ë¦¬ (fail-safe)
        print("ğŸ” Checking for any remaining Fargate tasks...", flush=True)
        try:
            result = subprocess.run([
                'aws', 'ecs', 'list-tasks',
                '--cluster', 'my-fargate-cluster',
                '--query', 'taskArns[*]',
                '--output', 'text'
            ], capture_output=True, text=True, timeout=30)

            if result.returncode == 0 and result.stdout.strip():
                task_arns = result.stdout.strip().split('\t')
                task_ids = [arn.split('/')[-1] for arn in task_arns if arn.strip()]

                if task_ids:
                    print(f"ğŸ›‘ Found {len(task_ids)} running tasks, terminating...", flush=True)
                    for task_id in task_ids:
                        subprocess.run([
                            'aws', 'ecs', 'stop-task',
                            '--cluster', 'my-fargate-cluster',
                            '--task', task_id
                        ], capture_output=True, timeout=20)
                        print(f"   â€¢ Stopped task: {task_id[:12]}...", flush=True)
                    print("âœ… All orphaned Fargate tasks terminated", flush=True)
                else:
                    print("âœ… No running Fargate tasks found", flush=True)
            else:
                print("â„¹ï¸ Could not list Fargate tasks (cluster may not exist)", flush=True)

        except subprocess.TimeoutExpired:
            print("âš ï¸ Timeout while checking Fargate tasks", flush=True)
        except Exception as cleanup_error:
            print(f"âš ï¸ Error during task cleanup: {cleanup_error}", flush=True)

        print("âœ… Fargate session cleanup completed", flush=True)
    except Exception as e:
        print(f"âš ï¸ Error during Fargate session cleanup: {e}", flush=True)

def signal_handler(signum, frame):
    """Enhanced signal handler with immediate cleanup"""
    print(f"\nğŸ›‘ Received signal {signum}, initiating graceful shutdown...", flush=True)

    # ì¦‰ì‹œ cleanup ì‹¤í–‰ (atexitê³¼ ë³„ë„ë¡œ)
    cleanup_fargate_session()

    # ì§§ì€ ëŒ€ê¸° í›„ ê°•ì œ ì¢…ë£Œ
    time.sleep(2)
    print("ğŸ”š Process terminating...", flush=True)
    sys.exit(0)

def _setup_execution():
    """Initialize execution environment"""
    remove_artifact_folder()
    clear_queue()

    # âš ï¸ cleanup_fargate_sessionì€ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì‹œì—ë§Œ ì‹¤í–‰ë˜ì–´ì•¼ í•¨
    # ìš”ì²­ë³„ ì •ë¦¬ëŠ” finally ë¸”ë¡ì—ì„œ cleanup_session(request_id)ë¡œ ì²˜ë¦¬
    # atexitëŠ” ìµœì´ˆ 1íšŒë§Œ ë“±ë¡ (ì¤‘ë³µ ë°©ì§€)

    print("\n=== Starting AgentCore Runtime Event Stream ===")
    print("ğŸ”§ Request-level cleanup will be handled in finally block")

def _print_conversation_history():
    """Print final conversation history"""
    print("\n=== Conversation History ===")
    from src.graph.nodes import _global_node_states
    shared_state = _global_node_states.get('shared', {})
    history = shared_state.get('history', [])

    if history:
        for hist_item in history:
            print(f"[{hist_item['agent']}] {hist_item['message']}")
    else:
        print("No conversation history found")

@app.entrypoint
async def agentcore_streaming_execution(payload, context):
    """
    Execute full graph streaming workflow through AgentCore Runtime
    Enhanced with Fargate session management and observability

    Args:
        payload: Request payload containing user query and configuration
        context: AgentCore runtime context for ping/health management
    """

    _setup_execution()

    # ê³ ìœ  ìš”ì²­ ID ìƒì„±
    import uuid
    request_id = str(uuid.uuid4())
    print(f"\n{'='*60}")
    print(f"ğŸ†” Request ID: {request_id}")
    print(f"{'='*60}\n", flush=True)

    # Fargate ì„¸ì…˜ ë§¤ë‹ˆì €ì— ìš”ì²­ ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
    try:
        fargate_manager = get_global_session()
        fargate_manager.set_request_context(request_id)
        print(f"âœ… Fargate session context set for request: {request_id}", flush=True)
    except Exception as e:
        print(f"âš ï¸ Failed to set Fargate session context: {e}", flush=True)

    # Get user query from payload - AgentCore uses 'prompt' key
    user_query = payload.get("prompt", "")

    # Fall back to 'user_query' for compatibility
    if not user_query:
        user_query = payload.get("user_query", "")

    # Use default query if none provided
    if not user_query:
        # user_query = "'./data/Dat-fresh-food-claude.csv'ë¥¼ ì½ì–´ì„œ ì´ ë§¤ì¶œì•¡ ê³„ì‚°í•˜ê³  ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„ê³¼ ì›”ë³„ ì¶”ì„¸ ì°¨íŠ¸ë¥¼ ìƒì„±í•œ í›„ ì¢…í•© PDF ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì¤˜"
        user_query = "'./data/Dat-fresh-food-claude.csv'ë¥¼ ì½ì–´ì„œ ì´ ë§¤ì¶œì•¡ ê³„ì‚°í•˜ê³  ê°„ë‹¨í•œ ì°¨íŠ¸ í•˜ë‚˜ë§Œ ê·¸ë ¤ì„œ pdfë¡œ í•´ì¤˜"

    context_token = set_session_context("agentcore-session")

    # Register async task to prevent 15-minute timeout during long-running streaming
    # AWS Official API: https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/runtime-long-run.html
    # âš ï¸ REMOVED: app.add_async_task() causes 94-second early termination
    # Root cause: AgentCore expects first yield event quickly when async task is registered
    # Our Health Check takes 60-90s, causing initial response timeout
    # WITHOUT async task: Health Check completes successfully âœ…
    # WITH async task: Connection terminates at 94s âŒ
    # task_id = app.add_async_task(
    #     "streaming_workflow",
    #     {
    #         "request_id": request_id,
    #         "query": user_query,
    #         "runtime": "bedrock_manus_agentcore"
    #     }
    # )
    # print(f"ğŸš€ Registered async task: {task_id} (auto HEALTHY_BUSY)", flush=True)

    try:
        # Get tracer for AgentCore application
        tracer = trace.get_tracer(
            instrumenting_module_name=os.getenv("TRACER_MODULE_NAME", "agentcore_insight_extractor"),
            instrumenting_library_version=os.getenv("TRACER_LIBRARY_VERSION", "2.0.0")
        )

        with tracer.start_as_current_span("agentcore_session") as span:

            # Build graph with AgentCore configuration
            graph = build_graph()

            # Prepare input for AgentCore-enhanced graph execution
            graph_input = {
                "request": user_query,
                "request_prompt": f"AgentCore Request: <user_request>{user_query}</user_request>",
                "agentcore_enabled": True,
                "runtime_source": "bedrock_manus_agentcore"
            }

            # CSV íŒŒì¼ ê²½ë¡œ ì¶”ê°€ (payloadì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©)
            csv_file_path = payload.get("csv_file_path", "./data/Dat-fresh-food-claude.csv")
            graph_input["csv_file_path"] = csv_file_path

            # AgentCore ë©”íƒ€ë°ì´í„° ì¶”ê°€
            agentcore_metadata = payload.get("agentcore_metadata", {
                "runtime": "agentcore",
                "version": "2.0",
                "fargate_enabled": True
            })
            graph_input["agentcore_metadata"] = agentcore_metadata

            print(f"ğŸš€ Launching AgentCore Runtime with query: {user_query[:100]}...")

            event_count = 0

            # Stream events from graph execution
            async for event in graph.stream_async(graph_input):
                event_count += 1

                # Add AgentCore runtime metadata to each event
                event["event_id"] = event_count
                event["runtime_source"] = "bedrock_manus_agentcore"

                # Mark final event
                if event.get("type") == "workflow_complete":
                    event["total_events"] = event_count
                    event["message"] = "All events processed through AgentCore Runtime"

                yield event

            _print_conversation_history()
            print("=== AgentCore Runtime Event Stream Complete ===")

            # Add AgentCore Event
            add_span_event(span, "agentcore_query", {
                "user-query": str(user_query),
                "agentcore-enabled": True,
                "total-events": event_count
            })

    finally:
        # Complete async task to signal streaming finished
        # âš ï¸ REMOVED: app.complete_async_task() (no task_id since app.add_async_task was removed)
        # print("ğŸ Completing async task...", flush=True)
        # try:
        #     app.complete_async_task(task_id)
        #     print(f"âœ… Async task completed: {task_id}", flush=True)
        # except Exception as task_error:
        #     print(f"âš ï¸ Error completing async task: {task_error}", flush=True)

        # ìš”ì²­ ì¢…ë£Œ ì‹œ Fargate ì„¸ì…˜ ì •ë¦¬ (ìš”ì²­ ID ê¸°ë°˜)
        try:
            fargate_manager = get_global_session()
            print(f"\nğŸ§¹ Request {request_id} completed - cleaning up Fargate session...", flush=True)
            fargate_manager.cleanup_session(request_id)
            print(f"âœ… Fargate session cleaned up for request {request_id}", flush=True)
        except Exception as cleanup_error:
            print(f"âš ï¸ Failed to cleanup Fargate session for request {request_id}: {cleanup_error}", flush=True)

        otel_context.detach(context_token)

if __name__ == "__main__":
    # í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì‹œì—ë§Œ ì‹¤í–‰ë˜ëŠ” cleanup ë“±ë¡ (1íšŒë§Œ)
    atexit.register(cleanup_fargate_session)
    signal.signal(signal.SIGINT, signal_handler)   # Ctrl+C
    signal.signal(signal.SIGTERM, signal_handler)  # Termination

    # Run with AgentCore app.run()
    print("=" * 60)
    print("ğŸ¤– AgentCore Runtime v2.0 with async task management")
    print("=" * 60)
    app.run()