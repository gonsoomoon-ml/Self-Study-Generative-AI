#!/usr/bin/env python3
"""
Dynamic Code Executor for Fargate V2 - HTTP Server Version
300ë²ˆì˜ ì½”ë“œ ì‹¤í–‰ ìš”ì²­ì„ ì²˜ë¦¬í•˜ê³  ì„¸ì…˜ ì™„ë£Œ ì‹œ S3ì— ì—…ë¡œë“œ
"""

import sys
import os
import json
import uuid
import traceback
import threading
import time
import subprocess
import re
from datetime import datetime
from io import StringIO
import contextlib
import boto3
from flask import Flask, request, jsonify
from pathlib import Path
import shutil

app = Flask(__name__)

# ê¸€ë¡œë²Œ ìƒíƒœ ê´€ë¦¬
class SessionManager:
    def __init__(self):
        self.session_id = os.environ.get('SESSION_ID', str(uuid.uuid4())[:8])
        self.executions = []
        self.max_executions = 300
        self.start_time = datetime.now()
        self.is_complete = False
        self.workspace = f"/tmp/session_{self.session_id}"
        os.makedirs(self.workspace, exist_ok=True)

        # File I/Oë¥¼ ìœ„í•œ dataì™€ artifacts ë””ë ‰í† ë¦¬ ìƒì„±
        self.data_dir = "/app/data"
        self.artifacts_dir = "/app/artifacts"
        os.makedirs(self.data_dir, exist_ok=True)
        os.makedirs(self.artifacts_dir, exist_ok=True)

    def add_execution(self, result):
        self.executions.append(result)
        execution_num = len(self.executions)

        # ë¡œì»¬ì— ê° ì‹¤í–‰ ê²°ê³¼ ì €ì¥
        output_file = f"{self.workspace}/execution_{execution_num}.json"

        # execution_time_msë¥¼ duration_msë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
        save_result = result.copy()
        if 'execution_time_ms' in save_result:
            save_result['duration_ms'] = save_result.pop('execution_time_ms')

        with open(output_file, 'w') as f:
            json.dump(save_result, f, indent=2)

        print(f"ğŸ’¾ Saved execution {execution_num} to {output_file}", flush=True)

        # 300ë²ˆ ì‹¤í–‰ ì™„ë£Œ ì²´í¬ ë˜ëŠ” ê°•ì œ ì—…ë¡œë“œ ì¡°ê±´
        if execution_num >= self.max_executions:
            self.complete_session()

        # 1íšŒ ì‹¤í–‰ë§ˆë‹¤ ì¤‘ê°„ ì €ì¥ (ë””ë²„ê¹…ìš©) - âœ… DISABLED: S3 upload only at session completion
        # ì´ìœ : Mid-session S3 uploadê°€ Flaskë¥¼ blockingí•˜ì—¬ ë‹¤ìŒ ìš”ì²­ ì²˜ë¦¬ ì§€ì—° ë°œìƒ (HTTP 502)
        # PDF ìƒì„± ì™„ë£Œ í›„ session complete ì‹œ í•œë²ˆì— ëª¨ë“  íŒŒì¼ ì—…ë¡œë“œ
        # else:
        #     print(f"ğŸ”„ Mid-session S3 backup at execution {execution_num}", flush=True)
        #     try:
        #         session_result = {
        #             "session_id": self.session_id,
        #             "status": "in_progress",
        #             "start_time": str(self.start_time),
        #             "current_time": str(datetime.now()),
        #             "executions": self.executions,
        #             "backup_execution": execution_num
        #         }
        #         self.upload_to_s3(session_result)
        #     except Exception as e:
        #         print(f"âš ï¸ Mid-session backup failed: {e}", flush=True)

    def complete_session(self):
        """ì„¸ì…˜ ì™„ë£Œ ì²˜ë¦¬ - ëª¨ë“  ê²°ê³¼ë¥¼ S3ì— ì—…ë¡œë“œ"""
        if self.is_complete:
            return

        self.is_complete = True
        print(f"ğŸ Session {self.session_id} complete. Uploading to S3...", flush=True)

        try:
            # ì „ì²´ ì„¸ì…˜ ê²°ê³¼ ìƒì„±
            session_result = {
                "session_id": self.session_id,
                "total_executions": len(self.executions),
                "start_time": str(self.start_time),
                "end_time": str(datetime.now()),
                "executions": self.executions
            }

            # S3ì— ì—…ë¡œë“œ
            self.upload_to_s3(session_result)

            print(f"âœ… Session {self.session_id} uploaded to S3", flush=True)
        except Exception as e:
            print(f"âŒ Failed to upload session to S3: {e}", flush=True)

    def upload_to_s3(self, session_result):
        """S3ì— ì„¸ì…˜ ê²°ê³¼ ë° ìƒì„±ëœ íŒŒì¼ë“¤ ì—…ë¡œë“œ"""
        s3_client = boto3.client('s3', region_name='us-east-1')
        bucket = "bedrock-logs-gonsoomoon"

        print(f"â˜ï¸ Starting S3 upload to s3://{bucket}/manus/fargate_sessions/{self.session_id}/", flush=True)

        # ì „ì²´ ì„¸ì…˜ ê²°ê³¼ë¥¼ debug í´ë”ì— ì €ì¥
        s3_key = f"manus/fargate_sessions/{self.session_id}/debug/session_status.json"
        s3_client.put_object(
            Bucket=bucket,
            Key=s3_key,
            Body=json.dumps(session_result, indent=2),
            ContentType='application/json'
        )
        print(f"  ğŸ“„ Uploaded debug/session_status.json", flush=True)

        # ê°œë³„ ì‹¤í–‰ ê²°ê³¼ë“¤ì„ debug í´ë”ì— ì €ì¥
        for i, execution in enumerate(self.executions, 1):
            s3_key = f"manus/fargate_sessions/{self.session_id}/debug/execution_{i}.json"
            s3_client.put_object(
                Bucket=bucket,
                Key=s3_key,
                Body=json.dumps(execution, indent=2),
                ContentType='application/json'
            )
        print(f"  ğŸ“„ Uploaded {len(self.executions)} execution result files to debug/", flush=True)

        # artifacts í´ë” ì—…ë¡œë“œ (ìƒì„±ëœ íŒŒì¼ë“¤) - ì¦‰ì‹œ ì—…ë¡œë“œ í™œì„±í™”
        artifacts_path = "/app/artifacts"
        if os.path.exists(artifacts_path):
            artifacts_uploaded = self._upload_directory_to_s3(
                s3_client, bucket, artifacts_path,
                f"manus/fargate_sessions/{self.session_id}/artifacts"
            )
            print(f"  ğŸ“ Uploaded {artifacts_uploaded} files from artifacts/", flush=True)

        # data í´ë” ì—…ë¡œë“œ (ìƒì„±ëœ ë°ì´í„° íŒŒì¼ë“¤)
        data_path = "/app/data"
        if os.path.exists(data_path):
            data_uploaded = self._upload_directory_to_s3(
                s3_client, bucket, data_path,
                f"manus/fargate_sessions/{self.session_id}/data"
            )
            print(f"  ğŸ“ Uploaded {data_uploaded} files from data/", flush=True)

        print(f"âœ… S3 upload completed for session {self.session_id}", flush=True)

    def _upload_directory_to_s3(self, s3_client, bucket, local_dir, s3_prefix):
        """ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  íŒŒì¼ì„ S3ì— ì—…ë¡œë“œ"""
        uploaded_count = 0

        for root, dirs, files in os.walk(local_dir):
            for file in files:
                local_file_path = os.path.join(root, file)
                relative_path = os.path.relpath(local_file_path, local_dir)
                s3_key = f"{s3_prefix}/{relative_path}".replace('\\', '/')

                try:
                    # íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ContentType ì„¤ì •
                    content_type = 'application/octet-stream'
                    if file.endswith('.json'):
                        content_type = 'application/json'
                    elif file.endswith('.txt'):
                        content_type = 'text/plain'
                    elif file.endswith('.csv'):
                        content_type = 'text/csv'
                    elif file.endswith('.png'):
                        content_type = 'image/png'
                    elif file.endswith('.jpg') or file.endswith('.jpeg'):
                        content_type = 'image/jpeg'
                    elif file.endswith('.pdf'):
                        content_type = 'application/pdf'
                    elif file.endswith('.py'):
                        content_type = 'text/x-python'

                    s3_client.upload_file(
                        local_file_path, bucket, s3_key,
                        ExtraArgs={'ContentType': content_type}
                    )
                    uploaded_count += 1
                    print(f"    ğŸ“¤ {relative_path} â†’ s3://{bucket}/{s3_key}", flush=True)
                except Exception as e:
                    print(f"    âŒ Upload failed for {relative_path}: {e}", flush=True)

        return uploaded_count

# ì„¸ì…˜ ë§¤ë‹ˆì € ì´ˆê¸°í™”
session_manager = SessionManager()

def create_compact_error_response(exception, traceback_text=None):
    """
    ì—ëŸ¬ ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë°ì— ì í•©í•˜ë„ë¡ ê°„ì†Œí™”

    Args:
        exception: ë°œìƒí•œ ì˜ˆì™¸ ê°ì²´
        traceback_text: traceback.format_exc() ê²°ê³¼

    Returns:
        dict: ê°„ì†Œí™”ëœ ì—ëŸ¬ ì •ë³´
    """
    error_type = type(exception).__name__
    error_message = str(exception)

    # ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ (8192ì)
    if len(error_message) > 4096*2:
        error_message = error_message[:4096*2] + "..."

    # ë¼ì¸ ë²ˆí˜¸ ì¶”ì¶œ
    line_number = None
    if traceback_text:
        # "line 205"ì™€ ê°™ì€ íŒ¨í„´ì—ì„œ ë¼ì¸ ë²ˆí˜¸ ì¶”ì¶œ
        line_match = re.search(r'line (\d+)', traceback_text)
        if line_match:
            line_number = int(line_match.group(1))

    # ì—ëŸ¬ íƒ€ì…ë³„ í•µì‹¬ ì •ë³´ ì¶”ì¶œ
    key_info = extract_error_key_info(error_type, error_message, traceback_text)

    compact_error = {
        "type": error_type,
        "message": error_message,
        "line": line_number,
        "key_info": key_info
    }

    # traceback ì „ì²´ í¬í•¨ (8192ì ì œí•œ)
    if traceback_text:
        if len(traceback_text) > 4096*2:
            compact_error["traceback"] = traceback_text[:4096*2] + "..."
        else:
            compact_error["traceback"] = traceback_text

    return compact_error

def extract_error_key_info(error_type, error_message, traceback_text):
    """ì—ëŸ¬ íƒ€ì…ë³„ í•µì‹¬ ì •ë³´ ì¶”ì¶œ"""
    key_info = {}

    if error_type == "SyntaxError":
        # ë¬¸ë²• ì˜¤ë¥˜ì˜ ê²½ìš° êµ¬ì²´ì ì¸ ë¬¸ì œì  ì¶”ì¶œ
        if "invalid decimal literal" in error_message:
            key_info["issue"] = "Invalid number format (possibly CSS in Python code)"
        elif "format code" in error_message:
            key_info["issue"] = "f-string formatting error"
        elif "unexpected EOF" in error_message:
            key_info["issue"] = "Missing closing bracket or quote"

    elif error_type == "ValueError":
        if "Unknown format code" in error_message:
            key_info["issue"] = "f-string format specifier error"
        elif "Cannot specify" in error_message:
            key_info["issue"] = "Invalid format combination"

    elif error_type == "NameError":
        # ë³€ìˆ˜ëª… ì¶”ì¶œ
        if "is not defined" in error_message:
            var_match = re.search(r"'(\w+)' is not defined", error_message)
            if var_match:
                key_info["undefined_variable"] = var_match.group(1)

    elif error_type == "ImportError" or error_type == "ModuleNotFoundError":
        # ëª¨ë“ˆëª… ì¶”ì¶œ
        module_match = re.search(r"No module named '(\w+)'", error_message)
        if module_match:
            key_info["missing_module"] = module_match.group(1)

    return key_info

def create_compact_output(output_text, output_type="stdout", max_length=500):
    """
    stdout/stderr ì¶œë ¥ì„ ìŠ¤íŠ¸ë¦¬ë°ì— ì í•©í•˜ë„ë¡ ê°„ì†Œí™”

    Args:
        output_text: ì›ë³¸ ì¶œë ¥ í…ìŠ¤íŠ¸
        output_type: ì¶œë ¥ íƒ€ì… ("stdout" ë˜ëŠ” "stderr")
        max_length: ìµœëŒ€ ê¸¸ì´ (ê¸°ë³¸ê°’: 500ì)

    Returns:
        str ë˜ëŠ” dict: ê°„ì†Œí™”ëœ ì¶œë ¥ ì •ë³´
    """
    if not output_text or not output_text.strip():
        return output_text

    # ì›ë³¸ ê¸¸ì´
    original_length = len(output_text)

    # ê¸¸ì´ê°€ ì œí•œ ë‚´ì— ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if original_length <= max_length:
        return output_text

    # ê¸¸ì´ê°€ ì´ˆê³¼í•˜ë©´ ìš”ì•½ ì •ë³´ ìƒì„±
    lines = output_text.strip().split('\n')
    total_lines = len(lines)

    # ì²˜ìŒ 3ì¤„ê³¼ ë§ˆì§€ë§‰ 3ì¤„ë§Œ ìœ ì§€
    if total_lines > 6:
        first_lines = '\n'.join(lines[:3])
        last_lines = '\n'.join(lines[-3:])
        compact_text = f"{first_lines}\n\n... ({total_lines - 6} lines omitted) ...\n\n{last_lines}\n\n[Output truncated: {original_length} chars, {total_lines} lines total]"
    else:
        # ì¤„ ìˆ˜ê°€ ì ìœ¼ë©´ ë‹¨ìˆœ ì ˆë‹¨
        compact_text = output_text[:max_length] + f"...\n\n[Output truncated: {original_length} chars total]"

    return compact_text

def get_file_snapshot(directories=['/app/artifacts', '/app/data']):
    """íŒŒì¼ ì‹œìŠ¤í…œ ìŠ¤ëƒ…ìƒ· ìƒì„±"""
    snapshot = {}
    for directory in directories:
        if os.path.exists(directory):
            for root, dirs, files in os.walk(directory):
                for file in files:
                    file_path = os.path.join(root, file)
                    try:
                        stat = os.stat(file_path)
                        snapshot[file_path] = {
                            'mtime': stat.st_mtime,
                            'size': stat.st_size
                        }
                    except:
                        pass
    return snapshot

def get_changed_files(before_snapshot, after_snapshot):
    """ë³€ê²½ëœ íŒŒì¼ ëª©ë¡ ì¶”ì¶œ"""
    changed = []

    # ìƒˆë¡œ ìƒì„±ë˜ê±°ë‚˜ ìˆ˜ì •ëœ íŒŒì¼
    for file_path, info in after_snapshot.items():
        if file_path not in before_snapshot:
            changed.append({'path': file_path, 'type': 'created'})
        elif info['mtime'] > before_snapshot[file_path]['mtime']:
            changed.append({'path': file_path, 'type': 'modified'})

    return changed

def read_file_content(file_path, max_size=1024*1024):
    """íŒŒì¼ ë‚´ìš© ì½ê¸° (ìµœëŒ€ 1MB)"""
    try:
        stat = os.stat(file_path)
        if stat.st_size > max_size:
            return {'error': f'File too large: {stat.st_size} bytes'}

        # ë°”ì´ë„ˆë¦¬ íŒŒì¼ ì²´í¬
        with open(file_path, 'rb') as f:
            chunk = f.read(512)
            if b'\x00' in chunk:
                return {'error': 'Binary file', 'size': stat.st_size}

        # í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸°
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            return {'content': content, 'size': len(content)}
    except Exception as e:
        return {'error': str(e)}

def execute_code(code_string, execution_num):
    """ë™ì  ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜ (Python ì½”ë“œ ë˜ëŠ” Bash ëª…ë ¹ì–´)"""

    print(f"ğŸš€ Execution {execution_num} starting...", flush=True)

    # # ì‹¤í–‰ ì „ íŒŒì¼ ìŠ¤ëƒ…ìƒ· - ì£¼ì„ ì²˜ë¦¬ë¨ (í•„ìš” ì—†ìŒ)
    # before_snapshot = get_file_snapshot()

    # ì½”ë“œ íƒ€ì… ê°ì§€
    code_type = "bash" if code_string.strip().startswith("BASH:") else "python"

    if code_type == "bash":
        # BASH: ì ‘ë‘ì‚¬ ì œê±°
        bash_command = code_string.strip()[5:].strip()
        print(f"ğŸ§ Executing bash command: {bash_command}", flush=True)
    else:
        print(f"ğŸ Executing python code", flush=True)

    # Container IP ê°€ì ¸ì˜¤ê¸°
    import socket
    try:
        hostname = socket.gethostname()
        container_ip = socket.gethostbyname(hostname)
    except Exception:
        container_ip = "unknown"

    result = {
        "execution_num": execution_num,
        "timestamp": str(datetime.now()),
        "code": code_string[:200] + "..." if len(code_string) > 200 else code_string,
        "code_type": code_type,
        "status": "running",
        "stdout": "",
        "stderr": "",
        "error": None,
        "execution_time_ms": 0,
        "container_ip": container_ip
    }

    start_time = datetime.now()

    try:
        if code_type == "bash":
            # Bash ëª…ë ¹ì–´ ì‹¤í–‰ (ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ /app/ìœ¼ë¡œ ì„¤ì •)
            process = subprocess.run(
                bash_command,
                shell=True,
                capture_output=True,
                text=True,
                cwd="/app",
                timeout=30
            )

            result["status"] = "completed" if process.returncode == 0 else "failed"
            result["stdout"] = process.stdout
            result["stderr"] = process.stderr

            if process.returncode != 0:
                result["error"] = {
                    "type": "BashError",
                    "message": f"Command failed with return code {process.returncode}",
                    "return_code": process.returncode
                }
                print(f"âŒ Bash execution {execution_num} failed with code {process.returncode}", flush=True)
            else:
                print(f"âœ… Bash execution {execution_num} completed successfully", flush=True)

        else:
            # Python ì½”ë“œ ì‹¤í–‰
            stdout_capture = StringIO()
            stderr_capture = StringIO()

            with contextlib.redirect_stdout(stdout_capture), contextlib.redirect_stderr(stderr_capture):
                # í•„ìš”í•œ import ìë™ ì¶”ê°€
                exec_globals = {
                    '__builtins__': __builtins__,
                    'datetime': datetime,
                    'json': json,
                    'os': os,
                    'workspace': session_manager.workspace
                }

                # ì½”ë“œ ì‹¤í–‰ - Explicit exception handling to prevent container instability
                try:
                    exec(code_string, exec_globals)
                    result["status"] = "completed"
                except Exception as exec_error:
                    # Catch exec() errors immediately to prevent container crash
                    result["status"] = "failed"
                    traceback_text = traceback.format_exc()
                    result["error"] = create_compact_error_response(exec_error, traceback_text)
                    print(f"âŒ Python execution {execution_num} failed during exec(): {exec_error}", flush=True)

            # Capture stdout/stderr regardless of success or failure
            result["stdout"] = stdout_capture.getvalue()
            result["stderr"] = stderr_capture.getvalue()

            if result["status"] == "completed":
                print(f"âœ… Python execution {execution_num} completed successfully", flush=True)

    except subprocess.TimeoutExpired:
        result["status"] = "failed"
        result["error"] = {
            "type": "TimeoutError",
            "message": "Command timed out after 30 seconds"
        }
        print(f"â° Execution {execution_num} timed out", flush=True)

    except Exception as e:
        result["status"] = "failed"
        if code_type == "python":
            result["stdout"] = stdout_capture.getvalue()
            result["stderr"] = stderr_capture.getvalue()

        # ìŠ¤íŠ¸ë¦¬ë°ì— ì í•©í•œ ê°„ì†Œí™”ëœ ì—ëŸ¬ ì‘ë‹µ ìƒì„±
        traceback_text = traceback.format_exc()
        result["error"] = create_compact_error_response(e, traceback_text)

        print(f"âŒ Execution {execution_num} failed: {e}", flush=True)

    finally:
        end_time = datetime.now()
        result["execution_time_ms"] = int((end_time - start_time).total_seconds() * 1000)

        # # ì‹¤í–‰ í›„ íŒŒì¼ ìŠ¤ëƒ…ìƒ· ë° ë³€ê²½ íŒŒì¼ ì¶”ì¶œ - ì£¼ì„ ì²˜ë¦¬ë¨ (í•„ìš” ì—†ìŒ)
        # after_snapshot = get_file_snapshot()
        # changed_files = get_changed_files(before_snapshot, after_snapshot)
        #
        # # ë³€ê²½ëœ íŒŒì¼ ë‚´ìš© ì½ê¸°
        # files_data = {}
        # for file_info in changed_files:
        #     file_path = file_info['path']
        #     file_content = read_file_content(file_path)
        #
        #     # ìƒëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        #     if file_path.startswith('/app/'):
        #         relative_path = file_path[5:]  # /app/ ì œê±°
        #     else:
        #         relative_path = file_path
        #
        #     files_data[relative_path] = {
        #         'type': file_info['type'],
        #         'path': file_path,
        #         'relative_path': relative_path,
        #         **file_content
        #     }
        #
        # # ê²°ê³¼ì— íŒŒì¼ ì •ë³´ ì¶”ê°€
        # result["files"] = files_data
        #
        # if files_data:
        #     print(f"ğŸ“ {len(files_data)} file(s) created/modified", flush=True)
        #     for path in files_data.keys():
        #         print(f"  - {path}", flush=True)

    return result

@app.route('/health', methods=['GET'])
def health():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ (ALB Health Checkìš©)"""
    return jsonify({
        "status": "healthy",
        "session_id": session_manager.session_id,
        "executions_completed": len(session_manager.executions),
        "max_executions": session_manager.max_executions,
        "is_complete": session_manager.is_complete
    })


@app.route('/container-info', methods=['GET'])
def container_info():
    """ì»¨í…Œì´ë„ˆ ì •ë³´ ë°˜í™˜ (Sticky Session ì¿ í‚¤ ê²€ì¦ìš©)

    ë©€í‹° Job ì§€ì›:
    - session_id íŒŒë¼ë¯¸í„°ë¡œ íŠ¹ì • ì„¸ì…˜ ê²€ì¦ ê°€ëŠ¥
    - known_sessions ë¦¬ìŠ¤íŠ¸ë¡œ ì´ ì»¨í…Œì´ë„ˆê°€ ì•Œê³  ìˆëŠ” ëª¨ë“  ì„¸ì…˜ ID ë°˜í™˜
    """
    import socket
    try:
        hostname = socket.gethostname()
        private_ip = socket.gethostbyname(hostname)
    except Exception as e:
        hostname = "unknown"
        private_ip = "unknown"

    # ì´ ì»¨í…Œì´ë„ˆê°€ ì•Œê³  ìˆëŠ” ì„¸ì…˜ ID ë¦¬ìŠ¤íŠ¸
    # session_manager.session_idëŠ” ì´ ì»¨í…Œì´ë„ˆê°€ ì‹œì‘ëœ ì„¸ì…˜
    known_sessions = [session_manager.session_id] if session_manager.session_id else []

    return jsonify({
        "private_ip": private_ip,
        "hostname": hostname,
        "session_id": session_manager.session_id,  # ì´ ì»¨í…Œì´ë„ˆì˜ ë©”ì¸ ì„¸ì…˜
        "known_sessions": known_sessions,  # ë©€í‹° Job ê²€ì¦ìš©
        "executions_completed": len(session_manager.executions)
    })

@app.route('/execute', methods=['POST'])
def execute():
    """ì½”ë“œ ì‹¤í–‰ ì—”ë“œí¬ì¸íŠ¸"""

    if session_manager.is_complete:
        return jsonify({
            "error": "Session is already complete",
            "session_id": session_manager.session_id
        }), 400

    # ìš”ì²­ì—ì„œ ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
    data = request.get_json()
    if not data or 'code' not in data:
        return jsonify({"error": "No code provided"}), 400

    code = data['code']
    execution_num = len(session_manager.executions) + 1

    # ì½”ë“œ ì‹¤í–‰
    result = execute_code(code, execution_num)

    # ê²°ê³¼ ì €ì¥
    session_manager.add_execution(result)

    # ìŠ¤íŠ¸ë¦¬ë° ì•ˆì •ì„±ì„ ìœ„í•´ stdout/stderr ì¶œë ¥ í¬ê¸° ì œí•œ
    compact_stdout = create_compact_output(result["stdout"], "stdout", max_length=4096*2)
    compact_stderr = create_compact_output(result["stderr"], "stderr", max_length=4096*2)

    # ì‘ë‹µ ë°˜í™˜ (íŒŒì¼ ì •ë³´ í¬í•¨)
    response_data = {
        "session_id": session_manager.session_id,
        "execution_num": execution_num,
        "status": result["status"],
        "stdout": compact_stdout,
        "stderr": compact_stderr,
        "error": result["error"],
        "execution_time_ms": result["execution_time_ms"],
        "total_executions": len(session_manager.executions),
        "is_session_complete": session_manager.is_complete
    }

    # # íŒŒì¼ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€ - ì£¼ì„ ì²˜ë¦¬ë¨ (í•„ìš” ì—†ìŒ)
    # if 'files' in result and result['files']:
    #     response_data['files'] = result['files']

    # ì‹¤ì‹œê°„ ë°±ì—… ë¹„í™œì„±í™” - ì„¸ì…˜ ì¢…ë£Œ ì‹œì—ë§Œ S3 ì—…ë¡œë“œ
    response_data['s3_backup'] = "skipped_until_session_end"

    return jsonify(response_data)

@app.route('/session/status', methods=['GET'])
def session_status():
    """ì„¸ì…˜ ìƒíƒœ ì¡°íšŒ"""
    return jsonify({
        "session_id": session_manager.session_id,
        "executions_completed": len(session_manager.executions),
        "max_executions": session_manager.max_executions,
        "is_complete": session_manager.is_complete,
        "workspace": session_manager.workspace,
        "uptime_seconds": int((datetime.now() - session_manager.start_time).total_seconds())
    })

@app.route('/session/complete', methods=['POST'])
def complete_session():
    """ì„¸ì…˜ ê°•ì œ ì™„ë£Œ (30ë²ˆ ì „ì—ë„ ì¢…ë£Œ ê°€ëŠ¥)"""
    session_manager.complete_session()
    return jsonify({
        "message": "Session completed",
        "session_id": session_manager.session_id,
        "total_executions": len(session_manager.executions)
    })

@app.route('/get_file', methods=['POST'])
def get_file():
    """íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° ì—”ë“œí¬ì¸íŠ¸ (Method 1 êµ¬í˜„)"""
    try:
        data = request.get_json()
        if not data or 'file_path' not in data:
            return jsonify({"error": "No file_path provided"}), 400

        file_path = data['file_path']

        # ë³´ì•ˆ: ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜í•˜ê³  /app ë‚´ë¶€ë¡œ ì œí•œ
        if not file_path.startswith('/'):
            # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° /app ê¸°ì¤€ìœ¼ë¡œ ì²˜ë¦¬
            if file_path.startswith('./artifacts/'):
                file_path = f"/app/artifacts/{file_path[12:]}"
            elif file_path.startswith('./data/'):
                file_path = f"/app/data/{file_path[7:]}"
            elif file_path.startswith('artifacts/'):
                file_path = f"/app/artifacts/{file_path[10:]}"
            elif file_path.startswith('data/'):
                file_path = f"/app/data/{file_path[5:]}"
            else:
                file_path = f"/app/{file_path}"

        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                return jsonify({
                    "exists": True,
                    "file_path": file_path,
                    "content": content,
                    "size": len(content)
                })
            except Exception as e:
                return jsonify({
                    "exists": True,
                    "file_path": file_path,
                    "error": f"Cannot read file: {str(e)}"
                }), 500
        else:
            return jsonify({
                "exists": False,
                "file_path": file_path,
                "error": "File not found"
            })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/file-sync', methods=['POST'])
def file_sync():
    """S3ë¥¼ í†µí•œ íŒŒì¼ ë™ê¸°í™” ì²˜ë¦¬"""

    try:
        data = request.get_json()
        if not data or 'action' not in data:
            return jsonify({"error": "No action specified"}), 400

        action = data['action']
        bucket_name = data.get('bucket_name')
        s3_key_prefix = data.get('s3_key_prefix')
        local_path = data.get('local_path')

        if not all([bucket_name, s3_key_prefix, local_path]):
            return jsonify({"error": "Missing required parameters"}), 400

        s3_client = boto3.client('s3', region_name='us-east-1')

        if action == "sync_data_from_s3":
            # S3ì—ì„œ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œ
            result = sync_from_s3(s3_client, bucket_name, s3_key_prefix, local_path)
            return jsonify(result)

        elif action == "sync_artifacts_to_s3":
            # ì•„í‹°íŒ©íŠ¸ë¥¼ S3ì— ì—…ë¡œë“œ
            result = sync_to_s3(s3_client, bucket_name, s3_key_prefix, local_path)
            return jsonify(result)

        else:
            return jsonify({"error": f"Unknown action: {action}"}), 400

    except Exception as e:
        print(f"âŒ File sync error: {e}", flush=True)
        return jsonify({
            "error": str(e),
            "traceback": traceback.format_exc()
        }), 500

def sync_from_s3(s3_client, bucket_name, s3_key_prefix, local_path):
    """S3ì—ì„œ ë¡œì»¬ë¡œ íŒŒì¼ë“¤ ë‹¤ìš´ë¡œë“œ"""
    downloaded_files = []

    try:
        # ë¡œì»¬ ë””ë ‰í† ë¦¬ ìƒì„±
        Path(local_path).mkdir(parents=True, exist_ok=True)

        # S3 ê°ì²´ ëª©ë¡ ì¡°íšŒ
        response = s3_client.list_objects_v2(
            Bucket=bucket_name,
            Prefix=s3_key_prefix
        )

        if 'Contents' not in response:
            print(f"âš ï¸ No files found in S3 with prefix: {s3_key_prefix}", flush=True)
            return {
                "status": "success",
                "message": "No files to download",
                "files_count": 0,
                "downloaded_files": []
            }

        for obj in response['Contents']:
            s3_key = obj['Key']

            # S3 í‚¤ì—ì„œ ìƒëŒ€ ê²½ë¡œ ì¶”ì¶œ
            relative_path = s3_key[len(s3_key_prefix):].lstrip('/')
            if not relative_path:  # ë¹ˆ í‚¤ëŠ” ê±´ë„ˆë›°ê¸°
                continue

            local_file_path = os.path.join(local_path, relative_path)

            # ë¡œì»¬ ë””ë ‰í† ë¦¬ ìƒì„±
            local_file_dir = os.path.dirname(local_file_path)
            Path(local_file_dir).mkdir(parents=True, exist_ok=True)

            try:
                s3_client.download_file(bucket_name, s3_key, local_file_path)
                downloaded_files.append(local_file_path)
                print(f"  â¬‡ï¸ Downloaded: s3://{bucket_name}/{s3_key} â†’ {local_file_path}", flush=True)
            except Exception as e:
                print(f"  âŒ Download failed for {s3_key}: {e}", flush=True)

        return {
            "status": "success",
            "message": f"Downloaded {len(downloaded_files)} files from S3",
            "files_count": len(downloaded_files),
            "downloaded_files": downloaded_files
        }

    except Exception as e:
        print(f"âŒ S3 download error: {e}", flush=True)
        return {
            "status": "error",
            "message": str(e),
            "files_count": 0
        }

def sync_to_s3(s3_client, bucket_name, s3_key_prefix, local_path):
    """ë¡œì»¬ì—ì„œ S3ë¡œ íŒŒì¼ë“¤ ì—…ë¡œë“œ"""
    uploaded_files = []

    try:
        if not os.path.exists(local_path):
            return {
                "status": "success",
                "message": "Local path does not exist",
                "files_count": 0,
                "uploaded_files": []
            }

        for root, dirs, files in os.walk(local_path):
            for file in files:
                local_file_path = os.path.join(root, file)
                relative_path = os.path.relpath(local_file_path, local_path)
                s3_key = f"{s3_key_prefix}/{relative_path}".replace('\\', '/')

                try:
                    s3_client.upload_file(local_file_path, bucket_name, s3_key)
                    uploaded_files.append(s3_key)
                    print(f"  ğŸ“¤ Uploaded: {local_file_path} â†’ s3://{bucket_name}/{s3_key}", flush=True)
                except Exception as e:
                    print(f"  âŒ Upload failed for {local_file_path}: {e}", flush=True)

        return {
            "status": "success",
            "message": f"Uploaded {len(uploaded_files)} files to S3",
            "files_count": len(uploaded_files),
            "uploaded_files": uploaded_files
        }

    except Exception as e:
        print(f"âŒ S3 upload error: {e}", flush=True)
        return {
            "status": "error",
            "message": str(e),
            "files_count": 0
        }

def auto_shutdown():
    """1ì‹œê°„ í›„ ìë™ ì¢…ë£Œ"""
    time.sleep(3600)  # 1ì‹œê°„

    print("â° Auto-shutdown timeout reached", flush=True)

    if not session_manager.is_complete:
        session_manager.complete_session()

    time.sleep(10)  # S3 ì—…ë¡œë“œ ì™„ë£Œ ëŒ€ê¸°
    sys.exit(0)

if __name__ == "__main__":
    print("=" * 60, flush=True)
    print("ğŸ”¥ FARGATE DYNAMIC CODE EXECUTOR V2 - HTTP Server", flush=True)
    print(f"ğŸ“ Session ID: {session_manager.session_id}", flush=True)
    print(f"ğŸ“Š Max Executions: {session_manager.max_executions}", flush=True)
    print("=" * 60, flush=True)

    # ìë™ ì¢…ë£Œ ìŠ¤ë ˆë“œ ì‹œì‘
    shutdown_thread = threading.Thread(target=auto_shutdown)
    shutdown_thread.daemon = True
    shutdown_thread.start()

    # Flask ì„œë²„ ì‹œì‘
    app.run(host='0.0.0.0', port=8080, debug=False)