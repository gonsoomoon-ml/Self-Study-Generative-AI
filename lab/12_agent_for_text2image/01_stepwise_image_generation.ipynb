{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Agentic system for Text2Image\n",
    "- Image generation with agentic patterns (planning and reflection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setting\n",
    " - Auto Reload\n",
    " - path for utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "module_path = \"./\"#\"../..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 1. Create Bedrock client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from termcolor import colored\n",
    "from utils import bedrock\n",
    "from utils.bedrock import bedrock_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "- os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "- os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "- os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "- os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"<YOUR_ENDPOINT_URL>\"  # E.g. \"https://...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    ")\n",
    "\n",
    "print (colored(\"\\n== FM lists ==\", \"green\"))\n",
    "pprint (bedrock_info.get_list_fm_models(verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 2. LLM 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.bedrock import bedrock_model\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = bedrock_model(\n",
    "    model_id=bedrock_info.get_model_id(model_name=\"Claude-V3-5-V-2-Sonnet-CRI\"),\n",
    "    #model_id=bedrock_info.get_model_id(model_name=\"Claude-V3-7-Sonnet-CRI\"),\n",
    "    \n",
    "    bedrock_client=boto3_bedrock,\n",
    "    stream=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    inference_config={\n",
    "        'maxTokens': 4096,\n",
    "        'stopSequences': [\"\\n\\nHuman\"],\n",
    "        'temperature': 0.01,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_generation_model = bedrock_model(\n",
    "    model_id=bedrock_info.get_model_id(model_name=\"SD-Ultra\"),\n",
    "    bedrock_client=boto3_bedrock\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 3. Comparision between conventional and agentic T2I\n",
    "### 3.1 Conventional T2I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import base64\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _body_generator(pos_prompt, neg_prompt=\"\", condition_image=None, condition_strength=None, seed=1):\n",
    "\n",
    "    if condition_image == None:\n",
    "        body_dict = {\n",
    "            \"prompt\": pos_prompt,\n",
    "            \"negative_prompt\": neg_prompt,\n",
    "            \"mode\": \"text-to-image\",\n",
    "            \"aspect_ratio\": \"3:2\",  # Default 1:1. Enum: 16:9, 1:1, 21:9, 2:3, 3:2, 4:5, 5:4, 9:16, 9:21.\n",
    "            \"output_format\": \"png\",\n",
    "            \"seed\": seed\n",
    "        }\n",
    "    else:\n",
    "        body_dict = {\n",
    "            \"prompt\": pos_prompt,\n",
    "            \"negative_prompt\": neg_prompt,\n",
    "            \"mode\": \"image-to-image\",\n",
    "            \"strength\": condition_strength,\n",
    "            \"image\": condition_image,\n",
    "            \"output_format\": \"png\",\n",
    "            \"seed\": seed\n",
    "        }\n",
    "\n",
    "    return json.dumps(body_dict)\n",
    "\n",
    "def _png_to_bytes(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as image_file:\n",
    "            # 파일을 바이너리 모드로 읽기\n",
    "            binary_data = image_file.read()\n",
    "\n",
    "            # 바이너리 데이터를 base64로 인코딩\n",
    "            base64_encoded = base64.b64encode(binary_data)\n",
    "\n",
    "            # bytes 타입을 문자열로 디코딩\n",
    "            base64_string = base64_encoded.decode('utf-8')\n",
    "\n",
    "            return binary_data, base64_string\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return \"Error: 파일을 찾을 수 없습니다.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "        \n",
    "def show_save_image(base64_string):\n",
    "    try:\n",
    "\n",
    "        # base64 문자열을 디코딩하여 바이너리 데이터로 변환\n",
    "        image_data = base64.b64decode(base64_string)\n",
    "\n",
    "        # 바이너리 데이터를 이미지로 변환\n",
    "        image = Image.open(io.BytesIO(image_data))\n",
    "\n",
    "        fig, (ax1) = plt.subplots(1, 1, figsize=(15, 7))\n",
    "        ax1.imshow(image)\n",
    "        ax1.axis('off')\n",
    "        ax1.set_title('Generated Image')\n",
    "\n",
    "        plt.tight_layout()  # 레이아웃 조정\n",
    "        plt.show()\n",
    "\n",
    "        # save images\n",
    "        img_path = './generated_imgs/GENERATED_IMAGE.png'\n",
    "        image.save(img_path, \"PNG\")\n",
    "\n",
    "        return img_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: 이미지를 표시하는 데 실패했습니다. {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_generation_model.model_id = \"stability.sd3-5-large-v1:0\"\n",
    "\n",
    "body = _body_generator(\n",
    "    pos_prompt=\n",
    "        '''\n",
    "        An icy landscape.\n",
    "        A vast expanse of snow-covered mountain peaks stretches endlessly.\n",
    "        Beneath them is a dense forest and a colossal frozen lake.\n",
    "        people are boating in three boats in the lake.\n",
    "        Not far from the lake, a volcano threatens eruption, its rumblings felt even from afar.\n",
    "        On the mountain, a ferocious red dragon dominates the sky and commands the heavens, fueled by the volcano's relentless energy flow.\n",
    "        Oil painting.\n",
    "        ''',\n",
    "    seed=random.randint(0, 100000)\n",
    ")\n",
    "response = image_generation_model.bedrock_client.invoke_model(\n",
    "    body=body,\n",
    "    modelId=image_generation_model.model_id\n",
    ")\n",
    "print (image_generation_model.model_id)\n",
    "\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "base64_image = response_body.get(\"images\")[0]\n",
    "condition_image = show_save_image(base64_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### 3.2 Agenic T2I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import pprint\n",
    "import base64\n",
    "import traceback\n",
    "from PIL import Image\n",
    "from termcolor import colored\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from textwrap import dedent\n",
    "from utils.bedrock import bedrock_utils\n",
    "from typing import TypedDict, Optional, List\n",
    "\n",
    "from src.genai_anaysis import llm_call\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from utils.common_utils import retry\n",
    "from botocore.exceptions import ClientError, ConnectionError, ConnectTimeoutError, ReadTimeoutError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimeMeasurement:\n",
    "    def __init__(self):\n",
    "        self.start_time = None\n",
    "        self.measurements = {}\n",
    "\n",
    "    def start(self):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def measure(self, section_name):\n",
    "        if self.start_time is None:\n",
    "            raise ValueError(\"start() 메서드를 먼저 호출해야 합니다.\")\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - self.start_time\n",
    "        self.measurements[section_name] = elapsed_time\n",
    "        self.start_time = end_time  # 다음 구간 측정을 위해 시작 시간 재설정\n",
    "\n",
    "    def reset(self, ):\n",
    "        self.measurements = {}\n",
    "\n",
    "    def print_measurements(self):\n",
    "        for section, elapsed_time in self.measurements.items():\n",
    "            #print(f\"{section}: {elapsed_time:.5f} 초\")\n",
    "            print(colored (f\"\\nelapsed time: {section}: {elapsed_time:.5f} 초\", \"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "#### 3.2.1 Agent state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    ask: str\n",
    "    \n",
    "    total_steps: int\n",
    "    steps: List[str]\n",
    "\n",
    "    seed: int\n",
    "    current_step: int\n",
    "    condition_image: str\n",
    "\n",
    "    suggestions: str\n",
    "    prompt_repo: dict\n",
    "    retry_count: int\n",
    "    prev_node: str\n",
    "    should_regeneration: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class genai_analyzer():\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        self.llm=kwargs[\"llm\"]\n",
    "        self.image_generation_model = kwargs[\"image_generation_model\"]\n",
    "        self.state = GraphState\n",
    "\n",
    "        self.llm_caller = llm_call(\n",
    "            llm=self.llm,\n",
    "            verbose=False\n",
    "        ) \n",
    "\n",
    "        self._graph_definition()\n",
    "        self.messages = []\n",
    "\n",
    "        self.timer = TimeMeasurement()\n",
    "\n",
    "    def _get_string_from_message(self, message):\n",
    "        return message[\"content\"][0][\"text\"]\n",
    "\n",
    "    def _get_message_from_string(self, role, string, imgs=None):\n",
    "        \n",
    "        message = {\n",
    "            \"role\": role,\n",
    "            \"content\": []\n",
    "        }\n",
    "        \n",
    "        if imgs is not None:\n",
    "            for img in imgs:\n",
    "                img_message = {\n",
    "                    \"image\": {\n",
    "                        \"format\": 'png',\n",
    "                        \"source\": {\"bytes\": img}\n",
    "                    }\n",
    "                }\n",
    "                message[\"content\"].append(img_message)\n",
    "        \n",
    "        message[\"content\"].append({\"text\": dedent(string)})\n",
    "\n",
    "        return message\n",
    "    \n",
    "    def _png_to_bytes(self, file_path):\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as image_file:\n",
    "                # 파일을 바이너리 모드로 읽기\n",
    "                binary_data = image_file.read()\n",
    "                \n",
    "                # 바이너리 데이터를 base64로 인코딩\n",
    "                base64_encoded = base64.b64encode(binary_data)\n",
    "                \n",
    "                # bytes 타입을 문자열로 디코딩\n",
    "                base64_string = base64_encoded.decode('utf-8')\n",
    "                \n",
    "                return binary_data, base64_string\n",
    "                \n",
    "        except FileNotFoundError:\n",
    "            return \"Error: 파일을 찾을 수 없습니다.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "    def show_save_image(self, base64_string):\n",
    "        try:\n",
    "            \n",
    "            # base64 문자열을 디코딩하여 바이너리 데이터로 변환\n",
    "            image_data = base64.b64decode(base64_string)\n",
    "            \n",
    "            # 바이너리 데이터를 이미지로 변환\n",
    "            image = Image.open(io.BytesIO(image_data))\n",
    "\n",
    "            fig, (ax1) = plt.subplots(1, 1, figsize=(15, 7))\n",
    "            ax1.imshow(image)\n",
    "            ax1.axis('off')\n",
    "            ax1.set_title('Generated Image')\n",
    "\n",
    "            plt.tight_layout()  # 레이아웃 조정\n",
    "            plt.show()\n",
    "            \n",
    "            # save images\n",
    "            img_path = './generated_imgs/GENERATED_IMAGE.png'\n",
    "            image.save(img_path, \"PNG\")\n",
    "            time.sleep(3)\n",
    "            \n",
    "            return img_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: 이미지를 표시하는 데 실패했습니다. {str(e)}\")\n",
    "            \n",
    "    def _body_generator(self, pos_prompt, neg_prompt=\"\", condition_image=None, control_strength=None, seed=1):\n",
    "        \n",
    "        \n",
    "        \n",
    "        print (\"_body_generator, control_strength\", control_strength)\n",
    "    \n",
    "        if condition_image == None:\n",
    "            self.image_generation_model.model_id = \"stability.stable-image-ultra-v1:1\"\n",
    "            print (f'Image generator: SD-Ultra')\n",
    "            body_dict = {\n",
    "                \"prompt\": pos_prompt,\n",
    "                \"negative_prompt\": neg_prompt,\n",
    "                \"mode\": \"text-to-image\",\n",
    "                \"aspect_ratio\": \"3:2\",  # Default 1:1. Enum: 16:9, 1:1, 21:9, 2:3, 3:2, 4:5, 5:4, 9:16, 9:21.\n",
    "                \"output_format\": \"png\",\n",
    "                \"seed\": seed\n",
    "            }\n",
    "        else:\n",
    "            self.image_generation_model.model_id = \"stability.sd3-5-large-v1:0\"\n",
    "            print (f'Image generator: SD-3-5-Large')\n",
    "            body_dict = {\n",
    "                \"prompt\": pos_prompt,\n",
    "                \"negative_prompt\": neg_prompt,\n",
    "                \"mode\": \"image-to-image\",\n",
    "                \"strength\": control_strength, # nova랑 반대\n",
    "                \"image\": condition_image,\n",
    "                \"output_format\": \"png\",\n",
    "                \"seed\": seed\n",
    "            }\n",
    "\n",
    "        return json.dumps(body_dict)\n",
    "\n",
    "    def get_messages(self, ):\n",
    "        return self.messages\n",
    "        \n",
    "    def _graph_definition(self, **kwargs):\n",
    "\n",
    "        def StepwiseTaskDecomposer(state):\n",
    "\n",
    "            self.timer.start()\n",
    "            self.timer.reset()\n",
    "            \n",
    "            print(\"---StepwiseTaskDecomposer---\")\n",
    "            ask = state[\"ask\"]\n",
    "            current_step = state.get(\"current_step\", 1)\n",
    "            messages = []\n",
    "        \n",
    "            system_prompts = dedent(\n",
    "                \n",
    "                '''\n",
    "                You are an agent that plans steps for stepwise image generation based on user requests.\n",
    "\n",
    "                Core Responsibilities:\n",
    "                \n",
    "                1. Break down user requests into manageable steps that:\n",
    "                   - Prioritize single step generation when feasible\n",
    "                   - Only split into multiple steps (2-3) when complexity demands it\n",
    "                     (e.g. layered scenes, multiple focal points, complex interactions)\n",
    "                   - Follow control mode restrictions (NONE for step 1, SEGMENTATION after)\n",
    "                   - Progress from core elements to details\n",
    "                   - Use appropriate control strength for smooth transitions\n",
    "                   - Track and maintain key subject and image style properties:\n",
    "                     * Exact counts (e.g., \"3 boats with passengers\" not just \"3 boats\")\n",
    "                     * Spatial orientations (e.g., \"facing left\")\n",
    "                     * Specific attributes (e.g., \"red cars\" not just \"cars\")\n",
    "                     * Relationships between subjects (e.g., \"person sitting in each boat\")\n",
    "                     * Image style (e.g., \"oil painting\")\n",
    "\n",
    "                2. For each step, provide:\n",
    "                   - Start with new elements in prompt generation\n",
    "                   - Step description\n",
    "                   - Image generation prompt that have to maintain key subjects(people, car, etc) and elements from previous steps while clearly specifying new additions\n",
    "                   - Add detailed improvements (style, lighting etc)\n",
    "                   - Control mode (NONE/SEGMENTATION)\n",
    "                   - Control strength (0.0-1.0, N/A for step 1)\n",
    "\n",
    "                Step Planning Guidelines:\n",
    "                First Step (Composition & Subject):\n",
    "                - Uses NONE control mode\n",
    "                - No control strength applicable\n",
    "                - Must establish:\n",
    "                  * Overall scene composition\n",
    "                  * Main subjects and objects\n",
    "                  * Spatial relationships and viewpoint\n",
    "                  * Foreground/background structure\n",
    "                  * Space allocation for future elements\n",
    "\n",
    "                Subsequent Steps:\n",
    "                - Uses SEGMENTATION control mode\n",
    "                - Each prompt should explicitly reference maintaining previous subjects and elements\n",
    "                - Control strength: 0.8-0.95 recommended\n",
    "                - Consider new elements' impact when selecting control strength\n",
    "                \n",
    "                Scene Composition Rules:\n",
    "                1. Foreground/Background\n",
    "                   - Specify clear spatial relationships\n",
    "                   - Maintain distinct layering\n",
    "                   - Use explicit positioning terms\n",
    "\n",
    "                2. Spatial Relationships\n",
    "                   - Use clear position indicators (left, right, near, far)\n",
    "                   - Consider depth and perspective\n",
    "                   - Be explicit about distances and relationships\n",
    "\n",
    "                Prompt Writing Guidelines:\n",
    "                - Use image captioning style\n",
    "                - Start with new elements or sbjects\n",
    "                - Maintain consistent style across steps\n",
    "                - Use clear, simple language\n",
    "                - Keep under 5,000 characters\n",
    "                - Include:\n",
    "                  * Spatial relationships\n",
    "                  * Depth indicators\n",
    "                  * Viewing angles when relevant\n",
    "                  * Style keywords at end\n",
    "\n",
    "                Output Format:\n",
    "                DO NOT include any text or json symbol (```json```)outside the JSON format in the response\n",
    "                You must provide your response in the following JSON format:\n",
    "                {\n",
    "                    \"total_steps\": <number_of_steps>,\n",
    "                    \"steps\": [\n",
    "                        {\n",
    "                            \"step_number\": <number>,\n",
    "                            \"description\": <string>,\n",
    "                            \"control_mode\": <\"NONE\"/\"SEGMENTATION\">,\n",
    "                            \"control_strength\": <float>,\n",
    "                            \"prompt\": {\n",
    "                                \"positive\": <string>,\n",
    "                                \"negative\": <string>\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "\n",
    "                Key Requirements:\n",
    "                - Each step builds on previous\n",
    "                - Maintain style consistency across steps through:\n",
    "                  * Matching artistic style keywords\n",
    "                  * Consistent quality enhancers\n",
    "                  * Uniform lighting/atmosphere descriptions\n",
    "                  * Consistent camera/perspective terms\n",
    "                \n",
    "                '''\n",
    "            )\n",
    "\n",
    "            if current_step == 1:\n",
    "                system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "                user_prompts = dedent(\n",
    "                    '''\n",
    "                    Here is user's ask: <ask>{ask}</ask>\n",
    "                    '''\n",
    "                )\n",
    "                context = {\n",
    "                    \"ask\": ask,\n",
    "                }\n",
    "                user_prompts = user_prompts.format(**context)\n",
    "                           \n",
    "                message = self._get_message_from_string(role=\"user\", string=user_prompts)\n",
    "                self.messages.append(message)\n",
    "                messages.append(message)\n",
    "                \n",
    "                resp, ai_message = self.llm_caller.invoke(\n",
    "                    messages=messages,\n",
    "                    system_prompts=system_prompts,\n",
    "                    enable_reasoning=False,\n",
    "                    reasoning_budget_tokens=1024\n",
    "                )\n",
    "                self.messages.append(ai_message)\n",
    "                            \n",
    "                results = json.loads(resp['text'])\n",
    "                total_steps, steps = results[\"total_steps\"], results[\"steps\"]\n",
    "                should_next_step = \"next_step\"\n",
    "            \n",
    "                return self.state(\n",
    "                    total_steps=total_steps,\n",
    "                    steps=steps,\n",
    "                    should_next_step=should_next_step,\n",
    "                    prev_node=\"StepwiseTaskDecomposer\"\n",
    "                )\n",
    "            else:\n",
    "                generation_steps = state[\"steps\"]\n",
    "                if current_step <= len(generation_steps):\n",
    "                    print (\"---GO TO IMAGE GENERATION---\")\n",
    "                    print (\"current_step: \", current_step)\n",
    "                    should_next_step = \"next_step\"\n",
    "                else:\n",
    "                    should_next_step = \"completed\"\n",
    "                    \n",
    "                return self.state(\n",
    "                    should_next_step=should_next_step,\n",
    "                    prev_node=\"StepwiseTaskDecomposer\"\n",
    "                )\n",
    "            \n",
    "            \n",
    "        def ShouldStepwiseImageGeneration(state):\n",
    "\n",
    "            print(\"---ShouldStepwiseImageGeneration---\")\n",
    "            return state[\"should_next_step\"]\n",
    "        \n",
    "        @retry(total_try_cnt=5, sleep_in_sec=60, retryable_exceptions=(ClientError,))\n",
    "        def ImageGeneration(state):\n",
    "            \n",
    "            print(\"---ImageGeneration---\")\n",
    "            generation_steps, current_step = state[\"steps\"], state.get(\"current_step\", 1)\n",
    "            condition_image = state.get(\"condition_image\", None)\n",
    "            seed = state.get(\"seed\", 1)\n",
    "            prev_node = state.get(\"prev_node\", None)\n",
    "            \n",
    "            pos_prompt = generation_steps[current_step-1][\"prompt\"][\"positive\"]\n",
    "            neg_prompt = generation_steps[current_step-1][\"prompt\"][\"negative\"]\n",
    "            control_mode = generation_steps[current_step-1][\"control_mode\"].upper()\n",
    "            control_strength = generation_steps[current_step-1][\"control_strength\"]\n",
    "            if prev_node == \"PromptReformulation\": seed = random.randint(0, 100000)\n",
    "\n",
    "            seed = random.randint(0, 100000)\n",
    "            print (\"current_step\", current_step)\n",
    "            print (\"condition_image\", condition_image)\n",
    "            print (\"prev_node\", prev_node)\n",
    "            print (\"seed\", seed)\n",
    "                      \n",
    "            if condition_image is not None: #and current_step != 1:\n",
    "                img_bytes, img_base64 = self._png_to_bytes(condition_image)\n",
    "                condition_image = img_base64\n",
    "            else:\n",
    "                condition_image = None\n",
    "            \n",
    "            body = self._body_generator(\n",
    "                pos_prompt=pos_prompt,\n",
    "                neg_prompt=neg_prompt,\n",
    "                condition_image=condition_image,\n",
    "                control_strength=control_strength, # nova랑 반대\n",
    "                seed=seed\n",
    "            )\n",
    "            \n",
    "            response = self.image_generation_model.bedrock_client.invoke_model(\n",
    "                body=body,\n",
    "                modelId=self.image_generation_model.model_id\n",
    "            )\n",
    "            response_body = json.loads(response.get(\"body\").read())\n",
    "            base64_image = response_body.get(\"images\")[0]\n",
    "            condition_image = self.show_save_image(base64_image)\n",
    "            \n",
    "            return self.state(\n",
    "                condition_image=condition_image,\n",
    "                current_step=current_step,\n",
    "                prev_node=\"ImageGeneration\"\n",
    "            )\n",
    "        \n",
    "        def PromptReformulation(state):\n",
    "            \n",
    "            print(\"---PromptReformulation---\")\n",
    "            generation_steps = state[\"steps\"]\n",
    "            suggestions = state[\"suggestions\"]\n",
    "            current_step = state[\"current_step\"]\n",
    "            retry_count = state.get(\"retry_count\", 0)\n",
    "\n",
    "            pos_prompt = generation_steps[current_step-1][\"prompt\"][\"positive\"]\n",
    "            neg_prompt = generation_steps[current_step-1][\"prompt\"][\"negative\"]\n",
    "            original_prompt = f'positive: {pos_prompt}, negative: {neg_prompt}'\n",
    "            messages=[]\n",
    "            \n",
    "            system_prompts = dedent(\n",
    "                '''\n",
    "                You are an agent that enhances image generation prompts based on provided suggestions. Your role is to:\n",
    "\n",
    "                1. Process Input:\n",
    "                   - Original image generation prompt\n",
    "                   - Provided suggestions for improvement\n",
    "\n",
    "                2. Enhance Prompt:\n",
    "                   - Start with new elements or sbjects\n",
    "                   - Maintain the core elements and structure of original prompt\n",
    "                   - Keep the total prompt length under 5,000 characters\n",
    "                   - Write prompts as concisely as possible\n",
    "                   - 제거되어야 하는 사항이 있다면 \"negative\" prompt에 넣어 주세요. \n",
    "                   \n",
    "                3. Determine Control Strength:\n",
    "                   - 0.8-0.95: Optimal range for balanced transformation\n",
    "                   - A value of 0 would yield an image that is identical to the input. A value of 1 would be as if you passed in no image at all. Range: [0, 1]\n",
    "                   - Consider the impact on existing elements\n",
    "\n",
    "                Required Output Format:\n",
    "                DO NOT include any text or json symbol (```json```)outside the JSON format in the response\n",
    "                You must ONLY output the JSON object, nothing else.\n",
    "                NO descriptions of what you're doing before or after JSON.\n",
    "                Note: \"control_strength\" must be included inside the \"prompt_repo\" object.\n",
    "                {\n",
    "                    \"prompt_repo\": {\n",
    "                        \"positive\": <improved prompt incorporating suggestions>,\n",
    "                        \"negative\": <negative prompt>,\n",
    "                        \"control_strength\": <float between 0.0 and 1.0>\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                General Guidelines:\n",
    "                - Keep the original prompt's main structure\n",
    "                - Integrate suggestions naturally\n",
    "                - Use image captioning style\n",
    "                - Maintain clear spatial relationships\n",
    "                - Ensure coherent flow in descriptions\n",
    "                - Preserve essential elements from original prompt\n",
    "                - Use concise, clear descriptions\n",
    "                - Prioritize critical elements when length is constrained\n",
    "                - Remove redundant or unnecessary descriptors\n",
    "                - Stay within 5,000 character limit\n",
    "                - Ensure style consistency with previous steps\n",
    "                \n",
    "                '''\n",
    "            )\n",
    "\n",
    "            system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "            user_prompts = dedent(\n",
    "                '''\n",
    "                Here is original prompt: <original_prompt>{original_prompt}</original_prompt>\n",
    "                Here is suggestions: <suggestions>{suggestions}</suggestions>\n",
    "                '''\n",
    "            )\n",
    "            context = {\n",
    "                \"original_prompt\": original_prompt,\n",
    "                \"suggestions\": suggestions\n",
    "            }\n",
    "            user_prompts = user_prompts.format(**context)\n",
    "                       \n",
    "            message = self._get_message_from_string(role=\"user\", string=user_prompts)\n",
    "            self.messages.append(message)\n",
    "            messages.append(message)\n",
    "            \n",
    "            resp, ai_message = self.llm_caller.invoke(\n",
    "                messages=messages,\n",
    "                system_prompts=system_prompts\n",
    "            )\n",
    "            self.messages.append(ai_message)\n",
    "                        \n",
    "            results = json.loads(resp['text'])\n",
    "            prompt_repo = results[\"prompt_repo\"]\n",
    "\n",
    "            print (\"=================before\")\n",
    "\n",
    "            print (\"pos:\", generation_steps[current_step-1][\"prompt\"][\"positive\"])\n",
    "            print (\"neg:\", generation_steps[current_step-1][\"prompt\"][\"negative\"])\n",
    "            print (\"control_strength:\", generation_steps[current_step-1][\"control_strength\"])\n",
    "\n",
    "            generation_steps[current_step-1][\"prompt\"][\"positive\"] = prompt_repo[\"positive\"]\n",
    "            generation_steps[current_step-1][\"prompt\"][\"negative\"] = prompt_repo[\"negative\"]\n",
    "            generation_steps[current_step-1][\"control_strength\"] = prompt_repo[\"control_strength\"]\n",
    "            \n",
    "            print (\"=================after\")\n",
    "            print (\"pos:\", generation_steps[current_step-1][\"prompt\"][\"positive\"])\n",
    "            print (\"neg:\", generation_steps[current_step-1][\"prompt\"][\"negative\"])\n",
    "            print (\"control_strength:\", generation_steps[current_step-1][\"control_strength\"])\n",
    "\n",
    "            return self.state(\n",
    "                generation_steps=generation_steps,\n",
    "                prev_node=\"PromptReformulation\"\n",
    "            )\n",
    "        \n",
    "        def Reflection(state):\n",
    "            \n",
    "            print(\"---Reflection---\")\n",
    "            generation_steps = state[\"steps\"]\n",
    "            current_step = state[\"current_step\"]\n",
    "            condition_image = state[\"condition_image\"]\n",
    "            retry_count = state.get(\"retry_count\", 0)\n",
    "\n",
    "            pos_prompt = generation_steps[current_step-1][\"prompt\"][\"positive\"]\n",
    "            neg_prompt = generation_steps[current_step-1][\"prompt\"][\"negative\"]\n",
    "            step_ask = f'positive: {pos_prompt}, negative: {neg_prompt}'\n",
    "            messages = []\n",
    "            \n",
    "            print (\"step_ask\", step_ask)\n",
    "        \n",
    "            system_prompts = dedent(\n",
    "                '''\n",
    "                You are an image quality evaluator.\n",
    "                Compare the generated image with the user's requirements and provide an assessment focusing on accuracy and alignment.\n",
    "                Evaluate whether all requested elements are present and match the requirements.\n",
    "                \n",
    "                Output your evaluation in the following JSON format:\n",
    "                DO NOT include any text or json symbol (```json```)outside the JSON format in the response\n",
    "                You must ONLY output the JSON object, nothing else.\n",
    "                NO descriptions of what you're doing before or after JSON.\n",
    "                {\n",
    "                    \"retouch\": \"true/false\",  // true if elements don't match (MUST mark true for ANY mismatch in counts, positions, or orientations of subjects/objects)\n",
    "                    \"suggestions\": [\n",
    "                        \"list mismatches first\"\n",
    "                    ],\n",
    "                    \"evaluation\": {\n",
    "                        \"key_subjects\": {\n",
    "                            \"subject_name\": {\n",
    "                                \"results\": \"match/mismatch\",\n",
    "                                \"count\": \"actual count\",\n",
    "                                \"attributes\": \"key details\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"composition\": {\n",
    "                            \"alignment\": \"evaluation of layout and positioning\"\n",
    "                        },\n",
    "                        \"style\": {\n",
    "                            \"overall\": \"evaluation of style and mood\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "                Provide clear, concise feedback for any mismatches.\n",
    "               \n",
    "                '''\n",
    "             )\n",
    "\n",
    "            system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "            user_prompts = dedent(\n",
    "                '''\n",
    "                Here is the user requests: <user_requests>{ask}</user_requests>\n",
    "                '''\n",
    "            )    \n",
    "            context = {\n",
    "                \"ask\": step_ask\n",
    "            }\n",
    "            user_prompts = user_prompts.format(**context)\n",
    "            \n",
    "            img_bytes, img_base64 = self._png_to_bytes(condition_image)\n",
    "            message = self._get_message_from_string(role=\"user\", string=user_prompts, imgs=[img_bytes])\n",
    "            messages.append(message)\n",
    "            self.messages.append(message)\n",
    "\n",
    "            resp, ai_message = self.llm_caller.invoke(\n",
    "                messages=messages,\n",
    "                system_prompts=system_prompts\n",
    "            )\n",
    "            self.messages.append(ai_message)\n",
    "\n",
    "            results = json.loads(resp['text'])\n",
    "            suggestions = results[\"suggestions\"]\n",
    "            retouch, suggestions = results[\"retouch\"], results[\"suggestions\"]\n",
    "            if retouch == \"true\":\n",
    "                retry_count += 1\n",
    "                if retry_count <= 5: should_regeneration = \"retouch\"\n",
    "                else:\n",
    "                    retry_count = 0\n",
    "                    current_step += 1\n",
    "                    should_regeneration = \"pass\"\n",
    "            else:\n",
    "                retry_count = 0  \n",
    "                current_step += 1\n",
    "                should_regeneration = \"pass\"\n",
    "\n",
    "            return self.state(\n",
    "                retouch=retouch,\n",
    "                suggestions=suggestions,\n",
    "                retry_count=retry_count,\n",
    "                current_step=current_step,\n",
    "                should_regeneration=should_regeneration,\n",
    "                prev_node=\"Reflection\"\n",
    "            )\n",
    "            messages = []\n",
    "\n",
    "        def ShouldImageRegeneration(state):\n",
    "            \n",
    "            print(\"---ShouldImageRegeneration---\")\n",
    "\n",
    "            return state[\"should_regeneration\"]\n",
    "\n",
    "        # langgraph.graph에서 StateGraph와 END를 가져옵니다.\n",
    "        workflow = StateGraph(self.state)\n",
    "\n",
    "        # Todo 를 작성합니다.\n",
    "        workflow.add_node(\"StepwiseTaskDecomposer\", StepwiseTaskDecomposer)  # 이미지 생성을 위해 필요한 요소들이 준비되었는지 확인합니다.\n",
    "        workflow.add_node(\"ImageGeneration\", ImageGeneration)  # 요청을 이미지 생성용 프롬프트로 수정하는 노드를 추가합니다.\n",
    "        workflow.add_node(\"Reflection\", Reflection)  # 사용자의 요청에 맞게 이미지가 생성 되었는지 확인힙니다.\n",
    "        workflow.add_node(\"PromptReformulation\", PromptReformulation)  # 사용자의 요청에 맞게 이미지가 생성 되었는지 확인힙니다.\n",
    "        \n",
    "        workflow.add_conditional_edges(\n",
    "            \"StepwiseTaskDecomposer\",\n",
    "            # 에이전트 결정 평가\n",
    "            ShouldStepwiseImageGeneration,\n",
    "            {\n",
    "                # 도구 노드 호출\n",
    "                \"next_step\": \"ImageGeneration\",\n",
    "                \"completed\": END,\n",
    "            },\n",
    "        )\n",
    "        workflow.add_edge(\"ImageGeneration\", \"Reflection\")\n",
    "        workflow.add_conditional_edges(\n",
    "            \"Reflection\",\n",
    "            # 에이전트 결정 평가\n",
    "            ShouldImageRegeneration,\n",
    "            {\n",
    "                # 도구 노드 호출\n",
    "                \"pass\": \"StepwiseTaskDecomposer\",\n",
    "                \"retouch\": \"PromptReformulation\"\n",
    "            },\n",
    "        )\n",
    "        workflow.add_edge(\"PromptReformulation\", \"ImageGeneration\")\n",
    "        \n",
    "        # 시작점을 설정합니다.\n",
    "        workflow.set_entry_point(\"StepwiseTaskDecomposer\")\n",
    "\n",
    "        # 기록을 위한 메모리 저장소를 설정합니다.\n",
    "        memory = MemorySaver()\n",
    "\n",
    "        # 그래프를 컴파일합니다.\n",
    "        self.app = workflow.compile(checkpointer=memory)        \n",
    "        self.config = RunnableConfig(recursion_limit=100, configurable={\"thread_id\": \"Text2Image\"})\n",
    "\n",
    "    def invoke(self, **kwargs):\n",
    "            \n",
    "        inputs = self.state(\n",
    "            ask=kwargs[\"ask\"],\n",
    "            image_model=kwargs[\"image_model\"]\n",
    "        )\n",
    "\n",
    "        # app.stream을 통해 입력된 메시지에 대한 출력을 스트리밍합니다.\n",
    "        for output in self.app.stream(inputs, self.config):\n",
    "            # 출력된 결과에서 키와 값을 순회합니다.\n",
    "            for key, value in output.items():\n",
    "                # 노드의 이름과 해당 노드에서 나온 출력을 출력합니다.\n",
    "                pprint.pprint(f\"\\nOutput from node '{key}':\")\n",
    "                pprint.pprint(\"---\")\n",
    "                # 출력 값을 예쁘게 출력합니다.\n",
    "                pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "                \n",
    "            # 각 출력 사이에 구분선을 추가합니다.\n",
    "            pprint.pprint(\"\\n---\\n\")\n",
    "\n",
    "        #return steps\n",
    "            \n",
    "    \n",
    "    def show_graph(self, ):\n",
    "        \n",
    "        from IPython.display import Image, display\n",
    "\n",
    "        try:\n",
    "            display(\n",
    "                Image(self.app.get_graph(xray=True).draw_mermaid_png())\n",
    "            )  # 실행 가능한 객체의 그래프를 mermaid 형식의 PNG로 그려서 표시합니다. \n",
    "            # xray=True는 추가적인 세부 정보를 포함합니다.\n",
    "        except:\n",
    "            # 이 부분은 추가적인 의존성이 필요하며 선택적으로 실행됩니다.\n",
    "            pass\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyzer = genai_analyzer(\n",
    "    llm=llm,\n",
    "    image_generation_model=image_generation_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyzer.show_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyzer = genai_analyzer(\n",
    "    llm=llm,\n",
    "    image_generation_model=image_generation_model\n",
    ")\n",
    "\n",
    "steps = analyzer.invoke(\n",
    "    ask=dedent(\n",
    "        '''\n",
    "        An icy landscape.\n",
    "        A vast expanse of snow-covered mountain peaks stretches endlessly.\n",
    "        Beneath them is a dense forest and a colossal frozen lake.\n",
    "        people are boating in three boats in the lake.\n",
    "        Not far from the lake, a volcano threatens eruption, its rumblings felt even from afar.\n",
    "        On the mountain, a ferocious red dragon dominates the sky and commands the heavens, fueled by the volcano's relentless energy flow.\n",
    "        Oil painting style.\n",
    "        '''\n",
    "    ),\n",
    "    image_model=\"stable-diffusion\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyzer = genai_analyzer(\n",
    "    llm=llm,\n",
    "    image_generation_model=image_generation_model\n",
    ")\n",
    "\n",
    "steps = analyzer.invoke(\n",
    "    ask=dedent(\n",
    "        '''\n",
    "        검은 벽에 파란 배경과 흰색 글씨로 'AWS AIML Specialist'라는 글자가 쓰여 있고, 그 앞에 빨간 자전거가 놓여있다.\n",
    "        '''\n",
    "    ),\n",
    "    image_model=\"stable-diffusion\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyzer = genai_analyzer(\n",
    "    llm=llm,\n",
    "    image_generation_model=image_generation_model\n",
    ")\n",
    "\n",
    "steps = analyzer.invoke(\n",
    "    ask=dedent(\"An oil painting, where a green vintage car, a blue scooter on the left of it and a black bicycle on the right of it, are parked on the road, with two birds in the sky.\"),\n",
    "    image_model=\"stable-diffusion\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyzer = genai_analyzer(\n",
    "    llm=llm,\n",
    "    image_generation_model=image_generation_model\n",
    ")\n",
    "steps = analyzer.invoke(\n",
    "    ask=dedent(\n",
    "        '''\n",
    "        Two hot dogs sit on a green plate near a soda cup which are sitting on a white picnic table, while a red bike (on the left of image) and a blue car (on the right of image)are parked nearby.\n",
    "        A high-resolution DSLR photograph\n",
    "        '''\n",
    "    ),\n",
    "    image_model=\"stable-diffusion\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
