import os
import logging
import json
from src.prompts.template import apply_prompt_template
from src.config.agents import AGENT_LLM_MAP, AGENT_PROMPT_CACHE_MAP
from src.tools.research_tools import research_tool_config, process_search_tool
from src.tools.coder_tools import coder_tool_config, process_coder_tool
# from src.tools.browser_tools import browser_tool_config, process_browser_tool
from src.tools.reporter_tools import reporter_tool_config, process_reporter_tool
from src.tools.validator_tools import validator_tool_config, process_validator_tool

from src.agents.llm import llm_call_langfuse

llm_module = os.environ.get('LLM_MODULE', 'src.agents.llm')
if llm_module == 'src.agents.llm_st': from src.agents.llm_st import get_llm_by_type, llm_call
else: from src.agents.llm import get_llm_by_type, llm_call

# ìƒˆ í•¸ë“¤ëŸ¬ì™€ í¬ë§·í„° ì„¤ì •
logger = logging.getLogger(__name__)
logger.propagate = False  # ìƒìœ„ ë¡œê±°ë¡œ ë©”ì‹œì§€ ì „íŒŒ ì¤‘ì§€
for handler in logger.handlers[:]:
    logger.removeHandler(handler)
handler = logging.StreamHandler()
formatter = logging.Formatter('\n%(levelname)s [%(name)s] %(message)s')  # ë¡œê·¸ ë ˆë²¨ì´ ë™ì ìœ¼ë¡œ í‘œì‹œë˜ë„ë¡ ë³€ê²½
handler.setFormatter(formatter)
logger.addHandler(handler)
# DEBUGì™€ INFO ì¤‘ ì›í•˜ëŠ” ë ˆë²¨ë¡œ ì„¤ì •
logger.setLevel(logging.INFO)  # ê¸°ë³¸ ë ˆë²¨ì€ INFOë¡œ ì„¤ì •

class Colors:
    BLUE = '\033[94m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'
    END = '\033[0m'

class create_react_agent():

    def __init__(self, **kwargs):

        self.agent_name = kwargs["agent_name"]
        self.llm = get_llm_by_type(AGENT_LLM_MAP[self.agent_name])
        self.llm.stream = True
        self.llm_caller = llm_call(llm=self.llm, verbose=False, tracking=False)
        
        if AGENT_LLM_MAP[self.agent_name] in ["reasoning"]: self.enable_reasoning = True
        else: self.enable_reasoning = False
        
        if self.agent_name == "researcher": self.tool_config = research_tool_config
        elif self.agent_name == "coder": self.tool_config = coder_tool_config
        elif self.agent_name == "validator": self.tool_config = validator_tool_config
        # elif self.agent_name == "browser": self.tool_config = browser_tool_config
        elif self.agent_name == "reporter": self.tool_config = reporter_tool_config
            
        # ë°˜ë³µ ëŒ€í™” ì²˜ë¦¬ë¥¼ ìœ„í•œ ì„¤ì •
        self.MAX_TURNS = 30  # ë¬´í•œ ë£¨í”„ ë°©ì§€ìš© ìµœëŒ€ í„´ ìˆ˜
        self.turn = 0
        self.final_response = False
        
    def invoke(self, **kwargs):

        state = kwargs.get("state", None)
        prompt_cache, cache_type = AGENT_PROMPT_CACHE_MAP[self.agent_name]
        system_prompts, messages = apply_prompt_template(self.agent_name, state, prompt_cache=prompt_cache, cache_type=cache_type)    
        
        # ë„êµ¬ ì‚¬ìš©ì´ ì¢…ë£Œë  ë•Œê¹Œì§€ ë°˜ë³µ
        while not self.final_response and self.turn < self.MAX_TURNS:
            self.turn += 1
            logger.info(f"{Colors.YELLOW}ğŸ”„ --- {self.agent_name} ëŒ€í™” í„´ {self.turn} ---{Colors.END}")
            response, ai_message = self.llm_caller.invoke(
                agent_name=self.agent_name,
                messages=messages,
                system_prompts=system_prompts,
                tool_config=self.tool_config,
                enable_reasoning=self.enable_reasoning,
                reasoning_budget_tokens=8192
            )
            messages.append(ai_message)    

            # ë„êµ¬ ì‚¬ìš© ìš”ì²­ í™•ì¸
            stop_reason = response.get("stop_reason") or response.get("stopReason")
            if stop_reason is None:
                # print("responseì— stop_reasonì´ ì—†ìŠµë‹ˆë‹¤:", json.dumps(response, indent=2, ensure_ascii=False))
                pass
            if stop_reason == "tool_use":
                tool_requests_found = False

                # ì‘ë‹µì—ì„œ ëª¨ë“  ë„êµ¬ ì‚¬ìš© ìš”ì²­ ì²˜ë¦¬
                for content in ai_message['content']:
                    if 'toolUse' in content:
                        tool = content['toolUse']
                        tool_requests_found = True

                        # ReAct ë‹¨ê³„ë³„ í–‰ë™ ì„¤ëª…
                        tool_descriptions = {
                            "search_tool": "ğŸ” ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘",
                            "read_file_tool": "ğŸ“– íŒŒì¼ ì½ê¸° ì¤‘",
                            "write_file_tool": "ğŸ“ íŒŒì¼ ì“°ê¸° ì¤‘", 
                            "python_repl_tool": "ğŸ íŒŒì´ì¬ ì½”ë“œ ì‹¤í–‰ ì¤‘",
                            "crawl_tool": "ğŸŒ ì›¹ í¬ë¡¤ë§ ì¤‘",
                            "bash_tool": "âš¡ ì‹œìŠ¤í…œ ëª…ë ¹ ì‹¤í–‰ ì¤‘"
                        }
                        
                        action_desc = tool_descriptions.get(tool['name'], f"ğŸ”§ {tool['name']} ì‹¤í–‰ ì¤‘")
                        logger.info(f"{Colors.YELLOW}ğŸ¤– ReAct Action: {action_desc}{Colors.END}")
                        logger.info(f"{Colors.BOLD}ToolUse - Tool Name: {tool['name']}, Input: {tool['input']}{Colors.END}")

                        if self.agent_name == "researcher": tool_result_message = process_search_tool(tool)
                        elif self.agent_name == "coder": tool_result_message = process_coder_tool(tool)
                        elif self.agent_name == "validator": tool_result_message = process_validator_tool(tool)
                        # elif self.agent_name == "browser": tool_result_message = process_browser_tool(tool)
                        elif self.agent_name == "reporter": tool_result_message = process_reporter_tool(tool)

                        messages.append(tool_result_message)
                        logger.info(f"{Colors.GREEN}âœ… ReAct Observation: ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ{Colors.END}")
                        logger.info(f"{Colors.BOLD}ToolUse - ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ëŒ€í™”ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.{Colors.END}")

                # ë„êµ¬ ìš”ì²­ì´ ì—†ìœ¼ë©´ ë£¨í”„ ì¢…ë£Œ
                if not tool_requests_found:
                    # print("ë„êµ¬ ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    # logger.info(f"{Colors.UNDERLINE}ToolUse - ë„êµ¬ ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.{Colors.END}")
                    self.final_response = True
            else:
                # ë„êµ¬ ì‚¬ìš©ì´ ìš”ì²­ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ìµœì¢… ì‘ë‹µìœ¼ë¡œ ê°„ì£¼
                self.final_response = True
                # logger.info(f"{Colors.UNDERLINE}ToolUse - ìµœì¢… ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤.{Colors.END}")
                # print("ìµœì¢… ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")

        # print("\n=== ëŒ€í™” ì™„ë£Œ ===")
        # print("ìµœì¢… ì‘ë‹µ:\n", response)
        # print("ë©”ì‹œì§€:\n", ai_message)
        
        return ai_message
    


class create_react_agent_langfuse():

    def __init__(self, **kwargs):

        self.agent_name = kwargs["agent_name"]
        self.llm = get_llm_by_type(AGENT_LLM_MAP[self.agent_name])
        # print("## Agent Name: ", self.agent_name, " , ", AGENT_LLM_MAP[self.agent_name])
        self.llm.stream = True
        # self.llm_caller = llm_call(llm=self.llm, verbose=False, tracking=False)
        self.llm_caller = llm_call_langfuse(llm=self.llm, verbose=False, tracking=False)
        
        if AGENT_LLM_MAP[self.agent_name] in ["reasoning"]: 
            self.enable_reasoning = True
            # self.enable_reasoning = False
        else: self.enable_reasoning = False
        
        if self.agent_name == "researcher": self.tool_config = research_tool_config
        elif self.agent_name == "coder": self.tool_config = coder_tool_config
        elif self.agent_name == "validator": self.tool_config = validator_tool_config
        # elif self.agent_name == "browser": self.tool_config = browser_tool_config
        elif self.agent_name == "reporter": self.tool_config = reporter_tool_config
            
        # ë°˜ë³µ ëŒ€í™” ì²˜ë¦¬ë¥¼ ìœ„í•œ ì„¤ì •
        self.MAX_TURNS = 20  # ë¬´í•œ ë£¨í”„ ë°©ì§€ìš© ìµœëŒ€ í„´ ìˆ˜
        # self.MAX_TURNS = 12  # ë¬´í•œ ë£¨í”„ ë°©ì§€ìš© ìµœëŒ€ í„´ ìˆ˜
        self.turn = 0
        self.final_response = False
        
    def invoke(self, **kwargs):

        state = kwargs.get("state", None)
        prompt_cache, cache_type = AGENT_PROMPT_CACHE_MAP[self.agent_name]
        system_prompts, messages = apply_prompt_template(self.agent_name, state, prompt_cache=prompt_cache, cache_type=cache_type)    
        
        # ë„êµ¬ ì‚¬ìš©ì´ ì¢…ë£Œë  ë•Œê¹Œì§€ ë°˜ë³µ
        while not self.final_response and self.turn < self.MAX_TURNS:
            self.turn += 1
            logger.info(f"{Colors.YELLOW}ğŸ”„ --- {self.agent_name} ëŒ€í™” í„´ {self.turn} ---{Colors.END}")
            response, ai_message = self.llm_caller.invoke(
                agent_name=self.agent_name,
                messages=messages,
                system_prompts=system_prompts,
                tool_config=self.tool_config,
                enable_reasoning=self.enable_reasoning,
                reasoning_budget_tokens=8192
            )
            messages.append(ai_message)    

            # print("## response in agent: \n", json.dumps(response, indent=2, ensure_ascii=False))
            
            # ë„êµ¬ ì‚¬ìš© ìš”ì²­ í™•ì¸
            stop_reason = response.get("stop_reason") or response.get("stopReason")
            if stop_reason is None:
                # print("responseì— stop_reasonì´ ì—†ìŠµë‹ˆë‹¤:", json.dumps(response, indent=2, ensure_ascii=False))
                pass
            if stop_reason == "tool_use":
                tool_requests_found = False

                # ì‘ë‹µì—ì„œ ëª¨ë“  ë„êµ¬ ì‚¬ìš© ìš”ì²­ ì²˜ë¦¬
                for content in ai_message['content']:
                    if 'toolUse' in content:
                        tool = content['toolUse']
                        tool_requests_found = True

                        # ReAct ë‹¨ê³„ë³„ í–‰ë™ ì„¤ëª…
                        tool_descriptions = {
                            "search_tool": "ğŸ” ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘",
                            "read_file_tool": "ğŸ“– íŒŒì¼ ì½ê¸° ì¤‘",
                            "write_file_tool": "ğŸ“ íŒŒì¼ ì“°ê¸° ì¤‘", 
                            "python_repl_tool": "ğŸ íŒŒì´ì¬ ì½”ë“œ ì‹¤í–‰ ì¤‘",
                            "crawl_tool": "ğŸŒ ì›¹ í¬ë¡¤ë§ ì¤‘",
                            "bash_tool": "âš¡ ì‹œìŠ¤í…œ ëª…ë ¹ ì‹¤í–‰ ì¤‘"
                        }
                        
                        action_desc = tool_descriptions.get(tool['name'], f"ğŸ”§ {tool['name']} ì‹¤í–‰ ì¤‘")
                        logger.info(f"{Colors.YELLOW}ğŸ¤– ReAct Action: {action_desc}{Colors.END}")
                        logger.info(f"{Colors.BOLD}ToolUse - Tool Name: {tool['name']}, Input: {tool['input']}{Colors.END}")

                        if self.agent_name == "researcher": tool_result_message = process_search_tool(tool)
                        elif self.agent_name == "coder": tool_result_message = process_coder_tool(tool)
                        elif self.agent_name == "validator": tool_result_message = process_validator_tool(tool)
                        # elif self.agent_name == "browser": tool_result_message = process_browser_tool(tool)
                        elif self.agent_name == "reporter": tool_result_message = process_reporter_tool(tool)

                        messages.append(tool_result_message)
                        logger.info(f"{Colors.GREEN}âœ… ReAct Observation: ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ{Colors.END}")
                        logger.info(f"{Colors.BOLD}ToolUse - ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ëŒ€í™”ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.{Colors.END}")

                # ë„êµ¬ ìš”ì²­ì´ ì—†ìœ¼ë©´ ë£¨í”„ ì¢…ë£Œ
                if not tool_requests_found:
                    # print("ë„êµ¬ ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    # logger.info(f"{Colors.UNDERLINE}ToolUse - ë„êµ¬ ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.{Colors.END}")
                    self.final_response = True
            else:
                # ë„êµ¬ ì‚¬ìš©ì´ ìš”ì²­ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ìµœì¢… ì‘ë‹µìœ¼ë¡œ ê°„ì£¼
                self.final_response = True
                # logger.info(f"{Colors.UNDERLINE}ToolUse - ìµœì¢… ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤.{Colors.END}")
                # print("ìµœì¢… ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")

        # print("\n=== ëŒ€í™” ì™„ë£Œ ===")
        # print("ìµœì¢… ì‘ë‹µ:\n", response)
        # print("ë©”ì‹œì§€:\n", ai_message)
        
        return ai_message


research_agent = None
coder_agent = None
browser_agent = None
