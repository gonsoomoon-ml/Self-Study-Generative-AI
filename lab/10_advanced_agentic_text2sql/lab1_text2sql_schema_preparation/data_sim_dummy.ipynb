{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# tqdm의 pandas용 progress_apply 활성화\n",
    "tqdm.pandas()\n",
    "\n",
    "# 1. OpenAI API 키 설정 (반드시 본인의 API 키로 변경하세요)\n",
    "openai.api_key = \"\"\n",
    "\n",
    "##############################################\n",
    "# 2. 데이터 로드: 원본 데이터(parquet) 및 카탈로그 데이터(CSV)\n",
    "##############################################\n",
    "# 원본 데이터 파일: '/Users/kali/Downloads/2024-05-20T10_00_00+09_00 (1).parquet'\n",
    "df1 = pd.read_parquet('/content/2024-05-20T10_00_00+09_00 (1).parquet')\n",
    "\n",
    "# 카탈로그 데이터 파일: '/Users/kali/Downloads/diaper_UNIQUE_240430_v1.csv'\n",
    "df2 = pd.read_csv('/content/fenelope_UNIQUE.csv')\n",
    "\n",
    "##############################################\n",
    "# 3. 카탈로그 데이터 임베딩 처리 및 CSV 저장 (오류 발생시 재시도)\n",
    "##############################################\n",
    "# 카탈로그 데이터의 join_item_name 생성\n",
    "df2['join_item_name'] = (\n",
    "    df2['TITLE_TEXT'].fillna('') + \" \" +\n",
    "    df2['opt_title'].fillna('') + \" \" +\n",
    "    df2['OPTION_TEXT_1'].fillna('') + \" \" +\n",
    "    df2['OPTION_TEXT_2'].fillna('') + \" \" +\n",
    "    df2['OPTION_TEXT_3'].fillna('')\n",
    ").str.strip()\n",
    "\n",
    "# 임베딩 캐싱용 딕셔너리 (중복 호출 방지)\n",
    "embedding_cache = {}\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    \"\"\"\n",
    "    주어진 텍스트에 대해 OpenAI 임베딩 벡터를 반환합니다.\n",
    "    \"\"\"\n",
    "    if text in embedding_cache:\n",
    "        return embedding_cache[text]\n",
    "    response = openai.Embedding.create(\n",
    "        input=[text],\n",
    "        model=model\n",
    "    )\n",
    "    embedding = np.array(response['data'][0]['embedding'])\n",
    "    embedding_cache[text] = embedding\n",
    "    return embedding\n",
    "\n",
    "def safe_get_embedding(text, model=\"text-embedding-3-large\", max_retries=3):\n",
    "    \"\"\"\n",
    "    임베딩 호출 시 오류가 발생하면 재시도합니다.\n",
    "    max_retries 번 시도 후에도 실패하면 None을 반환합니다.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return get_embedding(text, model=model)\n",
    "        except Exception as e:\n",
    "            print(f\"임베딩 오류 발생 (텍스트 일부: {text[:30]}...): {e} (재시도 {attempt+1}/{max_retries})\")\n",
    "            time.sleep(5)  # 재시도 전 5초 대기\n",
    "    return None\n",
    "\n",
    "# EMBEDDING 컬럼이 없으면 추가 (이미 존재하면 그대로 사용)\n",
    "if 'EMBEDDING' not in df2.columns:\n",
    "    df2['EMBEDDING'] = None\n",
    "\n",
    "# 임베딩이 없는 행(또는 NaN인 행)을 찾아 계산 (진행률 표시)\n",
    "missing_mask = df2['EMBEDDING'].isnull()\n",
    "if missing_mask.any():\n",
    "    df2.loc[missing_mask, 'EMBEDDING'] = df2.loc[missing_mask, 'join_item_name'].progress_apply(lambda x: safe_get_embedding(x))\n",
    "\n",
    "# CSV에 저장하기 위해 EMBEDDING 컬럼을 문자열(JSON 형식)로 변환\n",
    "df2['EMBEDDING_STR'] = df2['EMBEDDING'].apply(lambda arr: json.dumps(arr.tolist()) if arr is not None else None)\n",
    "\n",
    "# CSV 파일로 저장 (임베딩 재사용을 위해)\n",
    "df2.to_csv('/content/catalog_with_embeddings.csv', index=False)\n",
    "print(\"카탈로그 데이터의 임베딩이 계산되어 CSV 파일로 저장되었습니다.\")\n",
    "\n",
    "##############################################\n",
    "# 4. 원본 데이터 필터링 (CHECK == 0, BRAND == \"페넬로페\")\n",
    "##############################################\n",
    "df1_filtered = df1[(df1['CHECK'] == 0) & (df1['BRAND'] == \"페넬로페\")].copy()\n",
    "\n",
    "##############################################\n",
    "# 5. 원본 데이터의 join_item_name 생성 및 임베딩 계산\n",
    "##############################################\n",
    "df1_filtered['join_item_name'] = (\n",
    "    df1_filtered['OPTION_TEXT_1'].fillna('') + \" \" +\n",
    "    df1_filtered['opt_title'].fillna('') + \" \" +\n",
    "    df1_filtered['TITLE_TEXT'].fillna('') + \" \" +\n",
    "    df1_filtered['OPTION_TEXT_2'].fillna('') + \" \" +\n",
    "    df1_filtered['OPTION_TEXT_3'].fillna('')\n",
    ").str.strip()\n",
    "\n",
    "# 원본 데이터 임베딩 계산 (진행률 표시)\n",
    "df1_filtered['embedding'] = df1_filtered['join_item_name'].progress_apply(lambda x: safe_get_embedding(x))\n",
    "\n",
    "##############################################\n",
    "# 6. 상품 매칭: 원본 데이터 각 행에 대해 카탈로그 데이터와 코사인 유사도 비교\n",
    "##############################################\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"두 벡터 간의 코사인 유사도 계산\"\"\"\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# 카탈로그 데이터에서 BRAND가 \"페넬로페\"인 행만 필터링\n",
    "df2_filtered = df2[df2['BRAND'] == \"페넬로페\"].copy()\n",
    "\n",
    "# 매핑할 카탈로그 컬럼들 (매칭 후 원본 데이터에 삽입)\n",
    "catalog_cols = [\n",
    "    \"ITEM_ID\", \"MANUFACTURER\", \"BRAND\", \"SUBBRAND\",\n",
    "    \"WEIGHT\", \"UOM\", \"PIECE\", \"PACK\", \"TOTAL_WEIGHT\",\n",
    "    \"SKU\", \"SEGMENT1\", \"SEGMENT2\", \"SEGMENT3\"\n",
    "]\n",
    "\n",
    "# 원본 데이터에 해당 컬럼들을 미리 None으로 초기화\n",
    "for col in catalog_cols:\n",
    "    df1_filtered[col] = None\n",
    "\n",
    "similarity_scores = []  # 각 행별 최고 유사도 저장\n",
    "\n",
    "# 원본 데이터 각 행마다 카탈로그 데이터와 코사인 유사도 비교 (진행률 표시)\n",
    "for idx, row in tqdm(df1_filtered.iterrows(), total=df1_filtered.shape[0], desc=\"매칭 진행 중\"):\n",
    "    vec1 = row['embedding']\n",
    "    best_similarity = -1\n",
    "    best_match_idx = None\n",
    "\n",
    "    for jdx, cat_row in df2_filtered.iterrows():\n",
    "        vec2 = cat_row['EMBEDDING']\n",
    "        sim = cosine_similarity(vec1, vec2)\n",
    "        if sim > best_similarity:\n",
    "            best_similarity = sim\n",
    "            best_match_idx = jdx\n",
    "\n",
    "    similarity_scores.append(best_similarity)\n",
    "\n",
    "    # 최고 유사도에 해당하는 카탈로그 행의 정보 매핑\n",
    "    if best_match_idx is not None:\n",
    "        matched_row = df2_filtered.loc[best_match_idx]\n",
    "        for col in catalog_cols:\n",
    "            df1_filtered.at[idx, col] = matched_row[col]\n",
    "\n",
    "df1_filtered['similarity'] = similarity_scores\n",
    "\n",
    "##############################################\n",
    "# 7. 최종 결과 출력\n",
    "##############################################\n",
    "print(\"===== 매칭 결과 (브랜드 '페넬로페' 및 CHECK=0 대상) =====\")\n",
    "print(df1_filtered[[\n",
    "    'TITLE_TEXT', 'opt_title', 'OPTION_TEXT_1', 'OPTION_TEXT_2', 'OPTION_TEXT_3',\n",
    "    'join_item_name', 'ITEM_ID', 'MANUFACTURER', 'BRAND', 'SUBBRAND', 'WEIGHT',\n",
    "    'UOM', 'PIECE', 'PACK', 'TOTAL_WEIGHT', 'SKU', 'SEGMENT1', 'SEGMENT2',\n",
    "    'SEGMENT3', 'similarity'\n",
    "]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
